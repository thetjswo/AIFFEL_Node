{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396fed7c-40ce-4360-9e6b-3fbaac1331b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d60165-d9fb-45ba-8135-7f9b42310f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 높이 28, 너비 28, 채널 수 1개의 데이터 10개\n",
    "x = np.random.rand(10,1,28,28)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91d7389-36f0-4639-a5d8-b4f04a95865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n",
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 1번째 데이터 크기\n",
    "print(x[0].shape)\n",
    "# 10번째 데이터 크기\n",
    "print(x[9].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c995b25-7115-48ea-952e-9e83702bc4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.75286966e-01, 5.94905330e-01, 3.95710762e-02, 2.97328766e-01,\n",
       "        9.60782080e-01, 3.10431467e-01, 6.80809264e-01, 1.24479945e-01,\n",
       "        3.69552644e-01, 6.96970744e-01, 9.20187513e-01, 8.96859059e-01,\n",
       "        1.08854320e-01, 9.54927147e-01, 4.12053699e-02, 7.18291859e-01,\n",
       "        5.89725798e-01, 9.11242746e-01, 4.67309815e-01, 7.71272640e-01,\n",
       "        5.86613850e-01, 6.28509089e-01, 1.55208067e-01, 5.24145538e-01,\n",
       "        1.69169114e-01, 9.62853282e-01, 4.43384447e-01, 8.47205475e-01],\n",
       "       [8.35802068e-01, 3.82380951e-01, 6.09384632e-01, 7.00589277e-01,\n",
       "        5.99787436e-01, 3.62966692e-01, 8.34800083e-01, 6.85130161e-01,\n",
       "        5.17493022e-01, 1.71846224e-01, 7.32769019e-01, 9.53678340e-01,\n",
       "        8.27841769e-01, 6.84651117e-01, 6.10358185e-01, 9.82690501e-01,\n",
       "        6.18251222e-01, 6.57786982e-01, 9.84581056e-01, 6.58745656e-01,\n",
       "        1.00952060e-01, 8.40398290e-01, 1.71032674e-01, 4.57744622e-01,\n",
       "        9.57154724e-01, 4.54843968e-01, 3.01738725e-01, 8.78483940e-01],\n",
       "       [7.09525186e-01, 4.93701594e-01, 7.65400982e-01, 6.64384041e-01,\n",
       "        3.33383869e-01, 6.46917103e-01, 9.98949443e-01, 8.16008628e-01,\n",
       "        4.91671129e-01, 2.47101275e-01, 5.84124732e-01, 4.04219117e-01,\n",
       "        4.23472621e-01, 2.04476585e-01, 8.73581763e-01, 6.07999395e-01,\n",
       "        2.52692473e-01, 6.54291365e-01, 7.43145405e-01, 8.43469861e-01,\n",
       "        9.64141178e-01, 6.66504043e-01, 6.11576315e-01, 6.14917817e-01,\n",
       "        6.06711059e-01, 7.98925801e-01, 6.89361661e-01, 5.85509782e-01],\n",
       "       [4.63718123e-01, 3.45663496e-01, 3.93003207e-01, 9.35173936e-01,\n",
       "        9.91676655e-01, 9.75882757e-02, 1.51658798e-02, 9.28971885e-01,\n",
       "        9.26037691e-01, 8.65248450e-01, 3.48520432e-01, 6.85336547e-02,\n",
       "        8.74361254e-01, 1.91664416e-01, 1.66345632e-01, 9.29878021e-01,\n",
       "        3.70971748e-01, 8.82652080e-01, 9.37030620e-01, 1.23165006e-01,\n",
       "        5.24508929e-01, 7.80220683e-01, 1.56073543e-01, 2.41389317e-01,\n",
       "        4.53793339e-01, 6.81570285e-01, 2.38987865e-01, 4.50707026e-01],\n",
       "       [8.57342142e-01, 8.66906670e-02, 7.05624642e-01, 5.55301073e-01,\n",
       "        7.51616357e-01, 9.20987084e-01, 9.09649408e-02, 5.26179871e-01,\n",
       "        8.22618455e-01, 9.36367048e-01, 9.85805331e-01, 2.42500598e-01,\n",
       "        1.53704440e-01, 8.13173691e-01, 9.89221106e-01, 3.47181818e-02,\n",
       "        7.52374229e-01, 7.58746499e-02, 6.44432666e-01, 1.46226618e-03,\n",
       "        6.08494771e-01, 2.17356922e-01, 4.75726984e-01, 9.02940697e-01,\n",
       "        7.83141690e-01, 7.83895495e-01, 6.97219759e-01, 5.64233465e-01],\n",
       "       [3.06760518e-01, 9.78922722e-01, 9.10100211e-02, 7.60042148e-01,\n",
       "        9.44426670e-01, 7.15591836e-01, 1.22503895e-01, 5.96022249e-01,\n",
       "        6.42056436e-03, 9.53619396e-01, 6.68580488e-01, 4.11879554e-01,\n",
       "        8.89921293e-01, 7.04853459e-01, 3.15705500e-01, 7.82191989e-01,\n",
       "        3.07828639e-01, 7.31958745e-02, 4.13657462e-01, 5.76917028e-01,\n",
       "        4.09363540e-01, 6.16767732e-01, 4.58936969e-02, 3.29019026e-01,\n",
       "        2.01142372e-01, 4.63750414e-01, 9.48934561e-01, 2.23479628e-01],\n",
       "       [9.22710697e-01, 7.72178996e-01, 7.33880845e-01, 8.76412999e-01,\n",
       "        8.52173867e-01, 1.25189806e-01, 1.77865830e-01, 1.45848580e-01,\n",
       "        3.48009565e-01, 5.00365462e-01, 7.27026961e-01, 7.96913471e-01,\n",
       "        5.04514271e-01, 1.24855138e-01, 3.53396970e-01, 3.66140608e-01,\n",
       "        6.19213380e-02, 2.26305738e-01, 2.82999570e-01, 9.90461941e-01,\n",
       "        2.52441077e-02, 3.43029481e-01, 1.14827564e-01, 8.43171973e-03,\n",
       "        8.42710226e-01, 1.02753313e-01, 4.53120875e-02, 8.38459139e-01],\n",
       "       [7.08864397e-01, 3.30152814e-01, 1.34526968e-01, 3.16216257e-01,\n",
       "        1.85621156e-01, 6.44751923e-01, 6.46061658e-01, 4.66346342e-02,\n",
       "        3.86648280e-01, 4.79929419e-01, 9.37306327e-01, 5.11445271e-02,\n",
       "        7.87465698e-01, 8.46185225e-02, 2.92178387e-01, 9.04878129e-01,\n",
       "        2.04367300e-01, 6.31290518e-01, 9.61851873e-01, 4.88626661e-01,\n",
       "        8.86625863e-01, 6.51511447e-01, 3.74176618e-01, 7.50598620e-01,\n",
       "        6.41304032e-01, 8.95435899e-01, 4.91580861e-01, 6.82313047e-01],\n",
       "       [9.16094750e-01, 2.57653358e-01, 7.58496995e-02, 2.00207575e-01,\n",
       "        6.57439337e-01, 3.24427901e-02, 1.34168149e-01, 2.11724451e-01,\n",
       "        6.78891365e-01, 4.65307428e-02, 2.28114038e-02, 2.21137797e-01,\n",
       "        7.60196230e-01, 2.35565951e-01, 1.76172422e-01, 5.13260460e-01,\n",
       "        5.91956993e-01, 5.84135443e-01, 8.57374388e-01, 1.56713505e-01,\n",
       "        5.90127094e-01, 2.13271095e-01, 9.48397547e-01, 7.37115817e-01,\n",
       "        3.98852088e-01, 5.38440643e-02, 5.44193740e-01, 8.17415833e-01],\n",
       "       [9.28226304e-01, 7.24836698e-01, 8.11041835e-01, 8.14926261e-01,\n",
       "        2.34989683e-01, 9.02575184e-02, 4.49101871e-01, 1.80226434e-01,\n",
       "        4.83000423e-01, 2.75475162e-01, 2.46047759e-02, 3.07035896e-01,\n",
       "        2.80699420e-01, 7.33506864e-01, 8.82642510e-01, 5.27101295e-01,\n",
       "        2.52672592e-01, 4.22206298e-01, 5.02013364e-01, 2.27405032e-01,\n",
       "        6.33500277e-01, 6.08971918e-01, 6.04179066e-01, 9.52674781e-01,\n",
       "        1.01208719e-01, 2.13621255e-01, 6.47622541e-01, 1.91663762e-01],\n",
       "       [2.56482509e-01, 9.81588342e-02, 3.64668134e-01, 6.74079674e-01,\n",
       "        8.51958362e-01, 7.86567728e-01, 1.43221173e-01, 5.95567161e-01,\n",
       "        3.89096508e-01, 9.91918130e-01, 3.81082559e-01, 4.60799515e-01,\n",
       "        1.93724834e-01, 6.66016743e-01, 7.55283317e-01, 9.94418896e-01,\n",
       "        3.69658684e-01, 3.93234725e-01, 6.25112267e-01, 2.13407569e-01,\n",
       "        7.05141588e-02, 9.64879100e-01, 3.59415631e-01, 5.09394493e-01,\n",
       "        3.96047723e-02, 8.55594550e-01, 4.55478455e-01, 4.81113919e-01],\n",
       "       [8.75637461e-01, 9.20954129e-01, 7.76162330e-01, 6.09855407e-01,\n",
       "        5.07637040e-01, 1.55887462e-04, 4.56659732e-01, 2.27788854e-01,\n",
       "        7.51758990e-01, 7.21792295e-01, 6.43589347e-01, 5.92900115e-01,\n",
       "        7.03457696e-01, 1.80143385e-01, 9.95495666e-01, 5.98518542e-01,\n",
       "        5.67077506e-01, 7.36013491e-01, 8.91108353e-01, 9.83309052e-01,\n",
       "        6.07402156e-01, 5.12563843e-01, 6.12284906e-01, 8.05083475e-01,\n",
       "        6.40950762e-01, 9.97384908e-01, 7.54473786e-01, 4.46939988e-01],\n",
       "       [9.64466165e-01, 7.11329894e-01, 8.56254626e-01, 3.43386950e-01,\n",
       "        4.01287320e-01, 9.97414261e-01, 1.66364676e-01, 8.77875105e-01,\n",
       "        7.56404641e-01, 1.26575528e-01, 6.43917927e-01, 8.89012246e-01,\n",
       "        5.78399120e-01, 2.49232742e-01, 8.91942143e-01, 5.27159159e-01,\n",
       "        2.30396286e-01, 6.85631759e-01, 3.95230260e-01, 9.90343632e-01,\n",
       "        9.74867486e-01, 7.83123079e-01, 4.74991048e-01, 8.30723837e-03,\n",
       "        7.70145627e-01, 9.52163222e-01, 3.81276582e-01, 9.76341353e-01],\n",
       "       [7.44892903e-01, 3.59680661e-01, 6.64965848e-01, 4.48542675e-01,\n",
       "        2.29481006e-01, 9.84648906e-01, 8.02071696e-01, 7.11004308e-02,\n",
       "        6.29674627e-01, 8.94820516e-01, 3.47415035e-01, 9.37355840e-02,\n",
       "        8.59735179e-01, 6.32444756e-01, 8.58733597e-01, 7.04188782e-01,\n",
       "        4.17112574e-01, 1.72547345e-01, 8.42090145e-01, 5.97128160e-02,\n",
       "        4.64194858e-01, 2.90111659e-01, 3.45544725e-01, 4.99977621e-01,\n",
       "        1.32800720e-01, 1.32820642e-01, 8.59906759e-01, 8.04377981e-01],\n",
       "       [6.70890940e-01, 9.00633953e-01, 1.53860493e-01, 6.02457803e-01,\n",
       "        5.46265650e-01, 3.43763813e-01, 3.71454948e-01, 6.15073069e-02,\n",
       "        3.01373472e-01, 9.61353543e-01, 6.99836850e-01, 9.79199392e-01,\n",
       "        2.51828567e-01, 3.44318367e-01, 3.58072927e-01, 9.47367765e-01,\n",
       "        1.43745952e-01, 1.35318289e-01, 2.03615947e-02, 5.98528811e-01,\n",
       "        1.51888951e-01, 2.45844282e-01, 7.61749016e-01, 2.47489795e-01,\n",
       "        4.37866449e-01, 8.95888877e-01, 4.92699930e-01, 8.92894945e-01],\n",
       "       [2.16843436e-01, 1.76849324e-01, 8.19686424e-01, 1.61305326e-02,\n",
       "        2.06582327e-01, 2.37848593e-01, 4.14830740e-02, 4.39692456e-01,\n",
       "        5.08088844e-01, 3.10869551e-01, 9.22745581e-01, 8.59811670e-02,\n",
       "        2.36856323e-01, 2.74508064e-02, 4.69646354e-01, 5.95166619e-01,\n",
       "        5.60353502e-01, 1.00526791e-01, 8.95019777e-01, 7.89298238e-01,\n",
       "        7.01141863e-01, 6.33027526e-01, 3.29325728e-02, 2.56745355e-01,\n",
       "        3.90264452e-01, 7.47858919e-02, 5.58010711e-01, 7.64708252e-01],\n",
       "       [4.01905944e-01, 6.69810922e-01, 9.52550345e-01, 5.39580271e-02,\n",
       "        4.78646286e-01, 5.44583557e-01, 1.47036548e-01, 9.10629888e-01,\n",
       "        6.66328621e-01, 5.39946316e-01, 3.27866947e-01, 1.22788671e-01,\n",
       "        1.17771136e-01, 1.84101842e-01, 9.09367958e-01, 5.39069262e-01,\n",
       "        4.74442768e-01, 4.13874666e-01, 5.21165622e-01, 6.17828475e-01,\n",
       "        9.04992595e-01, 2.80089878e-01, 5.61796615e-01, 3.46708974e-01,\n",
       "        5.59842436e-01, 3.62006414e-01, 2.03907126e-01, 2.39514305e-01],\n",
       "       [1.33585952e-01, 3.66154087e-01, 7.44499534e-01, 9.98723044e-01,\n",
       "        3.48162762e-01, 5.50282186e-01, 8.60675416e-01, 6.26992042e-01,\n",
       "        9.60412554e-02, 1.11479635e-01, 4.57003324e-01, 8.81079182e-01,\n",
       "        3.63877507e-01, 2.01477319e-01, 6.35901975e-01, 6.69102350e-01,\n",
       "        2.45900118e-01, 2.17834593e-01, 8.99920471e-01, 6.96954711e-02,\n",
       "        8.34592067e-01, 5.83428790e-01, 5.81608380e-01, 8.17672593e-01,\n",
       "        2.22574410e-01, 8.40437762e-01, 2.96497793e-01, 6.62256384e-01],\n",
       "       [7.24924642e-01, 2.26452173e-01, 3.87483684e-01, 6.67290374e-01,\n",
       "        1.40930659e-01, 6.22884151e-01, 5.62409160e-01, 1.50398475e-01,\n",
       "        3.49764441e-01, 9.71562080e-01, 2.40632081e-01, 3.63936660e-02,\n",
       "        8.06008413e-01, 4.40489702e-01, 4.19702129e-01, 1.03775732e-01,\n",
       "        6.35717262e-01, 7.26677978e-01, 6.13754508e-01, 8.45907625e-01,\n",
       "        2.93072349e-01, 2.27758570e-01, 6.32586353e-01, 4.40458996e-01,\n",
       "        7.91572324e-01, 6.77727815e-01, 7.07815928e-01, 8.94037131e-01],\n",
       "       [9.43269331e-01, 3.28266595e-01, 3.68293666e-02, 3.78797169e-01,\n",
       "        7.70724507e-01, 2.59133909e-01, 6.80436217e-01, 4.22749036e-01,\n",
       "        9.00563654e-01, 2.66354991e-01, 9.82946644e-01, 4.27075698e-02,\n",
       "        7.70147782e-01, 4.26684194e-01, 1.82542726e-01, 8.67420767e-01,\n",
       "        8.46108169e-01, 4.98395917e-01, 1.61789061e-01, 7.39108007e-01,\n",
       "        1.54303374e-01, 2.44102071e-01, 8.96573131e-01, 6.32513383e-01,\n",
       "        2.62928263e-01, 2.37220321e-01, 6.63469018e-01, 9.04934148e-01],\n",
       "       [7.59117560e-01, 7.46643516e-01, 7.36565677e-01, 1.09723420e-01,\n",
       "        7.06831461e-01, 6.82827030e-01, 3.52778076e-01, 9.38320040e-01,\n",
       "        3.90435419e-01, 7.19439634e-01, 9.45415123e-02, 8.62403196e-01,\n",
       "        2.07621768e-01, 8.08132726e-02, 5.92807404e-01, 3.09590911e-01,\n",
       "        6.17951661e-01, 6.95875021e-01, 2.62266407e-01, 5.17543146e-01,\n",
       "        3.71041322e-01, 4.92558561e-01, 3.73883401e-01, 6.86919800e-01,\n",
       "        3.92014735e-01, 2.75545719e-01, 9.64206251e-01, 3.94820337e-02],\n",
       "       [3.83882925e-01, 7.80081774e-01, 1.92218246e-02, 4.69375407e-01,\n",
       "        2.13429012e-01, 1.70504360e-01, 8.72330791e-01, 3.03342673e-01,\n",
       "        2.52610956e-01, 7.05220643e-01, 5.44120490e-01, 8.16432438e-01,\n",
       "        6.79486647e-01, 8.31528855e-02, 6.85234610e-01, 4.08954963e-01,\n",
       "        3.31391389e-01, 9.45489777e-01, 6.79507277e-01, 9.41672409e-01,\n",
       "        8.53774279e-01, 5.69439755e-01, 2.81312434e-01, 6.53361597e-03,\n",
       "        1.33073596e-02, 2.61084146e-01, 2.74767339e-01, 9.20019370e-01],\n",
       "       [8.55442213e-01, 6.45498184e-01, 9.11702482e-01, 9.77131963e-01,\n",
       "        4.80387700e-01, 9.66648008e-01, 9.63717525e-01, 4.67321855e-01,\n",
       "        1.58219021e-01, 9.38538518e-01, 4.13922635e-01, 5.69569882e-01,\n",
       "        8.09262130e-01, 2.78668982e-01, 2.77684898e-01, 4.40414691e-01,\n",
       "        7.49184030e-02, 5.71019065e-01, 8.83660719e-01, 8.74858919e-01,\n",
       "        1.89932751e-01, 6.85266149e-01, 3.44882161e-01, 6.89657034e-02,\n",
       "        9.62017207e-01, 1.28832738e-01, 4.26183747e-01, 2.81114463e-01],\n",
       "       [8.41446645e-01, 7.19197385e-01, 1.86564255e-01, 3.95941836e-01,\n",
       "        5.30408979e-01, 6.06911774e-01, 6.30929376e-01, 7.17422372e-01,\n",
       "        7.92827541e-01, 4.43395897e-02, 9.65613018e-01, 9.30377036e-01,\n",
       "        4.72533537e-01, 2.08507538e-01, 5.62820499e-01, 1.09467603e-01,\n",
       "        6.66575510e-01, 9.58918240e-02, 9.93715244e-01, 9.21827058e-01,\n",
       "        1.20335062e-01, 4.41615861e-01, 9.33145672e-02, 9.15690365e-01,\n",
       "        9.53508743e-01, 9.92093726e-01, 9.19365596e-01, 6.50975369e-01],\n",
       "       [9.88168489e-01, 6.21111893e-01, 2.72299480e-01, 2.88120403e-01,\n",
       "        4.82584875e-01, 7.31131863e-01, 8.51670302e-01, 6.15717568e-01,\n",
       "        8.79003217e-01, 3.54460867e-01, 4.96623317e-01, 6.28001185e-01,\n",
       "        9.88955705e-01, 6.93695023e-01, 2.98416033e-01, 9.04827914e-01,\n",
       "        1.19389505e-01, 7.53732412e-01, 7.28932651e-01, 1.73941084e-01,\n",
       "        6.59732058e-01, 6.50945335e-01, 7.49158862e-01, 5.37302197e-03,\n",
       "        9.41520051e-01, 2.24746601e-01, 8.49219283e-01, 4.27392764e-01],\n",
       "       [9.31145986e-01, 7.81393404e-01, 7.13072579e-01, 5.14637997e-01,\n",
       "        8.62150638e-01, 9.48120682e-01, 9.73826503e-01, 6.09261705e-01,\n",
       "        9.98475908e-01, 1.94590089e-01, 5.43509193e-01, 7.15169967e-01,\n",
       "        7.86731291e-01, 7.68962636e-01, 5.36639211e-01, 6.47614712e-01,\n",
       "        7.90048225e-01, 6.94074542e-01, 2.35557265e-01, 8.75336931e-02,\n",
       "        5.23892949e-01, 3.28859527e-01, 4.07117133e-01, 9.33545384e-01,\n",
       "        2.16554748e-02, 7.67368953e-01, 5.28022337e-02, 8.29706101e-01],\n",
       "       [8.07079844e-01, 8.87819428e-01, 8.37430198e-01, 9.22993267e-01,\n",
       "        4.70703500e-01, 3.26849583e-01, 4.12755107e-01, 4.83531327e-01,\n",
       "        3.79114559e-01, 6.37649355e-01, 9.86304424e-01, 6.59296071e-01,\n",
       "        3.43150400e-02, 4.47014919e-01, 7.22027205e-01, 1.10125442e-01,\n",
       "        4.41193762e-01, 4.66169685e-01, 7.15686938e-01, 9.30420983e-01,\n",
       "        8.48270573e-01, 4.94339441e-01, 7.26259425e-01, 7.90612218e-01,\n",
       "        8.74052077e-01, 5.74807375e-01, 2.36131249e-01, 1.46195097e-02],\n",
       "       [8.45946981e-01, 1.97458250e-01, 2.05778153e-01, 7.06956905e-02,\n",
       "        4.47002610e-01, 6.77691389e-01, 6.73374757e-01, 8.58163702e-01,\n",
       "        4.28918999e-02, 6.77133456e-01, 6.59979429e-01, 5.87256924e-01,\n",
       "        2.42691058e-01, 3.18250314e-01, 4.44764718e-01, 9.32992103e-01,\n",
       "        6.59756884e-01, 1.10023778e-01, 4.78275528e-01, 3.69175233e-01,\n",
       "        5.20907913e-01, 5.31393301e-01, 3.56393881e-01, 1.31889408e-02,\n",
       "        9.86647909e-01, 8.19657550e-01, 9.22616772e-01, 6.75403184e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1번째 데이터의 1번째 채널 데이터\n",
    "x[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4f1845b-05b2-4dc6-aeed-ded3af1fd80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# im2col 메서드 구현\n",
    "def im2col(input_data, filter_h, filter_w, stride=1, padding=0):\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*padding - filter_h) // stride + 1\n",
    "    out_w = (W + 2*padding - filter_w) // stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (padding,padding), (padding, padding)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "    \n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape((N*out_h*out_w), -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9205c075-2263-4efe-a7ea-4c51ad641d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "003f6d99-bd51-4127-b1be-12212bb9df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 중간 데이터（backward 시 사용）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        # 가중치와 편향 매개변수의 기울기\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0635dc8-92e7-475b-8bc7-1f9eaf82eea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[17.61914232 17.91512701 18.87884767]\n",
      "   [18.39020687 17.65290026 17.44023401]\n",
      "   [19.66059368 19.31421215 19.6244057 ]]\n",
      "\n",
      "  [[18.9210165  18.08440186 19.821915  ]\n",
      "   [18.72054979 18.48306214 17.09882611]\n",
      "   [20.03111138 19.23498598 20.30227808]]\n",
      "\n",
      "  [[17.56176184 19.78505364 18.54251547]\n",
      "   [19.41983772 18.93238933 18.32658117]\n",
      "   [19.59383189 19.84856938 20.20265532]]\n",
      "\n",
      "  [[19.29639802 18.66616515 19.08660918]\n",
      "   [19.77950971 17.61551438 19.5389967 ]\n",
      "   [20.70189986 21.15884629 20.61707428]]\n",
      "\n",
      "  [[19.8348077  19.97959859 19.58518707]\n",
      "   [20.90873444 18.75814678 19.15578905]\n",
      "   [20.877239   19.42850531 22.27438747]]\n",
      "\n",
      "  [[21.24296481 21.31788108 21.46622479]\n",
      "   [21.78072279 19.14766765 19.85840817]\n",
      "   [22.73949401 21.83634335 21.95365684]]\n",
      "\n",
      "  [[17.63729349 16.91924691 17.6773402 ]\n",
      "   [17.26436838 16.67645728 17.77111348]\n",
      "   [18.15124132 16.94333785 18.88322319]]\n",
      "\n",
      "  [[19.14891539 18.6354312  19.17603155]\n",
      "   [20.64081076 18.57011631 19.16607945]\n",
      "   [19.96556202 20.01560812 18.94940242]]\n",
      "\n",
      "  [[19.13992233 19.33787123 19.83476943]\n",
      "   [19.80554767 17.93899965 18.31266031]\n",
      "   [20.8267213  20.0744729  20.20692269]]\n",
      "\n",
      "  [[18.5906987  17.53155666 19.67660879]\n",
      "   [17.9744416  16.45374501 17.60802914]\n",
      "   [19.8226343  19.08997315 19.72125364]]]\n",
      "\n",
      "\n",
      " [[[20.34023896 21.54376457 20.29037818]\n",
      "   [21.06366095 20.64278391 20.52705169]\n",
      "   [19.62131422 19.12368007 20.79243983]]\n",
      "\n",
      "  [[20.71378825 20.73459655 20.26120805]\n",
      "   [22.17804536 21.34660731 22.20907371]\n",
      "   [21.39439293 20.42251485 20.43057636]]\n",
      "\n",
      "  [[20.16146149 19.98213602 21.4754225 ]\n",
      "   [21.09483298 21.09073454 20.3891139 ]\n",
      "   [20.22263411 19.60443659 18.95004754]]\n",
      "\n",
      "  [[20.2745806  20.42812439 20.36863616]\n",
      "   [21.99632797 22.70081508 21.7997181 ]\n",
      "   [21.80023639 19.14568881 20.72713211]]\n",
      "\n",
      "  [[21.31210251 20.49655859 22.08035076]\n",
      "   [21.4152802  21.8232723  23.7433267 ]\n",
      "   [21.23408241 21.12355186 21.787118  ]]\n",
      "\n",
      "  [[22.1893327  21.66745549 22.42273358]\n",
      "   [23.09204545 22.87979623 21.87507245]\n",
      "   [23.79494688 22.46128857 21.44736016]]\n",
      "\n",
      "  [[19.06960276 18.82889762 17.70534204]\n",
      "   [18.32320998 18.63036701 19.32156066]\n",
      "   [18.78276541 18.06006211 19.24069484]]\n",
      "\n",
      "  [[20.14762279 20.56097743 20.00601334]\n",
      "   [21.31060468 20.53572339 21.67373613]\n",
      "   [19.9634123  19.69638901 21.3411258 ]]\n",
      "\n",
      "  [[21.56844677 21.05478917 21.61901155]\n",
      "   [21.52776239 20.89360444 21.73279934]\n",
      "   [20.33949362 19.80245173 21.05820618]]\n",
      "\n",
      "  [[17.63804852 19.03007385 19.18694767]\n",
      "   [20.64711997 20.62644613 19.84428444]\n",
      "   [19.67896942 19.58461894 18.48905573]]]\n",
      "\n",
      "\n",
      " [[[21.52374841 23.18873768 20.86672145]\n",
      "   [20.94630251 21.80048145 21.1956523 ]\n",
      "   [18.03756171 19.07957799 19.70008786]]\n",
      "\n",
      "  [[21.38508466 22.4249894  22.13212776]\n",
      "   [21.70561711 21.93627475 21.49944751]\n",
      "   [18.96541383 20.61402858 21.78918988]]\n",
      "\n",
      "  [[19.8582436  21.26893682 21.17039066]\n",
      "   [19.86662385 22.30724547 21.7650964 ]\n",
      "   [18.39999755 20.13401237 20.42309082]]\n",
      "\n",
      "  [[22.05272754 23.24917109 22.221573  ]\n",
      "   [20.70152142 21.46141328 20.99286961]\n",
      "   [20.8810271  22.27149648 21.51695305]]\n",
      "\n",
      "  [[22.66388224 24.01522973 22.15753844]\n",
      "   [20.54273255 23.4011589  22.02422824]\n",
      "   [19.09696465 22.19103621 21.20247457]]\n",
      "\n",
      "  [[22.86466354 25.04993633 23.12779373]\n",
      "   [22.22307365 24.40437783 25.1272118 ]\n",
      "   [21.99285511 22.26927372 23.18784897]]\n",
      "\n",
      "  [[20.30771648 20.15524996 20.11333108]\n",
      "   [19.28424315 19.15656994 21.37626089]\n",
      "   [17.02279054 19.00552551 17.93572826]]\n",
      "\n",
      "  [[21.6307867  23.05072701 22.06737277]\n",
      "   [18.50074744 22.55361357 21.44314469]\n",
      "   [20.44084669 20.06930896 20.25871066]]\n",
      "\n",
      "  [[21.44832596 22.77236449 22.45856759]\n",
      "   [19.9517083  22.0605792  21.78020263]\n",
      "   [21.16500878 21.79580729 21.91829889]]\n",
      "\n",
      "  [[20.07205209 21.42484901 21.21233447]\n",
      "   [19.90878595 21.25964289 22.54313864]\n",
      "   [20.04015704 20.82235812 18.21656106]]]\n",
      "\n",
      "\n",
      " [[[20.03233115 19.53995108 20.32737547]\n",
      "   [19.32907143 20.66152819 19.57066848]\n",
      "   [19.73611512 20.39855074 20.56565362]]\n",
      "\n",
      "  [[20.05054039 20.53520683 20.36358894]\n",
      "   [22.0179577  21.02127167 21.86418016]\n",
      "   [20.21103252 21.4851645  19.46633534]]\n",
      "\n",
      "  [[18.94766108 20.44728963 21.51550873]\n",
      "   [21.95674548 21.02426368 20.36595407]\n",
      "   [19.76924359 20.17924187 20.54634776]]\n",
      "\n",
      "  [[20.22082764 20.04716802 22.21965522]\n",
      "   [20.60213964 21.87897846 20.62858169]\n",
      "   [20.41562843 20.2383176  21.5861149 ]]\n",
      "\n",
      "  [[20.85926406 21.0877759  22.96132875]\n",
      "   [22.40902176 22.97958274 21.56433838]\n",
      "   [20.82602825 21.21764056 20.25485565]]\n",
      "\n",
      "  [[22.90761914 23.26313008 24.31012728]\n",
      "   [22.25401372 23.55477819 23.3485356 ]\n",
      "   [22.24398008 22.91979972 22.91237033]]\n",
      "\n",
      "  [[18.81163708 18.69253236 20.58812784]\n",
      "   [19.68143438 19.43310417 19.98606662]\n",
      "   [18.89769118 18.33904184 18.04224144]]\n",
      "\n",
      "  [[21.67694962 21.89198814 21.65872572]\n",
      "   [19.99019227 21.33651567 21.85402545]\n",
      "   [21.5782505  22.00358171 20.35915844]]\n",
      "\n",
      "  [[21.15779793 20.89031569 22.1507999 ]\n",
      "   [21.69627291 21.83161551 21.8635647 ]\n",
      "   [20.55152556 21.17397121 19.95516893]]\n",
      "\n",
      "  [[19.48584126 20.10043121 20.47205201]\n",
      "   [20.77154433 20.78381698 21.537779  ]\n",
      "   [19.02959462 20.13492174 18.77563379]]]\n",
      "\n",
      "\n",
      " [[[18.0316059  17.87750703 19.09311942]\n",
      "   [19.25237655 17.72558873 19.45957083]\n",
      "   [17.19424825 17.28466505 17.60793002]]\n",
      "\n",
      "  [[17.7911392  18.37327008 19.95916727]\n",
      "   [18.81970936 18.76306885 20.29032819]\n",
      "   [18.59212417 17.83373058 19.24110663]]\n",
      "\n",
      "  [[16.79967164 17.26394183 18.36655176]\n",
      "   [18.43971685 18.78123706 18.64009794]\n",
      "   [18.46929432 17.78371549 17.55165381]]\n",
      "\n",
      "  [[19.09696021 18.51983984 20.68649417]\n",
      "   [19.47834877 17.00052932 18.87451948]\n",
      "   [20.27006285 18.16984384 18.74441979]]\n",
      "\n",
      "  [[19.64203991 20.92071916 20.18555626]\n",
      "   [19.28928383 18.96069748 20.43340854]\n",
      "   [19.42388896 18.57738608 18.16904055]]\n",
      "\n",
      "  [[20.01247209 21.24608778 21.63801322]\n",
      "   [21.92235892 20.03411752 21.65929214]\n",
      "   [22.30946185 20.41501852 19.22299874]]\n",
      "\n",
      "  [[18.17362437 17.46218306 17.98841386]\n",
      "   [18.07694202 17.34912944 17.98144581]\n",
      "   [16.00775571 16.41883409 16.75428248]]\n",
      "\n",
      "  [[18.55385163 18.41624115 18.7696302 ]\n",
      "   [19.36152072 19.33229979 17.78286439]\n",
      "   [19.27361246 19.58664021 18.22019283]]\n",
      "\n",
      "  [[19.41864797 19.32509734 20.52366057]\n",
      "   [19.4209115  19.67032256 18.76471874]\n",
      "   [18.70573198 19.4573169  18.58886546]]\n",
      "\n",
      "  [[18.16239057 16.61737288 17.63852796]\n",
      "   [17.99073966 18.67975042 17.50572036]\n",
      "   [18.46361674 17.49304928 17.63310957]]]\n",
      "\n",
      "\n",
      " [[[21.25231176 20.47044462 20.5601753 ]\n",
      "   [21.36582082 20.33432038 20.1942799 ]\n",
      "   [20.05038903 17.57466032 18.9932317 ]]\n",
      "\n",
      "  [[21.97212985 21.54780645 23.24028152]\n",
      "   [23.57473251 20.39586724 20.68080217]\n",
      "   [20.2811652  19.85654834 20.33735491]]\n",
      "\n",
      "  [[21.83675605 21.30279894 20.17959475]\n",
      "   [21.8291692  19.61865003 19.87655391]\n",
      "   [20.5934452  19.34461856 19.86749384]]\n",
      "\n",
      "  [[22.19645481 21.47193601 20.94389013]\n",
      "   [20.37538389 20.90181929 19.18413087]\n",
      "   [21.93358609 20.75558079 21.25447048]]\n",
      "\n",
      "  [[24.59319062 21.64716384 22.89664957]\n",
      "   [23.28210367 19.79185842 20.53169298]\n",
      "   [21.91111802 21.7397813  21.51907881]]\n",
      "\n",
      "  [[25.23922067 24.6188584  21.78502615]\n",
      "   [23.6358008  23.8893139  23.64178396]\n",
      "   [21.97022727 22.68384983 22.24956615]]\n",
      "\n",
      "  [[20.33095992 19.81799193 20.12245198]\n",
      "   [18.53726059 18.60345374 19.32586523]\n",
      "   [18.02794285 17.74384351 17.99033646]]\n",
      "\n",
      "  [[22.92906635 21.56163918 21.7936563 ]\n",
      "   [22.56826006 20.9392007  20.26127538]\n",
      "   [20.92183739 19.87874463 20.21369306]]\n",
      "\n",
      "  [[24.00834643 20.7408318  21.4958955 ]\n",
      "   [23.20497731 19.96352394 21.57801731]\n",
      "   [21.05027341 20.23012825 21.79288764]]\n",
      "\n",
      "  [[21.66325611 19.92851598 20.19113115]\n",
      "   [20.24599293 20.29696597 19.62240177]\n",
      "   [19.01826033 18.80732297 18.53643076]]]\n",
      "\n",
      "\n",
      " [[[18.71931388 19.07221809 17.55132693]\n",
      "   [18.66833224 17.27743804 19.04904925]\n",
      "   [18.27069859 20.55961022 20.51962308]]\n",
      "\n",
      "  [[18.07844478 19.36210633 18.14778739]\n",
      "   [17.86973369 19.30543878 17.75178983]\n",
      "   [19.69232901 19.63294077 20.30154536]]\n",
      "\n",
      "  [[17.57541209 19.4117079  18.5298356 ]\n",
      "   [18.15184724 18.9980869  18.06851217]\n",
      "   [19.20672073 19.11979414 18.91056184]]\n",
      "\n",
      "  [[17.19390935 18.21036819 18.56261894]\n",
      "   [19.6880374  19.16454638 19.33857799]\n",
      "   [19.51161524 19.71122898 20.07818523]]\n",
      "\n",
      "  [[19.38536945 19.69621915 18.83649919]\n",
      "   [18.79112727 19.14817125 20.12375914]\n",
      "   [19.58285554 22.16632185 21.51664888]]\n",
      "\n",
      "  [[19.81570854 21.18083389 20.43199968]\n",
      "   [22.46053933 20.37187395 19.89255731]\n",
      "   [20.13827703 21.72289242 21.99806045]]\n",
      "\n",
      "  [[16.97105468 17.45859802 15.99437613]\n",
      "   [17.59182931 16.01277253 16.53272516]\n",
      "   [16.86545026 16.88089939 19.14105682]]\n",
      "\n",
      "  [[16.93003315 18.72783405 17.19722021]\n",
      "   [19.46662302 18.12854684 17.90705039]\n",
      "   [18.66697413 19.41249722 21.69239902]]\n",
      "\n",
      "  [[17.39811151 19.52620581 18.67261077]\n",
      "   [18.83450034 19.76823681 18.70908819]\n",
      "   [20.47568554 20.24842996 19.52175086]]\n",
      "\n",
      "  [[17.55799055 18.96090269 17.81061362]\n",
      "   [16.8381815  17.60046595 18.29834222]\n",
      "   [19.85036877 18.55188837 19.2601687 ]]]\n",
      "\n",
      "\n",
      " [[[19.00136422 17.88822364 18.90733925]\n",
      "   [20.69074844 20.85720817 22.3764262 ]\n",
      "   [21.46401083 23.0702918  23.19825605]]\n",
      "\n",
      "  [[20.40680382 19.16777921 19.64496619]\n",
      "   [19.90941331 21.17359743 21.70749968]\n",
      "   [22.96962441 23.20623786 23.88290565]]\n",
      "\n",
      "  [[18.06128162 18.52578614 18.60649296]\n",
      "   [19.46971031 21.56472177 21.59072941]\n",
      "   [23.06368784 21.26123061 22.5773203 ]]\n",
      "\n",
      "  [[20.1340006  18.3700267  20.26171262]\n",
      "   [20.12138552 20.79038039 22.39353043]\n",
      "   [24.41520199 22.88580668 24.40308505]]\n",
      "\n",
      "  [[19.52711167 19.38531754 21.00726586]\n",
      "   [21.26797579 23.95314238 23.49719246]\n",
      "   [24.95873575 24.81934474 22.83778163]]\n",
      "\n",
      "  [[20.06329551 19.24619224 20.7538182 ]\n",
      "   [22.53337443 23.07464215 25.42439515]\n",
      "   [23.86131915 24.15494497 25.41880979]]\n",
      "\n",
      "  [[17.07269038 16.35537859 17.75125658]\n",
      "   [17.97023929 20.37585587 22.10969328]\n",
      "   [20.5410651  20.98208076 21.20584169]]\n",
      "\n",
      "  [[19.09015772 17.89537722 19.92853095]\n",
      "   [22.37521313 21.21078754 23.11496733]\n",
      "   [21.3065847  23.92079365 23.56092608]]\n",
      "\n",
      "  [[19.07329912 18.75657209 19.39587652]\n",
      "   [21.67667659 21.36432285 23.43996356]\n",
      "   [22.89129219 22.66042619 23.53153994]]\n",
      "\n",
      "  [[17.45822484 18.50561189 19.85410074]\n",
      "   [19.28331043 20.80293573 19.5793667 ]\n",
      "   [20.79463369 20.94530534 23.12990551]]]\n",
      "\n",
      "\n",
      " [[[19.44791666 20.65894763 19.84077423]\n",
      "   [16.96972702 17.47183186 18.74969766]\n",
      "   [20.0389993  18.24585201 19.96883832]]\n",
      "\n",
      "  [[19.00557864 19.98362664 21.95164294]\n",
      "   [18.29928164 19.2207709  18.45363983]\n",
      "   [18.67319749 18.26176144 20.389449  ]]\n",
      "\n",
      "  [[18.44070236 17.43167523 20.34169302]\n",
      "   [17.56544625 17.04752862 19.00812513]\n",
      "   [18.63769393 19.59357142 19.06326494]]\n",
      "\n",
      "  [[19.73219059 20.79742744 19.22141615]\n",
      "   [19.7790609  18.7375476  19.6242173 ]\n",
      "   [18.84436673 19.44973341 21.38908531]]\n",
      "\n",
      "  [[19.84337093 20.7051711  21.63823035]\n",
      "   [20.17278739 17.30757442 21.20175263]\n",
      "   [19.43085881 21.97332682 21.07102485]]\n",
      "\n",
      "  [[22.43930692 22.2557631  22.23365526]\n",
      "   [20.42806175 20.80788325 22.11637048]\n",
      "   [22.10021439 22.0080148  22.49067027]]\n",
      "\n",
      "  [[17.0221581  19.14305661 20.43244967]\n",
      "   [17.79964563 17.70492931 17.38867209]\n",
      "   [18.50393023 18.07293133 18.96625765]]\n",
      "\n",
      "  [[19.82090471 19.02445929 21.06987997]\n",
      "   [19.0151695  19.03411785 19.83634068]\n",
      "   [20.3201629  19.2348634  20.47745985]]\n",
      "\n",
      "  [[20.47193226 20.52729073 20.66769715]\n",
      "   [18.43466119 19.88753146 20.93501734]\n",
      "   [19.11644997 20.26707371 20.97378307]]\n",
      "\n",
      "  [[19.19868915 18.90832257 19.76946418]\n",
      "   [18.23954053 18.29016069 18.38714433]\n",
      "   [19.01725601 18.67354967 19.31853961]]]\n",
      "\n",
      "\n",
      " [[[19.15837181 20.23598185 17.97668531]\n",
      "   [18.39726326 18.81331962 18.61267775]\n",
      "   [19.70844488 18.61506377 18.50396669]]\n",
      "\n",
      "  [[21.30849587 19.99091336 19.12795964]\n",
      "   [19.78795648 20.29513453 18.43847411]\n",
      "   [18.98183802 19.62970744 20.05214501]]\n",
      "\n",
      "  [[20.61297098 18.96747612 18.52814942]\n",
      "   [19.96210808 19.95672209 18.13195117]\n",
      "   [18.38309246 17.78498461 18.30811669]]\n",
      "\n",
      "  [[21.01312283 20.3106681  19.25888443]\n",
      "   [19.81881917 20.67528604 18.28407347]\n",
      "   [19.70359118 19.32179663 20.12459268]]\n",
      "\n",
      "  [[21.41438323 20.66349606 19.06987337]\n",
      "   [19.72932368 20.51108778 20.25259729]\n",
      "   [19.9465628  20.68837602 18.73102609]]\n",
      "\n",
      "  [[21.85598495 22.06859373 22.06017949]\n",
      "   [22.03367858 22.25929389 21.12483686]\n",
      "   [20.24675298 21.15111978 21.25983032]]\n",
      "\n",
      "  [[18.94372139 19.17713433 17.97741682]\n",
      "   [18.55649822 17.89089563 17.28664378]\n",
      "   [17.57370423 16.63279169 16.31836053]]\n",
      "\n",
      "  [[20.58744387 21.97174493 19.97468618]\n",
      "   [17.84909291 19.91914004 19.49303922]\n",
      "   [17.56475071 19.3119331  19.42964177]]\n",
      "\n",
      "  [[19.68390911 19.56820985 19.43119339]\n",
      "   [20.22129302 21.9671913  20.71791708]\n",
      "   [18.87527871 20.99892578 19.16608112]]\n",
      "\n",
      "  [[19.5438261  18.84930256 19.11318411]\n",
      "   [19.11895316 19.00409485 19.01435354]\n",
      "   [18.63854785 17.8120591  17.33690778]]]]\n",
      "[[[[ 100.62992527  191.67975284  318.70383432 ...  351.00873098\n",
      "     225.84520997  121.38271822]\n",
      "   [ 181.37450041  355.11535526  576.80568527 ...  645.1130931\n",
      "     420.77421925  203.19154728]\n",
      "   [ 272.44530969  539.01105097  881.6539496  ...  952.51145055\n",
      "     608.79442315  309.24858298]\n",
      "   ...\n",
      "   [ 291.58260669  602.50136759  890.03697648 ...  872.3330811\n",
      "     579.26718919  276.72857264]\n",
      "   [ 208.97867327  436.01738099  612.06219232 ...  580.88583956\n",
      "     401.41459954  181.07795531]\n",
      "   [  83.57453469  190.752952    273.70820088 ...  291.23892793\n",
      "     208.85039865   95.79625877]]\n",
      "\n",
      "  [[  95.43169283  178.87092213  256.1536917  ...  290.501935\n",
      "     215.67302639  119.36372975]\n",
      "   [ 225.84176917  392.43337903  548.65033791 ...  569.82654142\n",
      "     406.75670138  214.27544542]\n",
      "   [ 321.75586191  596.71017109  862.53121994 ...  902.27273106\n",
      "     623.084565    328.22965264]\n",
      "   ...\n",
      "   [ 248.51773372  513.13588355  806.80184187 ...  880.76745667\n",
      "     586.11881896  289.66000673]\n",
      "   [ 160.29344613  317.53638529  504.52560052 ...  566.6046979\n",
      "     375.48569511  184.43729517]\n",
      "   [  77.82027855  155.66001089  250.71146633 ...  292.95144775\n",
      "     198.74211835  100.06161303]]\n",
      "\n",
      "  [[  97.00284659  143.49801339  266.89672755 ...  347.13763633\n",
      "     225.29311516  127.46721354]\n",
      "   [ 193.28493336  324.82665562  567.04910155 ...  665.98309464\n",
      "     421.61720084  212.18553651]\n",
      "   [ 324.56178118  581.37671892  937.45360393 ...  968.61811097\n",
      "     613.52747746  310.60397542]\n",
      "   ...\n",
      "   [ 300.5306958   618.84464318  920.26837595 ...  920.58362855\n",
      "     618.53454981  322.72907246]\n",
      "   [ 171.18051141  365.66628489  556.00154593 ...  644.30280268\n",
      "     442.1126733   232.6905938 ]\n",
      "   [  94.34233885  187.77343768  283.4040885  ...  311.97765949\n",
      "     214.30035798  121.84044356]]]\n",
      "\n",
      "\n",
      " [[[ 110.29427461  207.28214561  343.90761426 ...  375.18836649\n",
      "     240.62598033  128.67005878]\n",
      "   [ 199.43474791  395.36820422  641.50577876 ...  714.28658731\n",
      "     469.95918462  225.37910842]\n",
      "   [ 285.80134118  573.95818483  940.15669948 ... 1022.64560553\n",
      "     659.35726536  324.33314205]\n",
      "   ...\n",
      "   [ 311.61326342  650.49904453  961.23661081 ...  939.25726253\n",
      "     623.21277386  297.12935603]\n",
      "   [ 218.91697545  462.48216325  653.58218732 ...  622.24896705\n",
      "     431.0132607   197.01799172]\n",
      "   [  85.28881912  194.18423009  278.14680558 ...  294.0024424\n",
      "     213.01047761   97.53996225]]\n",
      "\n",
      "  [[ 102.62713884  192.23291565  271.69646888 ...  311.7419996\n",
      "     231.4399052   125.87783994]\n",
      "   [ 245.88547394  429.4558765   608.54895566 ...  632.29999715\n",
      "     456.15546343  239.8712727 ]\n",
      "   [ 343.21440066  642.55396418  937.08594094 ...  963.51590202\n",
      "     676.98114732  349.53519893]\n",
      "   ...\n",
      "   [ 263.94716598  552.11941761  864.94012194 ...  942.60974819\n",
      "     626.1214466   308.53299932]\n",
      "   [ 168.77746395  337.49144408  540.71397901 ...  609.96029528\n",
      "     405.92779064  200.90370569]\n",
      "   [  79.79200368  159.41653125  255.29140252 ...  294.39308064\n",
      "     198.92545718  101.41961771]]\n",
      "\n",
      "  [[ 104.66747464  153.02701666  288.49399788 ...  371.80832698\n",
      "     238.75130106  134.49311016]\n",
      "   [ 208.22162325  359.37386054  623.63963683 ...  734.96561559\n",
      "     472.7359373   234.41574681]\n",
      "   [ 345.7935255   628.03649377 1007.32441308 ... 1042.28577144\n",
      "     663.71163302  329.58164606]\n",
      "   ...\n",
      "   [ 315.06255286  656.77138141  978.87306727 ... 1001.13703385\n",
      "     674.1451096   351.1590021 ]\n",
      "   [ 181.92955964  390.15885804  597.955998   ...  689.8061198\n",
      "     476.51800534  250.81768576]\n",
      "   [  97.25725918  191.99204771  284.32436863 ...  314.94290294\n",
      "     217.91106679  122.72196983]]]\n",
      "\n",
      "\n",
      " [[[ 113.85250143  223.47653931  366.69937799 ...  402.24176082\n",
      "     261.43675438  135.60591505]\n",
      "   [ 198.39096517  408.38304873  663.82881154 ...  745.96201986\n",
      "     499.58850414  237.40029699]\n",
      "   [ 282.62025624  588.67947205  968.02574308 ... 1049.61761004\n",
      "     689.9135347   338.24350644]\n",
      "   ...\n",
      "   [ 307.93005211  665.8124461   984.96341708 ...  970.02400613\n",
      "     657.94182973  306.56924222]\n",
      "   [ 209.62747614  458.76132285  654.42149749 ...  626.34803803\n",
      "     446.99871325  200.18524179]\n",
      "   [  79.27606792  193.37669173  277.34062694 ...  297.8394133\n",
      "     217.98311655   96.71316237]]\n",
      "\n",
      "  [[ 107.49178912  208.79830072  293.79561846 ...  334.69136434\n",
      "     251.90887717  133.48784046]\n",
      "   [ 245.59442049  450.22681849  635.37781567 ...  659.96773893\n",
      "     484.0344884   250.5164092 ]\n",
      "   [ 333.98796085  663.67735422  960.0333821  ...  981.40644117\n",
      "     704.1978756   357.41630457]\n",
      "   ...\n",
      "   [ 258.94404376  561.83705744  881.8565012  ...  972.33467858\n",
      "     663.12315644  318.9438875 ]\n",
      "   [ 162.14398637  337.9619319   541.44014913 ...  611.15655021\n",
      "     422.32463247  202.46418558]\n",
      "   [  73.96077523  156.08542382  252.99388555 ...  300.19821212\n",
      "     205.38194163  101.27281539]]\n",
      "\n",
      "  [[ 109.23080697  168.43771393  305.69997091 ...  398.33844048\n",
      "     261.50831676  143.0143554 ]\n",
      "   [ 207.28143473  377.47412856  646.14577493 ...  765.6153876\n",
      "     500.80755074  247.08007684]\n",
      "   [ 338.67864001  654.09959672 1036.34153663 ... 1065.7947131\n",
      "     694.10874176  338.73819814]\n",
      "   ...\n",
      "   [ 309.87246583  671.70908444 1007.37219912 ... 1018.63669228\n",
      "     704.64755948  359.70307338]\n",
      "   [ 172.09704332  387.8112479   603.43246448 ...  691.29155915\n",
      "     495.84745114  254.67238391]\n",
      "   [  91.33231133  189.4274243   285.51359986 ...  310.039208\n",
      "     223.45028567  125.16084005]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 102.65188286  190.06810086  318.66796998 ...  348.37308294\n",
      "     222.84297659  122.5570187 ]\n",
      "   [ 186.59475711  377.21905583  623.92594382 ...  696.58160136\n",
      "     466.98200249  229.36800752]\n",
      "   [ 288.85860246  581.19370209  967.96217091 ... 1058.2715878\n",
      "     685.54400419  348.44528909]\n",
      "   ...\n",
      "   [ 308.46478811  652.9873092   988.70943896 ...  954.91317375\n",
      "     643.89936102  316.36848283]\n",
      "   [ 227.9395133   491.56900385  704.5518158  ...  668.82865552\n",
      "     475.57586994  217.29671454]\n",
      "   [  95.165334    219.11747062  313.03334448 ...  332.0004942\n",
      "     244.73983245  108.97013358]]\n",
      "\n",
      "  [[  96.06692293  174.74158795  253.64585678 ...  291.12998614\n",
      "     214.55354159  120.72050663]\n",
      "   [ 232.41454106  409.54966673  592.22332123 ...  607.71673043\n",
      "     447.86902021  242.51177485]\n",
      "   [ 340.62837853  647.74567599  954.52032895 ...  983.680285\n",
      "     701.16012768  367.1320536 ]\n",
      "   ...\n",
      "   [ 265.22492172  560.63491356  887.18742387 ...  965.28706313\n",
      "     652.94746142  328.12558474]\n",
      "   [ 174.29392855  356.8469935   577.69311903 ...  652.31669739\n",
      "     447.31308937  218.28133314]\n",
      "   [  88.08049683  181.5835721   285.95161006 ...  330.68324138\n",
      "     230.01656518  115.73483278]]\n",
      "\n",
      "  [[  98.07925039  140.81854839  268.33898925 ...  346.12043176\n",
      "     222.60619799  128.91476363]\n",
      "   [ 196.18493572  344.69362234  603.10471703 ...  716.74764225\n",
      "     466.88519658  239.98181875]\n",
      "   [ 346.00954876  619.38526801 1014.77354858 ... 1072.05571725\n",
      "     689.63855114  350.29038583]\n",
      "   ...\n",
      "   [ 318.44249682  670.55478797 1013.50627974 ... 1014.78958233\n",
      "     694.35321448  360.49699753]\n",
      "   [ 184.6200273   408.81969944  640.90690787 ...  738.16053927\n",
      "     521.01535249  276.44998235]\n",
      "   [ 105.38496777  214.43430198  321.8444023  ...  355.80916192\n",
      "     250.09158505  139.14098231]]]\n",
      "\n",
      "\n",
      " [[[ 105.23098297  200.92339312  337.00238151 ...  369.16825599\n",
      "     239.44857912  130.37738482]\n",
      "   [ 178.07118766  361.47988009  595.12739283 ...  671.57060039\n",
      "     445.74440516  215.79845462]\n",
      "   [ 267.42222161  539.57154774  889.56464304 ...  975.65468\n",
      "     631.75372517  318.798642  ]\n",
      "   ...\n",
      "   [ 284.85658916  603.45586981  907.10566573 ...  888.92091791\n",
      "     601.08497047  292.35914335]\n",
      "   [ 202.30036872  426.64272606  612.32525409 ...  585.27468715\n",
      "     408.73969022  188.37501693]\n",
      "   [  80.88758706  188.07307177  268.84502835 ...  288.41822694\n",
      "     213.11925148   96.49879169]]\n",
      "\n",
      "  [[  98.59501508  186.93486753  268.3843207  ...  303.91689921\n",
      "     230.54137329  127.94542873]\n",
      "   [ 226.17825704  400.49690556  574.76675117 ...  588.95163966\n",
      "     428.6610684   226.97616286]\n",
      "   [ 313.77794614  601.34414597  885.0923518  ...  908.51757768\n",
      "     643.80002114  341.99556195]\n",
      "   ...\n",
      "   [ 242.22034698  514.66596174  819.89424497 ...  902.94534683\n",
      "     603.70478981  300.1860584 ]\n",
      "   [ 154.09594792  309.92195681  498.59703996 ...  571.64939923\n",
      "     386.01542018  192.17173348]\n",
      "   [  75.91606492  152.48119469  246.49148324 ...  288.05667847\n",
      "     199.4087943   101.28415364]]\n",
      "\n",
      "  [[  99.79284164  148.88301304  280.67823282 ...  366.35769293\n",
      "     238.92950248  135.62475543]\n",
      "   [ 192.59914821  329.17934189  583.35741374 ...  692.60119214\n",
      "     446.0225494   224.8496993 ]\n",
      "   [ 318.85869252  593.79550274  955.01228695 ...  985.6326553\n",
      "     639.86373878  325.25923706]\n",
      "   ...\n",
      "   [ 293.68036568  617.83877191  935.68729394 ...  944.63845472\n",
      "     641.33344775  338.00454001]\n",
      "   [ 164.7318609   359.1305226   553.85639624 ...  638.36276815\n",
      "     449.56049872  240.57792917]\n",
      "   [  90.56350256  182.39797503  281.00896208 ...  303.38526878\n",
      "     215.77768439  121.93274337]]]\n",
      "\n",
      "\n",
      " [[[ 109.37619948  203.90458     333.4397119  ...  367.90376667\n",
      "     232.70861642  120.89456593]\n",
      "   [ 189.47332429  380.94715412  603.55155545 ...  678.5234958\n",
      "     443.71023205  207.14180905]\n",
      "   [ 272.40825761  554.8601357   893.63452107 ...  966.00320888\n",
      "     619.49905256  302.66648343]\n",
      "   ...\n",
      "   [ 291.36695146  620.37910063  905.11716156 ...  886.57443403\n",
      "     592.30242581  275.13115573]\n",
      "   [ 200.34978752  429.13423793  606.72577896 ...  582.77688642\n",
      "     404.75055183  179.54636826]\n",
      "   [  79.99047281  182.93547615  257.84218239 ...  277.215799\n",
      "     200.99508454   88.27129703]]\n",
      "\n",
      "  [[ 102.70846321  191.97743296  268.52139683 ...  306.00228477\n",
      "     223.17610436  118.23036584]\n",
      "   [ 236.2802086   417.3644727   574.51680424 ...  600.13583582\n",
      "     429.38652807  218.0045236 ]\n",
      "   [ 318.97231427  617.71042619  878.07809473 ...  906.35961165\n",
      "     635.84034894  321.14004671]\n",
      "   ...\n",
      "   [ 247.33877326  530.11651022  815.51698173 ...  888.63277943\n",
      "     594.83952503  285.11758659]\n",
      "   [ 154.03398942  316.8937096   500.38597074 ...  567.02595837\n",
      "     383.28727065  182.52995686]\n",
      "   [  74.00009372  150.06501381  235.44649012 ...  277.1992324\n",
      "     189.39270368   93.31266192]]\n",
      "\n",
      "  [[ 106.14540132  152.40939502  279.75426798 ...  363.84836349\n",
      "     232.77277816  127.64580772]\n",
      "   [ 199.30179102  348.49307643  589.96695803 ...  695.9516599\n",
      "     447.61846797  216.17650988]\n",
      "   [ 326.11282497  605.84727377  954.1180378  ...  978.44701308\n",
      "     626.00840927  304.74689007]\n",
      "   ...\n",
      "   [ 299.42125389  626.99798867  924.84109009 ...  942.17551993\n",
      "     633.29094377  317.76281287]\n",
      "   [ 165.64683653  364.91519942  557.90185041 ...  640.51473067\n",
      "     446.79941588  228.11281974]\n",
      "   [  87.71887788  178.86131413  269.65038216 ...  292.69714254\n",
      "     208.32448549  113.93844245]]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(10, 3, 7, 7)\n",
    "w = np.random.rand(10, 3, 5,5)\n",
    "b = np.array([1])\n",
    "\n",
    "conv = Convolution(w,b)\n",
    "\n",
    "fw = conv.forward(x)\n",
    "print(fw)\n",
    "\n",
    "bw = conv.backward(fw)\n",
    "print(bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "814f102c-d446-466e-b587-458a03778d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "565e38fc-6a52-4ade-aaba-10081273d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\"\"\"\n",
    "input_dim: 입력 데이터의 차원 (채널 수, 높이, 너비)\n",
    "conv_param: {\n",
    "filter_num: 필터 개수\n",
    "filter_size: 필터 크기 (nXn)\n",
    "pad: 패딩 크기\n",
    "stride: 스트라이드 크기\n",
    "hidden_size: 은닉층 뉴런 개수\n",
    "output_size: 출력층 뉴런 개수\n",
    "weight_init_std: 초기화 때의 가중치 표준편차? 초깃값?\n",
    "}\n",
    "\"\"\"\n",
    "class SimpleConvNet:\n",
    "    \n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        # 합성곱 출력 크기\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        # 풀링 출력 크기\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        # 합성곱 가중치\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        # 합성곱 편향\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        # 풀링 가중치\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        # 풀링 편향\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        # 은닉층 가중치 \n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        # 은닉층 편향\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        # ReLU 활성화 함수 계층\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        # pooling 계층(2X2 2칸 간격)\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        # 입력 값과 가중치, 편향 Affine 계층\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        # ReLU 활성화 함수 계층\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        # 입력 값과 가중치, 편향 Affine 계층\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        # 소프트맥스 - 손실함수 계층\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    # 예측 메서드(순전파)\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    # 손실 메서드(SoftWithLoss 순전파)\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    # 정확도 메서드\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    # 기울기 메서드 (역전파)\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ea0d71e-b041-420a-aa1a-717bf3ec3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "391a7991-5a26-4051-89c4-d1898d9881d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.299896034287371\n",
      "=== epoch:1, train acc:0.291, test acc:0.221 ===\n",
      "train loss:2.295868928803414\n",
      "train loss:2.2932494948713553\n",
      "train loss:2.28857313634403\n",
      "train loss:2.27862232352161\n",
      "train loss:2.2667920575594906\n",
      "train loss:2.247739727198871\n",
      "train loss:2.2408436867811408\n",
      "train loss:2.2061369982339922\n",
      "train loss:2.1658934177469904\n",
      "train loss:2.1562520752108374\n",
      "train loss:2.1362714855433156\n",
      "train loss:2.0930986119892956\n",
      "train loss:2.0339425127341513\n",
      "train loss:1.9449581464271946\n",
      "train loss:1.860486592542263\n",
      "train loss:1.816506270101151\n",
      "train loss:1.7884317312893756\n",
      "train loss:1.7326561857336902\n",
      "train loss:1.518762688611004\n",
      "train loss:1.4999554152316599\n",
      "train loss:1.4929941109107738\n",
      "train loss:1.347505895685981\n",
      "train loss:1.2611693710543197\n",
      "train loss:1.1799189021971064\n",
      "train loss:1.3375412094776562\n",
      "train loss:0.9973022697994327\n",
      "train loss:1.0181462891377528\n",
      "train loss:1.0518695777241036\n",
      "train loss:0.9564813560746701\n",
      "train loss:0.8225111052096552\n",
      "train loss:0.9360411681314145\n",
      "train loss:0.8431182851487777\n",
      "train loss:0.763390324200714\n",
      "train loss:0.7643832888341473\n",
      "train loss:0.6778600843765454\n",
      "train loss:0.6684843048698439\n",
      "train loss:0.8906761785748594\n",
      "train loss:0.9041816097746731\n",
      "train loss:0.5534362450182884\n",
      "train loss:0.6737742131865498\n",
      "train loss:0.6745957876070591\n",
      "train loss:0.8682524317768384\n",
      "train loss:0.5733488698358444\n",
      "train loss:0.5914388899274988\n",
      "train loss:0.5876532624885344\n",
      "train loss:0.6101159720357233\n",
      "train loss:0.7414899309998367\n",
      "train loss:0.5224748663397384\n",
      "train loss:0.6328147215828488\n",
      "train loss:0.4292500092245581\n",
      "train loss:0.4233460648090783\n",
      "train loss:0.5329027366795739\n",
      "train loss:0.7681425587891019\n",
      "train loss:0.42151111161177546\n",
      "train loss:0.6863914223436169\n",
      "train loss:0.6281552157089474\n",
      "train loss:0.5718722500521947\n",
      "train loss:0.32281014522232276\n",
      "train loss:0.41337636948443157\n",
      "train loss:0.379706234521935\n",
      "train loss:0.40844781113939715\n",
      "train loss:0.4083819227008061\n",
      "train loss:0.4218950352061186\n",
      "train loss:0.40669473479029716\n",
      "train loss:0.4480363306168778\n",
      "train loss:0.41896253069310996\n",
      "train loss:0.36699427111166505\n",
      "train loss:0.5072833955937714\n",
      "train loss:0.3302209227382349\n",
      "train loss:0.5852511682278821\n",
      "train loss:0.40052499510312706\n",
      "train loss:0.5259236611544382\n",
      "train loss:0.45759591023406665\n",
      "train loss:0.38043723634622295\n",
      "train loss:0.35703336765571136\n",
      "train loss:0.45338826419393413\n",
      "train loss:0.45488735486456633\n",
      "train loss:0.5560333659282218\n",
      "train loss:0.5123034826890267\n",
      "train loss:0.45538389571214893\n",
      "train loss:0.288533800111489\n",
      "train loss:0.42884073894038466\n",
      "train loss:0.590585056652122\n",
      "train loss:0.41355305272498766\n",
      "train loss:0.3366471946115101\n",
      "train loss:0.482218537255798\n",
      "train loss:0.638798571548541\n",
      "train loss:0.3161968305513913\n",
      "train loss:0.27871363459717935\n",
      "train loss:0.4345352648359657\n",
      "train loss:0.48167649348163133\n",
      "train loss:0.4049767885797236\n",
      "train loss:0.34926444999189776\n",
      "train loss:0.4729163186826014\n",
      "train loss:0.3085671503970647\n",
      "train loss:0.41064544467675196\n",
      "train loss:0.4254966448973795\n",
      "train loss:0.38073060944218473\n",
      "train loss:0.38561851913783907\n",
      "train loss:0.2699573884505417\n",
      "train loss:0.5835496032490326\n",
      "train loss:0.4421535600469808\n",
      "train loss:0.49767594207515825\n",
      "train loss:0.3702252980898429\n",
      "train loss:0.45102299406266666\n",
      "train loss:0.4237013279760041\n",
      "train loss:0.3910626412934273\n",
      "train loss:0.6298886539132722\n",
      "train loss:0.43032478086129994\n",
      "train loss:0.25789081473428377\n",
      "train loss:0.40063988750486595\n",
      "train loss:0.33919466334896886\n",
      "train loss:0.30793619170780273\n",
      "train loss:0.39185891282905094\n",
      "train loss:0.37895558712646255\n",
      "train loss:0.41065572493444075\n",
      "train loss:0.3956108986468253\n",
      "train loss:0.5131131528364655\n",
      "train loss:0.4703027899906991\n",
      "train loss:0.5111608747677899\n",
      "train loss:0.3715387692221123\n",
      "train loss:0.45676092861462336\n",
      "train loss:0.45674211028764977\n",
      "train loss:0.21624086382757138\n",
      "train loss:0.36010679459392775\n",
      "train loss:0.32065060127147355\n",
      "train loss:0.3512543100488427\n",
      "train loss:0.27601919076906156\n",
      "train loss:0.27017854169386696\n",
      "train loss:0.40616898980845484\n",
      "train loss:0.3882880944468245\n",
      "train loss:0.40747877311133757\n",
      "train loss:0.4299304863690032\n",
      "train loss:0.4991836748413836\n",
      "train loss:0.3087076883712385\n",
      "train loss:0.629034537573102\n",
      "train loss:0.3654751948033151\n",
      "train loss:0.30568645278771733\n",
      "train loss:0.370840074542862\n",
      "train loss:0.378143340970966\n",
      "train loss:0.26741586944314405\n",
      "train loss:0.2851456026927754\n",
      "train loss:0.3401666849659227\n",
      "train loss:0.33021481351531967\n",
      "train loss:0.3505953600730223\n",
      "train loss:0.18865731831599306\n",
      "train loss:0.26413257375234717\n",
      "train loss:0.5272988394112954\n",
      "train loss:0.36756426756011623\n",
      "train loss:0.31967695832014376\n",
      "train loss:0.21032918124327962\n",
      "train loss:0.24952370794709938\n",
      "train loss:0.27384315918779395\n",
      "train loss:0.20074863035809834\n",
      "train loss:0.28174065070457355\n",
      "train loss:0.32915199355225233\n",
      "train loss:0.3818118249710426\n",
      "train loss:0.20989730009039037\n",
      "train loss:0.22648412077089522\n",
      "train loss:0.33471218101542577\n",
      "train loss:0.26151067409246803\n",
      "train loss:0.32428675462872597\n",
      "train loss:0.25415593561049016\n",
      "train loss:0.30636266358712944\n",
      "train loss:0.21465042959926117\n",
      "train loss:0.27842929698369434\n",
      "train loss:0.2607796180291502\n",
      "train loss:0.47816096982083545\n",
      "train loss:0.6385573901155848\n",
      "train loss:0.2951402402901319\n",
      "train loss:0.2485468787637396\n",
      "train loss:0.3166617219479964\n",
      "train loss:0.35873077645321577\n",
      "train loss:0.3154703871917605\n",
      "train loss:0.18637612976712087\n",
      "train loss:0.3211957794429045\n",
      "train loss:0.3901964173996968\n",
      "train loss:0.34425971771404085\n",
      "train loss:0.22035255745237337\n",
      "train loss:0.38913930287954895\n",
      "train loss:0.28014602907007796\n",
      "train loss:0.3932620134237061\n",
      "train loss:0.3522589846465374\n",
      "train loss:0.38289808847696244\n",
      "train loss:0.37495090480882526\n",
      "train loss:0.19357221519724305\n",
      "train loss:0.185061829501492\n",
      "train loss:0.21104264013268106\n",
      "train loss:0.3341866179582067\n",
      "train loss:0.3622220048070423\n",
      "train loss:0.40840055059592584\n",
      "train loss:0.28584901980679855\n",
      "train loss:0.3521779906007156\n",
      "train loss:0.29863506830746706\n",
      "train loss:0.2518339646617383\n",
      "train loss:0.284906324662858\n",
      "train loss:0.2703984013311446\n",
      "train loss:0.19373021638496504\n",
      "train loss:0.2243647849530609\n",
      "train loss:0.2621676412804666\n",
      "train loss:0.30711953248398793\n",
      "train loss:0.219183994581447\n",
      "train loss:0.2746535947447766\n",
      "train loss:0.24963869870554573\n",
      "train loss:0.2809172249328029\n",
      "train loss:0.20114241071505642\n",
      "train loss:0.2681288673717683\n",
      "train loss:0.21082387988521087\n",
      "train loss:0.18675971500011068\n",
      "train loss:0.22526648075951056\n",
      "train loss:0.29030610551845315\n",
      "train loss:0.23604680628139751\n",
      "train loss:0.26447731248383577\n",
      "train loss:0.3343487397709593\n",
      "train loss:0.24318563844841015\n",
      "train loss:0.32013262718123897\n",
      "train loss:0.32229811896667443\n",
      "train loss:0.2069373597880864\n",
      "train loss:0.34260536451724444\n",
      "train loss:0.1667367742910747\n",
      "train loss:0.2506274199032876\n",
      "train loss:0.465996122542193\n",
      "train loss:0.2778844616530971\n",
      "train loss:0.2733536158763144\n",
      "train loss:0.37897366977648095\n",
      "train loss:0.23412876272969005\n",
      "train loss:0.2885204771590423\n",
      "train loss:0.24020527397109526\n",
      "train loss:0.293319226239782\n",
      "train loss:0.20829171824548498\n",
      "train loss:0.17260947083806807\n",
      "train loss:0.28481278288297296\n",
      "train loss:0.1640580184876248\n",
      "train loss:0.3635914973430656\n",
      "train loss:0.22847264893366787\n",
      "train loss:0.16841415759547992\n",
      "train loss:0.28859346736530195\n",
      "train loss:0.1742516704135689\n",
      "train loss:0.31627773582038676\n",
      "train loss:0.30779549826985264\n",
      "train loss:0.2918343996758572\n",
      "train loss:0.21498091369931807\n",
      "train loss:0.43081109338222134\n",
      "train loss:0.3650029285301205\n",
      "train loss:0.23026078554363769\n",
      "train loss:0.19076195751510905\n",
      "train loss:0.2611927091385159\n",
      "train loss:0.22556394830900967\n",
      "train loss:0.2324848025570062\n",
      "train loss:0.24582472941162528\n",
      "train loss:0.2969828892083095\n",
      "train loss:0.34817889523638457\n",
      "train loss:0.2201558953352303\n",
      "train loss:0.20057009987362284\n",
      "train loss:0.30356640289265246\n",
      "train loss:0.3271162765364394\n",
      "train loss:0.1596971829030317\n",
      "train loss:0.40981756434081473\n",
      "train loss:0.2205323388011365\n",
      "train loss:0.1798452918244773\n",
      "train loss:0.23699272572622374\n",
      "train loss:0.17444475446295013\n",
      "train loss:0.34781709486854806\n",
      "train loss:0.361263413240986\n",
      "train loss:0.18254411898551243\n",
      "train loss:0.22019534422371664\n",
      "train loss:0.3291941990985569\n",
      "train loss:0.27952229786223026\n",
      "train loss:0.212499311178293\n",
      "train loss:0.20153953850119558\n",
      "train loss:0.2652420036157906\n",
      "train loss:0.13233761483794032\n",
      "train loss:0.15901341520603451\n",
      "train loss:0.2977000970667194\n",
      "train loss:0.2556217259903209\n",
      "train loss:0.20867730314084565\n",
      "train loss:0.24459734440667114\n",
      "train loss:0.18559745012808768\n",
      "train loss:0.19572556055226265\n",
      "train loss:0.3226458440667602\n",
      "train loss:0.27496047001248886\n",
      "train loss:0.17594997740010046\n",
      "train loss:0.23983366631911973\n",
      "train loss:0.14197419454203225\n",
      "train loss:0.1473536533514378\n",
      "train loss:0.295202311082811\n",
      "train loss:0.1152810627579194\n",
      "train loss:0.2520890613605688\n",
      "train loss:0.22419215311592464\n",
      "train loss:0.19775124899942448\n",
      "train loss:0.2686634721711042\n",
      "train loss:0.3767081396144021\n",
      "train loss:0.12015874453792907\n",
      "train loss:0.22272789267807142\n",
      "train loss:0.25575348254442265\n",
      "train loss:0.29319918443872994\n",
      "train loss:0.13422682228186059\n",
      "train loss:0.27498668107469876\n",
      "train loss:0.14664989741319087\n",
      "train loss:0.4042277107014398\n",
      "train loss:0.21042484081203652\n",
      "train loss:0.31780853862779496\n",
      "train loss:0.16235435855710303\n",
      "train loss:0.19904539971893898\n",
      "train loss:0.3811644473961974\n",
      "train loss:0.21386114789881533\n",
      "train loss:0.1230443950534494\n",
      "train loss:0.11880106780346696\n",
      "train loss:0.19419797210508338\n",
      "train loss:0.23851344829239643\n",
      "train loss:0.20797015242393738\n",
      "train loss:0.1674128334831699\n",
      "train loss:0.25595374651489794\n",
      "train loss:0.29538819938128463\n",
      "train loss:0.20723179292435684\n",
      "train loss:0.2323858637539252\n",
      "train loss:0.15567237781817414\n",
      "train loss:0.1568336891121801\n",
      "train loss:0.14040395282125315\n",
      "train loss:0.13389223909605255\n",
      "train loss:0.1828633168275556\n",
      "train loss:0.1490104967447527\n",
      "train loss:0.12624518492049186\n",
      "train loss:0.3855748914606314\n",
      "train loss:0.2501195995381968\n",
      "train loss:0.17342673988029972\n",
      "train loss:0.12858648265623096\n",
      "train loss:0.1660083282907042\n",
      "train loss:0.1790490605870362\n",
      "train loss:0.18714554906576655\n",
      "train loss:0.3431377974228098\n",
      "train loss:0.24513373805302766\n",
      "train loss:0.26287919383981956\n",
      "train loss:0.166439627575229\n",
      "train loss:0.11317221411999856\n",
      "train loss:0.32232636507524004\n",
      "train loss:0.197114289232884\n",
      "train loss:0.2034396336016696\n",
      "train loss:0.18766632320522775\n",
      "train loss:0.2426149267003751\n",
      "train loss:0.20487854912317807\n",
      "train loss:0.21221391582916915\n",
      "train loss:0.1103353740916079\n",
      "train loss:0.3301238742391766\n",
      "train loss:0.24964670873849354\n",
      "train loss:0.3155636416990668\n",
      "train loss:0.17266585682027813\n",
      "train loss:0.2225064994629176\n",
      "train loss:0.12138507976082441\n",
      "train loss:0.17542606324293658\n",
      "train loss:0.3783359218294703\n",
      "train loss:0.25623806996687665\n",
      "train loss:0.1742127046526366\n",
      "train loss:0.12024595069844128\n",
      "train loss:0.2818254398674852\n",
      "train loss:0.15668208510197934\n",
      "train loss:0.14903768264468906\n",
      "train loss:0.15971390212733527\n",
      "train loss:0.13339714016202683\n",
      "train loss:0.22552746816295968\n",
      "train loss:0.11959855140017511\n",
      "train loss:0.20138434844557104\n",
      "train loss:0.15344516284679335\n",
      "train loss:0.17268018063042948\n",
      "train loss:0.18871401734248422\n",
      "train loss:0.2369976405466512\n",
      "train loss:0.21697852660344413\n",
      "train loss:0.1793552852984565\n",
      "train loss:0.20985581145941423\n",
      "train loss:0.2495621337008123\n",
      "train loss:0.1493733121957243\n",
      "train loss:0.47186441986395233\n",
      "train loss:0.16600912069595558\n",
      "train loss:0.11160562172097566\n",
      "train loss:0.15226990723845904\n",
      "train loss:0.22653839110908738\n",
      "train loss:0.20353769756248763\n",
      "train loss:0.21543792542326476\n",
      "train loss:0.12425934576801462\n",
      "train loss:0.13154867326720926\n",
      "train loss:0.1660923926529696\n",
      "train loss:0.12057212843800513\n",
      "train loss:0.1668516959484516\n",
      "train loss:0.1962600229210039\n",
      "train loss:0.2662971376374071\n",
      "train loss:0.19851954007827655\n",
      "train loss:0.09971160500633887\n",
      "train loss:0.2033130583832924\n",
      "train loss:0.1963504281082785\n",
      "train loss:0.09410991876296804\n",
      "train loss:0.22995317970261536\n",
      "train loss:0.20878049078870325\n",
      "train loss:0.19822996552464006\n",
      "train loss:0.18246035443435168\n",
      "train loss:0.20338973716778078\n",
      "train loss:0.14643075935893662\n",
      "train loss:0.15315395211121913\n",
      "train loss:0.22171816139042566\n",
      "train loss:0.1935935100001229\n",
      "train loss:0.08764987124557874\n",
      "train loss:0.14208529675799977\n",
      "train loss:0.24906075098808012\n",
      "train loss:0.2791094774244373\n",
      "train loss:0.23142665848573915\n",
      "train loss:0.19662859414416456\n",
      "train loss:0.16285584514373672\n",
      "train loss:0.14067573537445785\n",
      "train loss:0.230676288685869\n",
      "train loss:0.18146667166268465\n",
      "train loss:0.2254994623039741\n",
      "train loss:0.09595376386175794\n",
      "train loss:0.23078796659674405\n",
      "train loss:0.12288961433943156\n",
      "train loss:0.1352858320378144\n",
      "train loss:0.17483633654475536\n",
      "train loss:0.2772809571149352\n",
      "train loss:0.2109770722123997\n",
      "train loss:0.18388647736144503\n",
      "train loss:0.27722391989781714\n",
      "train loss:0.20717164879576064\n",
      "train loss:0.23200510322285808\n",
      "train loss:0.13222933037510398\n",
      "train loss:0.15224353066380764\n",
      "train loss:0.26284413811761315\n",
      "train loss:0.19949176638878477\n",
      "train loss:0.10485324924210776\n",
      "train loss:0.16772317994789687\n",
      "train loss:0.1011693397127717\n",
      "train loss:0.18352191104049834\n",
      "train loss:0.1803541049024734\n",
      "train loss:0.2690443676077677\n",
      "train loss:0.11426765380906596\n",
      "train loss:0.12718146420745366\n",
      "train loss:0.13273433346128977\n",
      "train loss:0.11296831867834356\n",
      "train loss:0.3458588008257275\n",
      "train loss:0.24723465450944648\n",
      "train loss:0.05750191967634291\n",
      "train loss:0.11525655533497847\n",
      "train loss:0.15290279426774073\n",
      "train loss:0.21173883002121205\n",
      "train loss:0.19570328977508453\n",
      "train loss:0.16272148973770226\n",
      "train loss:0.20832941550832942\n",
      "train loss:0.11397082549658873\n",
      "train loss:0.10065868228655417\n",
      "train loss:0.06148817871170976\n",
      "train loss:0.10954989718405668\n",
      "train loss:0.1562333044018133\n",
      "train loss:0.1071379146289755\n",
      "train loss:0.20039700370946917\n",
      "train loss:0.06328646591389314\n",
      "train loss:0.0860300431580491\n",
      "train loss:0.1722566729529875\n",
      "train loss:0.105970942610665\n",
      "train loss:0.15668822230268364\n",
      "train loss:0.16210921533841888\n",
      "train loss:0.1998036604244452\n",
      "train loss:0.1959286313450854\n",
      "train loss:0.12896978462923614\n",
      "train loss:0.16785319538254184\n",
      "train loss:0.24246939865095588\n",
      "train loss:0.10391416818249176\n",
      "train loss:0.13249976802577698\n",
      "train loss:0.18565538325344552\n",
      "train loss:0.0741811066641578\n",
      "train loss:0.1679404899957847\n",
      "train loss:0.12426424505614948\n",
      "train loss:0.11526234227065775\n",
      "train loss:0.15265248902235118\n",
      "train loss:0.17812205367748507\n",
      "train loss:0.13727108862942244\n",
      "train loss:0.3425975287197066\n",
      "train loss:0.12654217660692635\n",
      "train loss:0.16321690037202452\n",
      "train loss:0.15476903889840923\n",
      "train loss:0.1891252526568714\n",
      "train loss:0.2279237196571801\n",
      "train loss:0.10610140685343417\n",
      "train loss:0.16527887551583603\n",
      "train loss:0.0647471687941963\n",
      "train loss:0.10650809792922356\n",
      "train loss:0.06028095509575529\n",
      "train loss:0.11488707206492639\n",
      "train loss:0.12523688395130433\n",
      "train loss:0.11043649434554424\n",
      "train loss:0.12756084855113822\n",
      "train loss:0.06728009715852531\n",
      "train loss:0.06797381722377475\n",
      "train loss:0.13698568055072305\n",
      "train loss:0.18589516235131215\n",
      "train loss:0.2223271146887732\n",
      "train loss:0.07702791544444874\n",
      "train loss:0.09074250368687325\n",
      "train loss:0.19690753010261758\n",
      "train loss:0.19366600220224847\n",
      "train loss:0.10120880219447694\n",
      "train loss:0.19755029232651172\n",
      "train loss:0.09248309054467194\n",
      "train loss:0.04029842247858704\n",
      "train loss:0.16572536380597092\n",
      "train loss:0.20704278345502658\n",
      "train loss:0.12477242573257694\n",
      "train loss:0.08543940766760529\n",
      "train loss:0.11494130331792218\n",
      "train loss:0.06390214559116575\n",
      "train loss:0.12814949818755286\n",
      "train loss:0.08738778875115695\n",
      "train loss:0.13303156274530153\n",
      "train loss:0.0881838343443507\n",
      "train loss:0.09134099848959702\n",
      "train loss:0.10754555523180687\n",
      "train loss:0.05659515534752089\n",
      "train loss:0.060899840587782965\n",
      "train loss:0.15844823955178353\n",
      "train loss:0.11177857713113225\n",
      "train loss:0.07489670618617333\n",
      "train loss:0.10563697424648298\n",
      "train loss:0.17622091581037339\n",
      "train loss:0.0965085541581952\n",
      "train loss:0.12279628940529302\n",
      "train loss:0.13147797158462826\n",
      "train loss:0.34757278168541544\n",
      "train loss:0.1834288388586652\n",
      "train loss:0.07460410357622543\n",
      "train loss:0.11917957047532685\n",
      "train loss:0.11350011112380855\n",
      "train loss:0.14876104209218347\n",
      "train loss:0.20697360193985015\n",
      "train loss:0.12144865044150337\n",
      "train loss:0.09471621545489511\n",
      "train loss:0.09742705579152056\n",
      "train loss:0.13531815102204608\n",
      "train loss:0.10660579920768339\n",
      "train loss:0.05868144301516609\n",
      "train loss:0.1329212795322751\n",
      "train loss:0.21750231918883556\n",
      "train loss:0.17497161321168142\n",
      "train loss:0.11196692351051851\n",
      "train loss:0.0783864362061106\n",
      "train loss:0.10914468154348535\n",
      "train loss:0.07014071496411999\n",
      "train loss:0.16057075727947442\n",
      "train loss:0.09657203146581357\n",
      "train loss:0.16438307634461577\n",
      "train loss:0.1818025617362703\n",
      "train loss:0.06918148080779249\n",
      "train loss:0.19226276888350916\n",
      "train loss:0.16644810171247915\n",
      "train loss:0.15401976471331646\n",
      "train loss:0.10088042280633665\n",
      "train loss:0.10022966919901846\n",
      "train loss:0.20619935216629318\n",
      "train loss:0.1676174474335927\n",
      "train loss:0.07646145358500696\n",
      "train loss:0.14446996931104808\n",
      "train loss:0.12018736362224244\n",
      "train loss:0.22878676310219512\n",
      "train loss:0.115360935160885\n",
      "train loss:0.16959155924100838\n",
      "train loss:0.052208023829358734\n",
      "train loss:0.06708028547512111\n",
      "train loss:0.1807887545719995\n",
      "train loss:0.10319787691859722\n",
      "train loss:0.15033987575286537\n",
      "train loss:0.07258628258032829\n",
      "train loss:0.08154417674431501\n",
      "train loss:0.1362771685230541\n",
      "train loss:0.11431521676884654\n",
      "train loss:0.10442786323280133\n",
      "train loss:0.1675794759272687\n",
      "train loss:0.1944158120348661\n",
      "train loss:0.15267719885746214\n",
      "train loss:0.1864133494525798\n",
      "train loss:0.10828612703178014\n",
      "train loss:0.19014981736602718\n",
      "train loss:0.17122052592745196\n",
      "train loss:0.1607799426991989\n",
      "train loss:0.07759613343770559\n",
      "train loss:0.10333318256982808\n",
      "train loss:0.22880127888186913\n",
      "train loss:0.1636108725408728\n",
      "train loss:0.0644215461657385\n",
      "train loss:0.26801563943363355\n",
      "train loss:0.1466442277955263\n",
      "train loss:0.0890904798419759\n",
      "train loss:0.15789103278490013\n",
      "train loss:0.12188739380209665\n",
      "train loss:0.09108151040524967\n",
      "train loss:0.09554972310938775\n",
      "train loss:0.07953089255513252\n",
      "train loss:0.08155419512231359\n",
      "train loss:0.0836448880418266\n",
      "train loss:0.06594512274391935\n",
      "train loss:0.06955850713348304\n",
      "train loss:0.11634883891451933\n",
      "train loss:0.06759432410357913\n",
      "train loss:0.10946070146858186\n",
      "train loss:0.09403612526978104\n",
      "train loss:0.14701783064862362\n",
      "=== epoch:2, train acc:0.963, test acc:0.955 ===\n",
      "train loss:0.14786735176579727\n",
      "train loss:0.0715927767789421\n",
      "train loss:0.12854959708630773\n",
      "train loss:0.1571674093977634\n",
      "train loss:0.18824570599236357\n",
      "train loss:0.06063564833389898\n",
      "train loss:0.11145636818589416\n",
      "train loss:0.1225711463722408\n",
      "train loss:0.2468355186455497\n",
      "train loss:0.10312346015617263\n",
      "train loss:0.05596919796416737\n",
      "train loss:0.09845638073747662\n",
      "train loss:0.1583264718754218\n",
      "train loss:0.05674591166732783\n",
      "train loss:0.10761952820902526\n",
      "train loss:0.17861750034160784\n",
      "train loss:0.06428824981934783\n",
      "train loss:0.08289947635204484\n",
      "train loss:0.3350737416758172\n",
      "train loss:0.060192641515212836\n",
      "train loss:0.16111690094334843\n",
      "train loss:0.11021661893803993\n",
      "train loss:0.08641642428343334\n",
      "train loss:0.08678069908787388\n",
      "train loss:0.14432702997198432\n",
      "train loss:0.1488840465503233\n",
      "train loss:0.10152895302763212\n",
      "train loss:0.23583310962846904\n",
      "train loss:0.05204910932468799\n",
      "train loss:0.09176138792708674\n",
      "train loss:0.11332761405364929\n",
      "train loss:0.13353801670776963\n",
      "train loss:0.10965468875710535\n",
      "train loss:0.07838080567772054\n",
      "train loss:0.16056827925957978\n",
      "train loss:0.1764300816037215\n",
      "train loss:0.10768511601796206\n",
      "train loss:0.11693260976360721\n",
      "train loss:0.0892263700294391\n",
      "train loss:0.100024545909562\n",
      "train loss:0.07887927512102381\n",
      "train loss:0.18869348434927552\n",
      "train loss:0.07452140919660719\n",
      "train loss:0.0989352601604675\n",
      "train loss:0.12645015621563338\n",
      "train loss:0.11006596936675078\n",
      "train loss:0.21213181187840138\n",
      "train loss:0.08978553749234773\n",
      "train loss:0.06665992348885648\n",
      "train loss:0.10489323448927847\n",
      "train loss:0.05108092545481772\n",
      "train loss:0.14090258281959664\n",
      "train loss:0.06654641236489242\n",
      "train loss:0.08426697808781505\n",
      "train loss:0.1928608227780436\n",
      "train loss:0.1718408204099964\n",
      "train loss:0.10033230781186765\n",
      "train loss:0.12702718268683896\n",
      "train loss:0.09857433710065557\n",
      "train loss:0.13354568206980125\n",
      "train loss:0.06158863856642534\n",
      "train loss:0.07814652103207421\n",
      "train loss:0.10470634437186384\n",
      "train loss:0.09918507662089507\n",
      "train loss:0.22043690743179226\n",
      "train loss:0.08905520777185029\n",
      "train loss:0.1681844070206017\n",
      "train loss:0.1575959093214913\n",
      "train loss:0.09032470814914301\n",
      "train loss:0.1161687326526181\n",
      "train loss:0.15206988971717966\n",
      "train loss:0.11360581735814153\n",
      "train loss:0.05547549464996919\n",
      "train loss:0.09780377379283178\n",
      "train loss:0.04148913614398463\n",
      "train loss:0.04190492761632103\n",
      "train loss:0.15722989487651642\n",
      "train loss:0.13947604991876741\n",
      "train loss:0.06859234513232619\n",
      "train loss:0.040781263267671806\n",
      "train loss:0.10204825417567406\n",
      "train loss:0.06804187483734303\n",
      "train loss:0.02865541468588754\n",
      "train loss:0.0881640385390488\n",
      "train loss:0.1993643332946023\n",
      "train loss:0.16032049286567715\n",
      "train loss:0.11968470416699337\n",
      "train loss:0.044042429761623945\n",
      "train loss:0.09408034833639559\n",
      "train loss:0.09397920082506232\n",
      "train loss:0.14128514742045145\n",
      "train loss:0.046298708488763406\n",
      "train loss:0.11369104338978632\n",
      "train loss:0.09245883506841851\n",
      "train loss:0.09411933983415605\n",
      "train loss:0.09571795582139168\n",
      "train loss:0.06803454496936945\n",
      "train loss:0.1368327003593494\n",
      "train loss:0.17531666528966144\n",
      "train loss:0.06358329395783709\n",
      "train loss:0.0870083912544178\n",
      "train loss:0.12422021830044155\n",
      "train loss:0.2716891191229858\n",
      "train loss:0.024735906563542676\n",
      "train loss:0.05527221707907244\n",
      "train loss:0.16445172145943357\n",
      "train loss:0.11435215380241592\n",
      "train loss:0.12856087073261235\n",
      "train loss:0.0598666311313145\n",
      "train loss:0.1527978726320169\n",
      "train loss:0.17801059849956996\n",
      "train loss:0.08809788287692026\n",
      "train loss:0.11735544360874567\n",
      "train loss:0.0768556498528224\n",
      "train loss:0.10714424682174048\n",
      "train loss:0.042084421364176165\n",
      "train loss:0.10430320180177942\n",
      "train loss:0.21648846998375157\n",
      "train loss:0.20069756105666334\n",
      "train loss:0.1198982721615738\n",
      "train loss:0.08949287437804342\n",
      "train loss:0.17149404950709432\n",
      "train loss:0.05629166637278691\n",
      "train loss:0.07743977446011811\n",
      "train loss:0.0850229068390116\n",
      "train loss:0.06591303487708905\n",
      "train loss:0.09420204326990796\n",
      "train loss:0.06197310711698166\n",
      "train loss:0.24344141700214464\n",
      "train loss:0.17794140372193967\n",
      "train loss:0.13130231016616042\n",
      "train loss:0.07959911205722905\n",
      "train loss:0.04695254549260123\n",
      "train loss:0.055962672988910514\n",
      "train loss:0.15176492045043896\n",
      "train loss:0.10816036311498099\n",
      "train loss:0.03745687958621209\n",
      "train loss:0.055383027368386004\n",
      "train loss:0.1274509608703807\n",
      "train loss:0.12856766210786633\n",
      "train loss:0.1365643356465188\n",
      "train loss:0.09880147780237344\n",
      "train loss:0.0630091888446146\n",
      "train loss:0.05853288285172602\n",
      "train loss:0.08955113479701199\n",
      "train loss:0.05064706040002727\n",
      "train loss:0.11432033220089265\n",
      "train loss:0.0359455452242518\n",
      "train loss:0.10722848945809932\n",
      "train loss:0.08254180660475598\n",
      "train loss:0.045049485708744334\n",
      "train loss:0.11840447923471029\n",
      "train loss:0.09144760863173645\n",
      "train loss:0.06549675014782855\n",
      "train loss:0.09430044849167463\n",
      "train loss:0.043143979086561576\n",
      "train loss:0.08947596338843672\n",
      "train loss:0.09977549864144807\n",
      "train loss:0.0645076996303305\n",
      "train loss:0.09030065498860897\n",
      "train loss:0.09815115738058916\n",
      "train loss:0.230108465393404\n",
      "train loss:0.13721949753146515\n",
      "train loss:0.027223321204247655\n",
      "train loss:0.09550196049564585\n",
      "train loss:0.12763208737682075\n",
      "train loss:0.1206875492226278\n",
      "train loss:0.15295716807265897\n",
      "train loss:0.04802401517115231\n",
      "train loss:0.06410498534910883\n",
      "train loss:0.06785820868018719\n",
      "train loss:0.05454970512146799\n",
      "train loss:0.2227260110409343\n",
      "train loss:0.15177489306986955\n",
      "train loss:0.06363828294015068\n",
      "train loss:0.07989071184222857\n",
      "train loss:0.1024629375398923\n",
      "train loss:0.19384746912542292\n",
      "train loss:0.10625190432467241\n",
      "train loss:0.07230509204788667\n",
      "train loss:0.08221355942920017\n",
      "train loss:0.06868110722269063\n",
      "train loss:0.0850044142879886\n",
      "train loss:0.046140427001663556\n",
      "train loss:0.04763418550918359\n",
      "train loss:0.1179150665877182\n",
      "train loss:0.09947212899983869\n",
      "train loss:0.06970686372791011\n",
      "train loss:0.16003228685591384\n",
      "train loss:0.08886299244398436\n",
      "train loss:0.1519346298533197\n",
      "train loss:0.11680141028864952\n",
      "train loss:0.07519624741875405\n",
      "train loss:0.03930112827503187\n",
      "train loss:0.1321285413903989\n",
      "train loss:0.17278232863910564\n",
      "train loss:0.1328096979207443\n",
      "train loss:0.0694558160477035\n",
      "train loss:0.09870237986262259\n",
      "train loss:0.17208420448445216\n",
      "train loss:0.06636059108150247\n",
      "train loss:0.0923177364708147\n",
      "train loss:0.031726410446150204\n",
      "train loss:0.045373245833693295\n",
      "train loss:0.07160613080318351\n",
      "train loss:0.03751924814761287\n",
      "train loss:0.03318498224413456\n",
      "train loss:0.07402884040305978\n",
      "train loss:0.09580249639359474\n",
      "train loss:0.03188140274027802\n",
      "train loss:0.15235321286455472\n",
      "train loss:0.07732484328633955\n",
      "train loss:0.05644971364955392\n",
      "train loss:0.11856004996847208\n",
      "train loss:0.15024209987270956\n",
      "train loss:0.09164268046875097\n",
      "train loss:0.08984880498054203\n",
      "train loss:0.04893961896662049\n",
      "train loss:0.10098846241399725\n",
      "train loss:0.09688236560376984\n",
      "train loss:0.16168481380659522\n",
      "train loss:0.03682976003977391\n",
      "train loss:0.06258589999199557\n",
      "train loss:0.11598035988346223\n",
      "train loss:0.03760145296661763\n",
      "train loss:0.12059543903298152\n",
      "train loss:0.03882706962689796\n",
      "train loss:0.03164752545127672\n",
      "train loss:0.04325382286050344\n",
      "train loss:0.0741289325597884\n",
      "train loss:0.041282980312668666\n",
      "train loss:0.10183492335617902\n",
      "train loss:0.0675238806632342\n",
      "train loss:0.060989974010796526\n",
      "train loss:0.11799040896268603\n",
      "train loss:0.07757301205148975\n",
      "train loss:0.02611712008682299\n",
      "train loss:0.14226288317336352\n",
      "train loss:0.05576966849635249\n",
      "train loss:0.04444025246506528\n",
      "train loss:0.06389505670192146\n",
      "train loss:0.08727754979951925\n",
      "train loss:0.1256068470908342\n",
      "train loss:0.07581979401652333\n",
      "train loss:0.06579717526028651\n",
      "train loss:0.08451734647350484\n",
      "train loss:0.044743431704259304\n",
      "train loss:0.15735284026181431\n",
      "train loss:0.14705370620584568\n",
      "train loss:0.06829256808681902\n",
      "train loss:0.0215924631621222\n",
      "train loss:0.06829014709204632\n",
      "train loss:0.032937617812134404\n",
      "train loss:0.08035334646640503\n",
      "train loss:0.14143553921957025\n",
      "train loss:0.18235611399387305\n",
      "train loss:0.13403080686047505\n",
      "train loss:0.0708358815986795\n",
      "train loss:0.06730830496339156\n",
      "train loss:0.05787711921279613\n",
      "train loss:0.13580422375803172\n",
      "train loss:0.12441494527321051\n",
      "train loss:0.13108227372467338\n",
      "train loss:0.1123548504443681\n",
      "train loss:0.13115818098521717\n",
      "train loss:0.042764381605590616\n",
      "train loss:0.05890502564940471\n",
      "train loss:0.047916797951708626\n",
      "train loss:0.05939720166026102\n",
      "train loss:0.16408603394822813\n",
      "train loss:0.08627821829798452\n",
      "train loss:0.07699577890885612\n",
      "train loss:0.11173719088468462\n",
      "train loss:0.06663216388796257\n",
      "train loss:0.07270408235047833\n",
      "train loss:0.04021622684016129\n",
      "train loss:0.054101368707746324\n",
      "train loss:0.06918578327103425\n",
      "train loss:0.10276935055275815\n",
      "train loss:0.09951480730360673\n",
      "train loss:0.21225139824228947\n",
      "train loss:0.2562553393350306\n",
      "train loss:0.08721201114668078\n",
      "train loss:0.0567181950507085\n",
      "train loss:0.12393642542365875\n",
      "train loss:0.0713883316141732\n",
      "train loss:0.04437331498211388\n",
      "train loss:0.14227883578629139\n",
      "train loss:0.18139860274605357\n",
      "train loss:0.09876955116990356\n",
      "train loss:0.0676750394646897\n",
      "train loss:0.14899434630015357\n",
      "train loss:0.10347960691370912\n",
      "train loss:0.16650122781430882\n",
      "train loss:0.08125800496772481\n",
      "train loss:0.09451135096464217\n",
      "train loss:0.10072002994767186\n",
      "train loss:0.08308495368182729\n",
      "train loss:0.09652125285041631\n",
      "train loss:0.06364930545970571\n",
      "train loss:0.16266100829268246\n",
      "train loss:0.10067682659481919\n",
      "train loss:0.0788105734568343\n",
      "train loss:0.03252490896191706\n",
      "train loss:0.05406276985780257\n",
      "train loss:0.0665523878809707\n",
      "train loss:0.10378804437791242\n",
      "train loss:0.07181810651478684\n",
      "train loss:0.0643908381519139\n",
      "train loss:0.048377409619675654\n",
      "train loss:0.029710952550735813\n",
      "train loss:0.09575962532801224\n",
      "train loss:0.09580023345470691\n",
      "train loss:0.04530803036870707\n",
      "train loss:0.07832822037006999\n",
      "train loss:0.0435108550915754\n",
      "train loss:0.05698014692846843\n",
      "train loss:0.16769726430393803\n",
      "train loss:0.02711960578287284\n",
      "train loss:0.12237029704610602\n",
      "train loss:0.03339458778693623\n",
      "train loss:0.1004854413641926\n",
      "train loss:0.046587410216056856\n",
      "train loss:0.06981990970070258\n",
      "train loss:0.13268374023894747\n",
      "train loss:0.03532696844524618\n",
      "train loss:0.041691877589568244\n",
      "train loss:0.10679772031476548\n",
      "train loss:0.035341882988341795\n",
      "train loss:0.06273310183205871\n",
      "train loss:0.063501930008717\n",
      "train loss:0.057432740190205826\n",
      "train loss:0.029972887116950498\n",
      "train loss:0.11101172080131338\n",
      "train loss:0.028658035625045413\n",
      "train loss:0.14845701958790708\n",
      "train loss:0.07558541920655626\n",
      "train loss:0.08276534626532175\n",
      "train loss:0.14463192391333263\n",
      "train loss:0.0842358600788839\n",
      "train loss:0.07670921149254054\n",
      "train loss:0.08555022587270054\n",
      "train loss:0.08742048086591286\n",
      "train loss:0.09684534586336042\n",
      "train loss:0.04943198195471164\n",
      "train loss:0.0359013856375771\n",
      "train loss:0.05754482815636161\n",
      "train loss:0.09616284575911721\n",
      "train loss:0.059769280098865785\n",
      "train loss:0.05438046746130485\n",
      "train loss:0.07749082429835262\n",
      "train loss:0.03486541205391666\n",
      "train loss:0.037181554965678994\n",
      "train loss:0.021931450045481214\n",
      "train loss:0.06631719372729866\n",
      "train loss:0.045562825094441595\n",
      "train loss:0.13935924533030225\n",
      "train loss:0.05953633009337718\n",
      "train loss:0.027588145255624922\n",
      "train loss:0.10237101255889608\n",
      "train loss:0.07507275607271052\n",
      "train loss:0.030341633118266886\n",
      "train loss:0.07041662340129229\n",
      "train loss:0.046529164609814114\n",
      "train loss:0.05684576427374414\n",
      "train loss:0.025507281186518724\n",
      "train loss:0.06121460391939724\n",
      "train loss:0.09566581104248639\n",
      "train loss:0.024451757542926816\n",
      "train loss:0.044099629349454446\n",
      "train loss:0.06010695560964088\n",
      "train loss:0.01489336173832052\n",
      "train loss:0.04105200259839074\n",
      "train loss:0.09445633051167109\n",
      "train loss:0.056033705085555656\n",
      "train loss:0.06524305944999652\n",
      "train loss:0.10619949871948553\n",
      "train loss:0.11135893213571642\n",
      "train loss:0.0763217210419643\n",
      "train loss:0.054123294804818534\n",
      "train loss:0.10113982250030853\n",
      "train loss:0.055337217618553834\n",
      "train loss:0.06411823844805689\n",
      "train loss:0.03132583304867383\n",
      "train loss:0.06627660131753448\n",
      "train loss:0.047520169127263395\n",
      "train loss:0.07657015973777147\n",
      "train loss:0.022632959979226618\n",
      "train loss:0.05989008061586963\n",
      "train loss:0.07284441414274605\n",
      "train loss:0.19303844366882394\n",
      "train loss:0.0889611083761392\n",
      "train loss:0.06549342951953402\n",
      "train loss:0.0697478054007224\n",
      "train loss:0.04148435486483844\n",
      "train loss:0.12352342746919284\n",
      "train loss:0.017709379779982177\n",
      "train loss:0.042385731370926216\n",
      "train loss:0.09409221214534474\n",
      "train loss:0.0716548276549499\n",
      "train loss:0.04793541770525491\n",
      "train loss:0.10866068492021996\n",
      "train loss:0.046141809950675114\n",
      "train loss:0.023734384140549472\n",
      "train loss:0.0371161162863515\n",
      "train loss:0.08290112488073235\n",
      "train loss:0.03434929401642904\n",
      "train loss:0.02634497256043761\n",
      "train loss:0.013494105554705291\n",
      "train loss:0.0715739248101334\n",
      "train loss:0.03426870585945819\n",
      "train loss:0.06425722038459467\n",
      "train loss:0.08290377701718138\n",
      "train loss:0.06977266748994293\n",
      "train loss:0.08902713959706117\n",
      "train loss:0.020583283988511017\n",
      "train loss:0.07440092376530238\n",
      "train loss:0.09097932596159135\n",
      "train loss:0.043322209326143606\n",
      "train loss:0.04851586777350746\n",
      "train loss:0.04158594617778925\n",
      "train loss:0.08883224819792869\n",
      "train loss:0.09030303990019357\n",
      "train loss:0.061029702333660334\n",
      "train loss:0.05551461015357426\n",
      "train loss:0.09395930553598494\n",
      "train loss:0.0692482048606395\n",
      "train loss:0.11267112121333246\n",
      "train loss:0.062345921553101154\n",
      "train loss:0.06476020417029575\n",
      "train loss:0.058483838930885816\n",
      "train loss:0.06917678286298068\n",
      "train loss:0.08598629130726744\n",
      "train loss:0.05429942355172252\n",
      "train loss:0.05116818215396823\n",
      "train loss:0.05307933132413153\n",
      "train loss:0.08182688341193892\n",
      "train loss:0.07100418644378786\n",
      "train loss:0.08612514738331964\n",
      "train loss:0.10309645105531993\n",
      "train loss:0.07128983132457012\n",
      "train loss:0.073687547388434\n",
      "train loss:0.0245306968369956\n",
      "train loss:0.1447398103228446\n",
      "train loss:0.054344466139241515\n",
      "train loss:0.13813782080766288\n",
      "train loss:0.14487247787547372\n",
      "train loss:0.08477206686955036\n",
      "train loss:0.04301550046789659\n",
      "train loss:0.1682945633268385\n",
      "train loss:0.15171249370612264\n",
      "train loss:0.07016278853934022\n",
      "train loss:0.09835940834806337\n",
      "train loss:0.061985264806802685\n",
      "train loss:0.057121774190965126\n",
      "train loss:0.03824975749358288\n",
      "train loss:0.03054773700194266\n",
      "train loss:0.07097136799109367\n",
      "train loss:0.08974580951424177\n",
      "train loss:0.02518107320380397\n",
      "train loss:0.12421003501641614\n",
      "train loss:0.04920449333866652\n",
      "train loss:0.04380798387102587\n",
      "train loss:0.04389748139534658\n",
      "train loss:0.06943554225781211\n",
      "train loss:0.07681005356028098\n",
      "train loss:0.0685845190223227\n",
      "train loss:0.05290739100786314\n",
      "train loss:0.04228621896146314\n",
      "train loss:0.1170305034331211\n",
      "train loss:0.060637704265126276\n",
      "train loss:0.07679706722409232\n",
      "train loss:0.1319466506884589\n",
      "train loss:0.029789681715046742\n",
      "train loss:0.05854792771112441\n",
      "train loss:0.05001522764456024\n",
      "train loss:0.039937911625704876\n",
      "train loss:0.042955087548799335\n",
      "train loss:0.07176965573337916\n",
      "train loss:0.04845191522788167\n",
      "train loss:0.07796928282950925\n",
      "train loss:0.10276478139526031\n",
      "train loss:0.07409691379371203\n",
      "train loss:0.041158265621273664\n",
      "train loss:0.052880511591325854\n",
      "train loss:0.04423838421971141\n",
      "train loss:0.0925991802854566\n",
      "train loss:0.1407823468371192\n",
      "train loss:0.05968017400504356\n",
      "train loss:0.10308694688935559\n",
      "train loss:0.15613285220546366\n",
      "train loss:0.05741775952317111\n",
      "train loss:0.045396407028352\n",
      "train loss:0.12881967752422652\n",
      "train loss:0.04980524260509323\n",
      "train loss:0.06663466697912797\n",
      "train loss:0.09144100954609206\n",
      "train loss:0.08643065030850465\n",
      "train loss:0.03785331954216546\n",
      "train loss:0.07398444034378865\n",
      "train loss:0.14982247265871518\n",
      "train loss:0.08491485979564312\n",
      "train loss:0.06388950861686023\n",
      "train loss:0.11302957332365417\n",
      "train loss:0.05538374283017619\n",
      "train loss:0.06987058338601865\n",
      "train loss:0.07668750471815412\n",
      "train loss:0.03946292484700515\n",
      "train loss:0.09693471644421807\n",
      "train loss:0.04114544859231599\n",
      "train loss:0.038007851074138455\n",
      "train loss:0.13099798634129647\n",
      "train loss:0.06093893971028453\n",
      "train loss:0.03981318601750612\n",
      "train loss:0.06595656506014393\n",
      "train loss:0.07163119449352372\n",
      "train loss:0.10456856885464172\n",
      "train loss:0.040146495730732645\n",
      "train loss:0.05025551893343099\n",
      "train loss:0.09887542876384851\n",
      "train loss:0.03291413615371089\n",
      "train loss:0.08523103462995987\n",
      "train loss:0.10649870296001358\n",
      "train loss:0.10886610163809017\n",
      "train loss:0.04850717916749472\n",
      "train loss:0.0759069605560125\n",
      "train loss:0.05765904511500155\n",
      "train loss:0.07740249126240474\n",
      "train loss:0.0703772114786544\n",
      "train loss:0.05246399886033179\n",
      "train loss:0.03922056713855693\n",
      "train loss:0.036882646376758144\n",
      "train loss:0.06948837736601235\n",
      "train loss:0.08753036780583452\n",
      "train loss:0.026295360336237802\n",
      "train loss:0.10286302559184612\n",
      "train loss:0.03803650016658055\n",
      "train loss:0.07675086327156287\n",
      "train loss:0.05371723324178462\n",
      "train loss:0.04673513039297727\n",
      "train loss:0.06409957359360878\n",
      "train loss:0.13430498701737156\n",
      "train loss:0.06043264441368721\n",
      "train loss:0.04284349660900221\n",
      "train loss:0.03339314799154164\n",
      "train loss:0.07647358869233678\n",
      "train loss:0.061317408595942986\n",
      "train loss:0.05004048592047094\n",
      "train loss:0.11559218570721906\n",
      "train loss:0.026420434475931998\n",
      "train loss:0.0595402406829165\n",
      "train loss:0.02137226869693837\n",
      "train loss:0.07176088535981393\n",
      "train loss:0.03763837400872459\n",
      "train loss:0.14750409858974728\n",
      "train loss:0.06584122684842891\n",
      "train loss:0.035120923533211924\n",
      "train loss:0.08320492604380236\n",
      "train loss:0.04419730713664202\n",
      "train loss:0.06600743257824176\n",
      "train loss:0.047071428572576436\n",
      "train loss:0.06793058410492064\n",
      "train loss:0.055113089410098653\n",
      "train loss:0.009491374218386502\n",
      "train loss:0.01735145186600811\n",
      "train loss:0.03376945844610825\n",
      "train loss:0.02368682728116151\n",
      "train loss:0.0621632740597266\n",
      "train loss:0.059930886572707794\n",
      "train loss:0.09024070533733738\n",
      "train loss:0.03497325845646132\n",
      "train loss:0.0871307206620345\n",
      "train loss:0.02565592528015455\n",
      "train loss:0.12336059181434907\n",
      "train loss:0.03808471916681392\n",
      "train loss:0.11194999952847809\n",
      "train loss:0.04382110397476405\n",
      "train loss:0.06670264760626267\n",
      "train loss:0.12524594172967285\n",
      "train loss:0.06423305405321844\n",
      "train loss:0.051772337802269155\n",
      "train loss:0.04498436216998442\n",
      "train loss:0.09512210452378883\n",
      "train loss:0.08687477027598617\n",
      "train loss:0.04440227497476465\n",
      "train loss:0.026444747002541423\n",
      "train loss:0.03896759026613043\n",
      "train loss:0.09461217687361936\n",
      "train loss:0.13155095614421147\n",
      "train loss:0.0699927397329661\n",
      "train loss:0.06774373935897915\n",
      "train loss:0.06577468813156238\n",
      "train loss:0.03449814272703061\n",
      "train loss:0.16095687076227158\n",
      "train loss:0.13897775792386935\n",
      "train loss:0.026271919409794463\n",
      "train loss:0.08317889626275915\n",
      "train loss:0.16613114205305465\n",
      "train loss:0.10880317999914708\n",
      "train loss:0.18196684210709846\n",
      "=== epoch:3, train acc:0.979, test acc:0.974 ===\n",
      "train loss:0.0572961890966908\n",
      "train loss:0.042326322003594485\n",
      "train loss:0.02402959586304554\n",
      "train loss:0.038341347121309724\n",
      "train loss:0.05805130337530304\n",
      "train loss:0.06790319035472839\n",
      "train loss:0.09347990218060374\n",
      "train loss:0.044222741187209154\n",
      "train loss:0.09952634620712669\n",
      "train loss:0.04540712016515767\n",
      "train loss:0.17408192612439893\n",
      "train loss:0.08184058333918735\n",
      "train loss:0.08698554975894134\n",
      "train loss:0.032178488355603004\n",
      "train loss:0.0660737665121426\n",
      "train loss:0.035014500010720685\n",
      "train loss:0.009054916543901384\n",
      "train loss:0.03711634711197033\n",
      "train loss:0.25326423906928003\n",
      "train loss:0.07878647735053859\n",
      "train loss:0.1451420351108443\n",
      "train loss:0.03402547562841102\n",
      "train loss:0.08321158200865533\n",
      "train loss:0.06852991679037992\n",
      "train loss:0.07030755472491579\n",
      "train loss:0.037112576514485185\n",
      "train loss:0.04710212357821562\n",
      "train loss:0.08390106253026851\n",
      "train loss:0.02264851887349255\n",
      "train loss:0.057343011577686544\n",
      "train loss:0.07129233109593391\n",
      "train loss:0.02754496178805961\n",
      "train loss:0.035011547381489184\n",
      "train loss:0.059925462472501946\n",
      "train loss:0.022812940299969265\n",
      "train loss:0.04528047708445241\n",
      "train loss:0.02620643383835951\n",
      "train loss:0.08086945763885268\n",
      "train loss:0.04749011880923206\n",
      "train loss:0.06052252692127043\n",
      "train loss:0.07274530129566814\n",
      "train loss:0.06730289511922408\n",
      "train loss:0.07026384769199347\n",
      "train loss:0.09341121764026461\n",
      "train loss:0.019809017222577597\n",
      "train loss:0.0489367180951508\n",
      "train loss:0.18690803744224826\n",
      "train loss:0.040716831748100424\n",
      "train loss:0.037739958312360496\n",
      "train loss:0.03207362289375097\n",
      "train loss:0.046831664521556675\n",
      "train loss:0.05169716977165754\n",
      "train loss:0.04353640375064534\n",
      "train loss:0.025518754665985716\n",
      "train loss:0.05290127989296617\n",
      "train loss:0.05312797819958031\n",
      "train loss:0.04823768431813358\n",
      "train loss:0.05201943128449432\n",
      "train loss:0.051681114622690795\n",
      "train loss:0.05158928741582987\n",
      "train loss:0.05152530079095885\n",
      "train loss:0.02147406155888137\n",
      "train loss:0.06875145437883391\n",
      "train loss:0.09529598023198663\n",
      "train loss:0.01719606399467624\n",
      "train loss:0.04165707191945521\n",
      "train loss:0.10240694941764465\n",
      "train loss:0.03182917866579984\n",
      "train loss:0.07181831312270714\n",
      "train loss:0.036958113932704095\n",
      "train loss:0.03378977622545827\n",
      "train loss:0.047750793821792696\n",
      "train loss:0.10689897242021652\n",
      "train loss:0.01745066870368572\n",
      "train loss:0.06777495396593888\n",
      "train loss:0.057943680502180184\n",
      "train loss:0.06245500379436345\n",
      "train loss:0.013191867330684321\n",
      "train loss:0.008726655761728064\n",
      "train loss:0.07174910405482972\n",
      "train loss:0.11265798196060241\n",
      "train loss:0.018005376274938555\n",
      "train loss:0.04754287774041594\n",
      "train loss:0.05278652343297781\n",
      "train loss:0.021756064869411527\n",
      "train loss:0.03322236259030928\n",
      "train loss:0.06478306838684754\n",
      "train loss:0.045375218637388644\n",
      "train loss:0.06134497210143814\n",
      "train loss:0.017187780968072792\n",
      "train loss:0.01793030346813711\n",
      "train loss:0.040170346775958946\n",
      "train loss:0.027935238514977017\n",
      "train loss:0.04521848122104553\n",
      "train loss:0.09794446422828104\n",
      "train loss:0.12026225752862878\n",
      "train loss:0.020071568564235448\n",
      "train loss:0.020697095950683884\n",
      "train loss:0.035460753035776456\n",
      "train loss:0.07913781405690537\n",
      "train loss:0.0676471575944461\n",
      "train loss:0.030777603110408877\n",
      "train loss:0.03724156939129446\n",
      "train loss:0.0457865079582181\n",
      "train loss:0.06489928974739309\n",
      "train loss:0.023701617047107854\n",
      "train loss:0.021635743757450684\n",
      "train loss:0.03767061906168719\n",
      "train loss:0.05303416209327767\n",
      "train loss:0.044551593097293\n",
      "train loss:0.046200492543111184\n",
      "train loss:0.025523886623617417\n",
      "train loss:0.014756871376343067\n",
      "train loss:0.09180507661535563\n",
      "train loss:0.04428632597193431\n",
      "train loss:0.035888860244875816\n",
      "train loss:0.022535090781727024\n",
      "train loss:0.026697810451160014\n",
      "train loss:0.05469962443326077\n",
      "train loss:0.031292986195611695\n",
      "train loss:0.043698707940194065\n",
      "train loss:0.03707692159783691\n",
      "train loss:0.03413432431270771\n",
      "train loss:0.06826804091302223\n",
      "train loss:0.05088045746931497\n",
      "train loss:0.02655363943266542\n",
      "train loss:0.08227322626014416\n",
      "train loss:0.07590601106515127\n",
      "train loss:0.0564176704034957\n",
      "train loss:0.04586906101607452\n",
      "train loss:0.010617230475552504\n",
      "train loss:0.08087401837898447\n",
      "train loss:0.08333883309998093\n",
      "train loss:0.06073109552074806\n",
      "train loss:0.014494550015326214\n",
      "train loss:0.06401946577163566\n",
      "train loss:0.12825442547461038\n",
      "train loss:0.0463016480300131\n",
      "train loss:0.03449455206170152\n",
      "train loss:0.0446750464162211\n",
      "train loss:0.03378193728716591\n",
      "train loss:0.04362680098071341\n",
      "train loss:0.04077127211348104\n",
      "train loss:0.040824984961324126\n",
      "train loss:0.054843767540503796\n",
      "train loss:0.14124272402613114\n",
      "train loss:0.06758544984004121\n",
      "train loss:0.08124355884347112\n",
      "train loss:0.021176668256724925\n",
      "train loss:0.04290452492333956\n",
      "train loss:0.02611652118200127\n",
      "train loss:0.0872748736564714\n",
      "train loss:0.041883113259130134\n",
      "train loss:0.053073170984451065\n",
      "train loss:0.07326746800302111\n",
      "train loss:0.10002406301012969\n",
      "train loss:0.07588530483939429\n",
      "train loss:0.0945418268723989\n",
      "train loss:0.04957927583897603\n",
      "train loss:0.033366406375780866\n",
      "train loss:0.03729679498522153\n",
      "train loss:0.13250541641669994\n",
      "train loss:0.033706991070219586\n",
      "train loss:0.02623830444134141\n",
      "train loss:0.10285653373464985\n",
      "train loss:0.03836811287022515\n",
      "train loss:0.10690832011662646\n",
      "train loss:0.021718597079753064\n",
      "train loss:0.06793621314312445\n",
      "train loss:0.11543999849253497\n",
      "train loss:0.06317590195212039\n",
      "train loss:0.020631332196418804\n",
      "train loss:0.04748607119306633\n",
      "train loss:0.015925302826353106\n",
      "train loss:0.027105049558022412\n",
      "train loss:0.025998325635505606\n",
      "train loss:0.03650926187918688\n",
      "train loss:0.03420359715159746\n",
      "train loss:0.08384767448484898\n",
      "train loss:0.11562803450511859\n",
      "train loss:0.03585258830615429\n",
      "train loss:0.02443412044604688\n",
      "train loss:0.09997473324792004\n",
      "train loss:0.027227129360330005\n",
      "train loss:0.046050634560096636\n",
      "train loss:0.07704896185973645\n",
      "train loss:0.06843787108682184\n",
      "train loss:0.07517198390237524\n",
      "train loss:0.059433819198907646\n",
      "train loss:0.0902564839339597\n",
      "train loss:0.021827187229039112\n",
      "train loss:0.11422758091286006\n",
      "train loss:0.026820774413087663\n",
      "train loss:0.027364453761457935\n",
      "train loss:0.04579621060288835\n",
      "train loss:0.1275754424920425\n",
      "train loss:0.04795362718257157\n",
      "train loss:0.06636694693863482\n",
      "train loss:0.06949439430191597\n",
      "train loss:0.06179075456231811\n",
      "train loss:0.037953215069014355\n",
      "train loss:0.02842921525101364\n",
      "train loss:0.09999426983887244\n",
      "train loss:0.1115290745425514\n",
      "train loss:0.03065738944832741\n",
      "train loss:0.05174361370956881\n",
      "train loss:0.03824187237627686\n",
      "train loss:0.11893308059306079\n",
      "train loss:0.04195855845052645\n",
      "train loss:0.09344151879631252\n",
      "train loss:0.054960252734822135\n",
      "train loss:0.022513885713701706\n",
      "train loss:0.058202788075142\n",
      "train loss:0.019065221234168997\n",
      "train loss:0.036658274372404494\n",
      "train loss:0.062398132318162006\n",
      "train loss:0.0415463773794857\n",
      "train loss:0.035964114324441965\n",
      "train loss:0.01735606708579388\n",
      "train loss:0.022250966120608485\n",
      "train loss:0.06287566286336667\n",
      "train loss:0.06934394020789851\n",
      "train loss:0.06696857103242287\n",
      "train loss:0.04965574751197033\n",
      "train loss:0.03578613790500227\n",
      "train loss:0.053153720774452046\n",
      "train loss:0.044541692389260513\n",
      "train loss:0.01418430337797684\n",
      "train loss:0.017011931667282355\n",
      "train loss:0.03358622601175783\n",
      "train loss:0.022229731352395664\n",
      "train loss:0.09780703032891264\n",
      "train loss:0.05976187716946039\n",
      "train loss:0.0692568368746162\n",
      "train loss:0.06993929341568732\n",
      "train loss:0.038183088281713636\n",
      "train loss:0.05097759368060534\n",
      "train loss:0.018767400458381805\n",
      "train loss:0.09517710105555496\n",
      "train loss:0.02246390236231209\n",
      "train loss:0.023569470968637075\n",
      "train loss:0.01518747121670932\n",
      "train loss:0.04072880259713191\n",
      "train loss:0.07475988439916577\n",
      "train loss:0.028791189031527966\n",
      "train loss:0.04653415896140666\n",
      "train loss:0.08591365843640936\n",
      "train loss:0.020622426225335576\n",
      "train loss:0.10522942806422765\n",
      "train loss:0.019760330854921477\n",
      "train loss:0.028922810739725052\n",
      "train loss:0.08649183432900605\n",
      "train loss:0.03049075224394753\n",
      "train loss:0.0368642716257629\n",
      "train loss:0.08559952200823842\n",
      "train loss:0.11871407567113333\n",
      "train loss:0.05420391091465984\n",
      "train loss:0.020417839246908306\n",
      "train loss:0.026328769781414615\n",
      "train loss:0.015582137761559972\n",
      "train loss:0.14091926387368717\n",
      "train loss:0.10451019591091587\n",
      "train loss:0.07046609829037312\n",
      "train loss:0.037127297178174236\n",
      "train loss:0.0730632148096278\n",
      "train loss:0.013840528978013338\n",
      "train loss:0.09071447664445069\n",
      "train loss:0.08306971352136258\n",
      "train loss:0.03978003353795367\n",
      "train loss:0.02821931419837157\n",
      "train loss:0.015100452887817903\n",
      "train loss:0.012000213905611401\n",
      "train loss:0.054735346083121215\n",
      "train loss:0.04781531666136928\n",
      "train loss:0.05615157935437348\n",
      "train loss:0.05120170613266653\n",
      "train loss:0.026960851471946056\n",
      "train loss:0.10847847127417463\n",
      "train loss:0.04394675205447121\n",
      "train loss:0.09592013744095444\n",
      "train loss:0.031757208402349\n",
      "train loss:0.02873275195346631\n",
      "train loss:0.030324787641469966\n",
      "train loss:0.08484549192353592\n",
      "train loss:0.14270845411096336\n",
      "train loss:0.12341756492023745\n",
      "train loss:0.015960738116356055\n",
      "train loss:0.022665875568894166\n",
      "train loss:0.01643876135317065\n",
      "train loss:0.20785525929603232\n",
      "train loss:0.03394497339066808\n",
      "train loss:0.011886665279447255\n",
      "train loss:0.01086639060530515\n",
      "train loss:0.038835403743335155\n",
      "train loss:0.0695628446545473\n",
      "train loss:0.05065023652903176\n",
      "train loss:0.03550960756717705\n",
      "train loss:0.046944228285225195\n",
      "train loss:0.10215585913166851\n",
      "train loss:0.049605323729981804\n",
      "train loss:0.1004554183636224\n",
      "train loss:0.09375205255942756\n",
      "train loss:0.036698753928858026\n",
      "train loss:0.08453573502392672\n",
      "train loss:0.060896296479264395\n",
      "train loss:0.004248593956861012\n",
      "train loss:0.02960169306906433\n",
      "train loss:0.02131874294285453\n",
      "train loss:0.10103478344634657\n",
      "train loss:0.03600130121830995\n",
      "train loss:0.02011828191876726\n",
      "train loss:0.0360246083146442\n",
      "train loss:0.15521362502784283\n",
      "train loss:0.039012289738116504\n",
      "train loss:0.06731180532554984\n",
      "train loss:0.04716465490188284\n",
      "train loss:0.06637716826283485\n",
      "train loss:0.04245515775084243\n",
      "train loss:0.007090533451538102\n",
      "train loss:0.026286785102254736\n",
      "train loss:0.05148776508847174\n",
      "train loss:0.06906714827703436\n",
      "train loss:0.02651240250145875\n",
      "train loss:0.047102091971166944\n",
      "train loss:0.04842078844724844\n",
      "train loss:0.018525115982669472\n",
      "train loss:0.1079086763680623\n",
      "train loss:0.014997034889559765\n",
      "train loss:0.03463301641762631\n",
      "train loss:0.024921505367687575\n",
      "train loss:0.06091165564071692\n",
      "train loss:0.04878198915163237\n",
      "train loss:0.029770006516992936\n",
      "train loss:0.028255163067131127\n",
      "train loss:0.02353983144185009\n",
      "train loss:0.09256054301509511\n",
      "train loss:0.06769222451749521\n",
      "train loss:0.06815403923237755\n",
      "train loss:0.09677112256579239\n",
      "train loss:0.05914260379088763\n",
      "train loss:0.05116888474482639\n",
      "train loss:0.07403126280815804\n",
      "train loss:0.0980960375795224\n",
      "train loss:0.035692316043602526\n",
      "train loss:0.0383539736413873\n",
      "train loss:0.05136712425916716\n",
      "train loss:0.03695340799976228\n",
      "train loss:0.0632755819157813\n",
      "train loss:0.06555092076975545\n",
      "train loss:0.10159527292140305\n",
      "train loss:0.03517342237788406\n",
      "train loss:0.10826533606609087\n",
      "train loss:0.01272262375084815\n",
      "train loss:0.045734044213719835\n",
      "train loss:0.02322103606313299\n",
      "train loss:0.07680308298665059\n",
      "train loss:0.06766674157688998\n",
      "train loss:0.020720332561170972\n",
      "train loss:0.05962167202013197\n",
      "train loss:0.05726662365255325\n",
      "train loss:0.02094825937890503\n",
      "train loss:0.02247559576861733\n",
      "train loss:0.05478485280037963\n",
      "train loss:0.15341514673685122\n",
      "train loss:0.015000610843403775\n",
      "train loss:0.05329294679664722\n",
      "train loss:0.04747240991957821\n",
      "train loss:0.0296223154790117\n",
      "train loss:0.020715541869707376\n",
      "train loss:0.03272034149557026\n",
      "train loss:0.021178316665960758\n",
      "train loss:0.10931648255025024\n",
      "train loss:0.02792900478057539\n",
      "train loss:0.13975361679068707\n",
      "train loss:0.04224908214054958\n",
      "train loss:0.022129607295020132\n",
      "train loss:0.016169737469792132\n",
      "train loss:0.031925210986751405\n",
      "train loss:0.021904344355002225\n",
      "train loss:0.03319477499122463\n",
      "train loss:0.038384097833604025\n",
      "train loss:0.008191870329847637\n",
      "train loss:0.04330733691299922\n",
      "train loss:0.004913506824961852\n",
      "train loss:0.0282964271674321\n",
      "train loss:0.04254940284204561\n",
      "train loss:0.02962135878167052\n",
      "train loss:0.03943226893681036\n",
      "train loss:0.04804685150617835\n",
      "train loss:0.008995925519906798\n",
      "train loss:0.016011319954094227\n",
      "train loss:0.029754096628366825\n",
      "train loss:0.023173660481392085\n",
      "train loss:0.10397901249886818\n",
      "train loss:0.14679736155011763\n",
      "train loss:0.017303945428215287\n",
      "train loss:0.12539913824358304\n",
      "train loss:0.05806914575303928\n",
      "train loss:0.028893720431014278\n",
      "train loss:0.03772605738624566\n",
      "train loss:0.025688350775127412\n",
      "train loss:0.07893812289166868\n",
      "train loss:0.042711391461465756\n",
      "train loss:0.03532205350900917\n",
      "train loss:0.027282022984887185\n",
      "train loss:0.027933529976749985\n",
      "train loss:0.024166593634424097\n",
      "train loss:0.04673282010480042\n",
      "train loss:0.05799626326009014\n",
      "train loss:0.1017697357760625\n",
      "train loss:0.04876284081291498\n",
      "train loss:0.04030526542305034\n",
      "train loss:0.034825147135439535\n",
      "train loss:0.08147603074478013\n",
      "train loss:0.030530395549785358\n",
      "train loss:0.10068866092952586\n",
      "train loss:0.025971958327399736\n",
      "train loss:0.046592398921825096\n",
      "train loss:0.023403743116537853\n",
      "train loss:0.04013519452552242\n",
      "train loss:0.09062799183014718\n",
      "train loss:0.020306253437035262\n",
      "train loss:0.08859645060303784\n",
      "train loss:0.05237624486517374\n",
      "train loss:0.034183550321888335\n",
      "train loss:0.10743886929595044\n",
      "train loss:0.03505128268468195\n",
      "train loss:0.03030410698519928\n",
      "train loss:0.0151130415998586\n",
      "train loss:0.08985974609574555\n",
      "train loss:0.028179955046917376\n",
      "train loss:0.04134261315010147\n",
      "train loss:0.06836653767910203\n",
      "train loss:0.06429115545714845\n",
      "train loss:0.07803554321616234\n",
      "train loss:0.05052564490190911\n",
      "train loss:0.04245114128233706\n",
      "train loss:0.05177752794657314\n",
      "train loss:0.07360639627671511\n",
      "train loss:0.039353486845560046\n",
      "train loss:0.04204775077550706\n",
      "train loss:0.020136126243083807\n",
      "train loss:0.017907265343954325\n",
      "train loss:0.06240033602107741\n",
      "train loss:0.03176684954269934\n",
      "train loss:0.03700076478585538\n",
      "train loss:0.024979179961936767\n",
      "train loss:0.017667330201582402\n",
      "train loss:0.010271105072578002\n",
      "train loss:0.018971052550940913\n",
      "train loss:0.02389540736574931\n",
      "train loss:0.038072363128051456\n",
      "train loss:0.09511257901307299\n",
      "train loss:0.052087110868882285\n",
      "train loss:0.05255645710875296\n",
      "train loss:0.09095077622485666\n",
      "train loss:0.066120672214051\n",
      "train loss:0.09490638621642324\n",
      "train loss:0.05374385691290991\n",
      "train loss:0.04942415315003891\n",
      "train loss:0.03996574900560245\n",
      "train loss:0.045631708689737406\n",
      "train loss:0.023480574502666888\n",
      "train loss:0.08076496889142627\n",
      "train loss:0.09119592378824938\n",
      "train loss:0.03460818679624959\n",
      "train loss:0.029209166034291092\n",
      "train loss:0.025037469174790584\n",
      "train loss:0.0133598673496644\n",
      "train loss:0.044914251817004106\n",
      "train loss:0.0876920569999431\n",
      "train loss:0.049913569429920174\n",
      "train loss:0.04520912608531659\n",
      "train loss:0.019996319598112353\n",
      "train loss:0.08079610844085161\n",
      "train loss:0.10144314993424564\n",
      "train loss:0.027306256689230323\n",
      "train loss:0.03742592928120667\n",
      "train loss:0.023276750318080994\n",
      "train loss:0.0619917284607115\n",
      "train loss:0.019606946578335983\n",
      "train loss:0.015202378309040492\n",
      "train loss:0.027027163750814435\n",
      "train loss:0.1282221397372963\n",
      "train loss:0.02553423677450444\n",
      "train loss:0.05033686871726264\n",
      "train loss:0.01591543723932274\n",
      "train loss:0.032801154804973864\n",
      "train loss:0.029220128513868775\n",
      "train loss:0.02421449890608891\n",
      "train loss:0.020829137835259366\n",
      "train loss:0.05953686383101133\n",
      "train loss:0.03217008316350076\n",
      "train loss:0.04431170550728665\n",
      "train loss:0.030021546933037678\n",
      "train loss:0.039743796752171726\n",
      "train loss:0.009270232192839215\n",
      "train loss:0.04398086718408217\n",
      "train loss:0.030399447788279\n",
      "train loss:0.047628008515688804\n",
      "train loss:0.04772096248318865\n",
      "train loss:0.06909616910596107\n",
      "train loss:0.020580462384071657\n",
      "train loss:0.04313660062320429\n",
      "train loss:0.04604285849633787\n",
      "train loss:0.06228280721014886\n",
      "train loss:0.11514932767524572\n",
      "train loss:0.033441785725876375\n",
      "train loss:0.03189121283952621\n",
      "train loss:0.03685648767742018\n",
      "train loss:0.022822558362876708\n",
      "train loss:0.030939301730318627\n",
      "train loss:0.018987441683891083\n",
      "train loss:0.04189248578342707\n",
      "train loss:0.029747627571629683\n",
      "train loss:0.04282031279351366\n",
      "train loss:0.060139855396161644\n",
      "train loss:0.023473333411992443\n",
      "train loss:0.0547542040222491\n",
      "train loss:0.015754727314564475\n",
      "train loss:0.01796162402151869\n",
      "train loss:0.038290876488484435\n",
      "train loss:0.023786443982658775\n",
      "train loss:0.031242113165338342\n",
      "train loss:0.02353165909011675\n",
      "train loss:0.07800573335432408\n",
      "train loss:0.009373917099511917\n",
      "train loss:0.04547432592211018\n",
      "train loss:0.04102748093870196\n",
      "train loss:0.05291649524758871\n",
      "train loss:0.02150983260651401\n",
      "train loss:0.03637761283045995\n",
      "train loss:0.06569590166939361\n",
      "train loss:0.019350647338381478\n",
      "train loss:0.02389319868657363\n",
      "train loss:0.01664746378627267\n",
      "train loss:0.03278570838636854\n",
      "train loss:0.062309414840420956\n",
      "train loss:0.01857745597874901\n",
      "train loss:0.007657002647201273\n",
      "train loss:0.04800094991909129\n",
      "train loss:0.014297326431604416\n",
      "train loss:0.0924843709257381\n",
      "train loss:0.01667701164923562\n",
      "train loss:0.04561391164610382\n",
      "train loss:0.022797131781226374\n",
      "train loss:0.052085551054873516\n",
      "train loss:0.038944685802155606\n",
      "train loss:0.03969096656909531\n",
      "train loss:0.034614832937310366\n",
      "train loss:0.01256293195134809\n",
      "train loss:0.05607890524864603\n",
      "train loss:0.043156116210122004\n",
      "train loss:0.020355477254424662\n",
      "train loss:0.006762356428916766\n",
      "train loss:0.05103960832862259\n",
      "train loss:0.14372796024746756\n",
      "train loss:0.018390902409195463\n",
      "train loss:0.0748662374124877\n",
      "train loss:0.03143579571906677\n",
      "train loss:0.07771058725606475\n",
      "train loss:0.03058256185384223\n",
      "train loss:0.019918950055969692\n",
      "train loss:0.025381138169579907\n",
      "train loss:0.056851404214887005\n",
      "train loss:0.052140333167504126\n",
      "train loss:0.06216885338153145\n",
      "train loss:0.021847362022019735\n",
      "train loss:0.06357317721680465\n",
      "train loss:0.03797960514578555\n",
      "train loss:0.02320129314249226\n",
      "train loss:0.08923154428538291\n",
      "train loss:0.14146845731299287\n",
      "train loss:0.036291648885264\n",
      "train loss:0.022175744866881925\n",
      "train loss:0.02428948495999375\n",
      "train loss:0.03212395602531462\n",
      "train loss:0.020506432892484498\n",
      "train loss:0.031667336581940354\n",
      "train loss:0.0478958091427205\n",
      "train loss:0.03689525877895208\n",
      "train loss:0.03167509155519842\n",
      "train loss:0.015371575346019939\n",
      "train loss:0.020589900846037342\n",
      "train loss:0.05860032157653712\n",
      "train loss:0.007184862006404906\n",
      "train loss:0.042434300894667085\n",
      "train loss:0.056435275426578724\n",
      "train loss:0.05438498646064956\n",
      "train loss:0.07196751260128581\n",
      "train loss:0.03449927783669078\n",
      "train loss:0.01327969338764386\n",
      "train loss:0.04054460128029718\n",
      "train loss:0.04748625930548295\n",
      "train loss:0.05858692810544927\n",
      "train loss:0.017803191280249653\n",
      "train loss:0.00988731766726213\n",
      "train loss:0.060302138497153115\n",
      "train loss:0.06151715520689601\n",
      "train loss:0.0067708192497863764\n",
      "=== epoch:4, train acc:0.984, test acc:0.986 ===\n",
      "train loss:0.02412463340474805\n",
      "train loss:0.02907035205847198\n",
      "train loss:0.011499621375880205\n",
      "train loss:0.029713739848644945\n",
      "train loss:0.05521513630882691\n",
      "train loss:0.03496708212696417\n",
      "train loss:0.08169340384603861\n",
      "train loss:0.04880221214562268\n",
      "train loss:0.021058196865770627\n",
      "train loss:0.07888329252522638\n",
      "train loss:0.03497357813549245\n",
      "train loss:0.019500643452520127\n",
      "train loss:0.06503863017578997\n",
      "train loss:0.02433034513665176\n",
      "train loss:0.023555130167917247\n",
      "train loss:0.010948269841070161\n",
      "train loss:0.04315650545246502\n",
      "train loss:0.006534870996646385\n",
      "train loss:0.02439693713336649\n",
      "train loss:0.009676641880217673\n",
      "train loss:0.05671512045327577\n",
      "train loss:0.019952314166313684\n",
      "train loss:0.02869563895902713\n",
      "train loss:0.08855310336264935\n",
      "train loss:0.08291751593556128\n",
      "train loss:0.028881168314817844\n",
      "train loss:0.08073501597810102\n",
      "train loss:0.07695193648230159\n",
      "train loss:0.04486014850526361\n",
      "train loss:0.0345053104144982\n",
      "train loss:0.02382199557109098\n",
      "train loss:0.007314279549938098\n",
      "train loss:0.07125180185611693\n",
      "train loss:0.015127575853922808\n",
      "train loss:0.013030164082970775\n",
      "train loss:0.018641612379284463\n",
      "train loss:0.005914128259237092\n",
      "train loss:0.017929993310069642\n",
      "train loss:0.0871503176471356\n",
      "train loss:0.028085584639880746\n",
      "train loss:0.020643447371601033\n",
      "train loss:0.0884500568708599\n",
      "train loss:0.04358551091063847\n",
      "train loss:0.03243282553194619\n",
      "train loss:0.019655715825119945\n",
      "train loss:0.03895608191153342\n",
      "train loss:0.036042635389397504\n",
      "train loss:0.03968079791674981\n",
      "train loss:0.02735208195681897\n",
      "train loss:0.025520485978719382\n",
      "train loss:0.014192583614624743\n",
      "train loss:0.046404743702128604\n",
      "train loss:0.07052917036622727\n",
      "train loss:0.020302603058578225\n",
      "train loss:0.08014272975642658\n",
      "train loss:0.022217662147731555\n",
      "train loss:0.03138297891258256\n",
      "train loss:0.02824796880076638\n",
      "train loss:0.052299769573243886\n",
      "train loss:0.06215730399139938\n",
      "train loss:0.01792139620679574\n",
      "train loss:0.029121161792259667\n",
      "train loss:0.010423656783249849\n",
      "train loss:0.007032638636156923\n",
      "train loss:0.021442616479384197\n",
      "train loss:0.014978850716296342\n",
      "train loss:0.01968025258669343\n",
      "train loss:0.027444064212709073\n",
      "train loss:0.015702248563956488\n",
      "train loss:0.05452938139719941\n",
      "train loss:0.05475761934514368\n",
      "train loss:0.0445517213554707\n",
      "train loss:0.05669069158806733\n",
      "train loss:0.007088715911147756\n",
      "train loss:0.027136336026659828\n",
      "train loss:0.041747245542910844\n",
      "train loss:0.058350435358046876\n",
      "train loss:0.024460527372532723\n",
      "train loss:0.03059083335555173\n",
      "train loss:0.009642905257387934\n",
      "train loss:0.03785225451055447\n",
      "train loss:0.09414426487533448\n",
      "train loss:0.04103058306945666\n",
      "train loss:0.019253942013352236\n",
      "train loss:0.011246719434816164\n",
      "train loss:0.04300843156742252\n",
      "train loss:0.020842114652521806\n",
      "train loss:0.013720626598114485\n",
      "train loss:0.0470558262969091\n",
      "train loss:0.020103951050270883\n",
      "train loss:0.020665216444975577\n",
      "train loss:0.03601857845948954\n",
      "train loss:0.04297706067216521\n",
      "train loss:0.04604656779839735\n",
      "train loss:0.01147602956088831\n",
      "train loss:0.039409116865576584\n",
      "train loss:0.054033038766843\n",
      "train loss:0.012679892471453538\n",
      "train loss:0.0076988670288746465\n",
      "train loss:0.032856708317618964\n",
      "train loss:0.07580515833104101\n",
      "train loss:0.05342331729155772\n",
      "train loss:0.014319611575646698\n",
      "train loss:0.00899992821530031\n",
      "train loss:0.02730635892213061\n",
      "train loss:0.010779922677757521\n",
      "train loss:0.058523944292105654\n",
      "train loss:0.06478940883888469\n",
      "train loss:0.14608609360262717\n",
      "train loss:0.06307849209106044\n",
      "train loss:0.022191729767352397\n",
      "train loss:0.01710200368163238\n",
      "train loss:0.03559828919151481\n",
      "train loss:0.019276871780451652\n",
      "train loss:0.029344931072398456\n",
      "train loss:0.018557370752597824\n",
      "train loss:0.025326788865045368\n",
      "train loss:0.019242688435413945\n",
      "train loss:0.024172958651271705\n",
      "train loss:0.018899379081049605\n",
      "train loss:0.010831580520906003\n",
      "train loss:0.04430803861060112\n",
      "train loss:0.06551283682271825\n",
      "train loss:0.040879234306984216\n",
      "train loss:0.021926561419863475\n",
      "train loss:0.05482206448311138\n",
      "train loss:0.03885939248820697\n",
      "train loss:0.03618378826452158\n",
      "train loss:0.009867102928929087\n",
      "train loss:0.05899804749688503\n",
      "train loss:0.03474852494601185\n",
      "train loss:0.021951331473327902\n",
      "train loss:0.13029744379618166\n",
      "train loss:0.016683910825502288\n",
      "train loss:0.04827655328004475\n",
      "train loss:0.05026203378998829\n",
      "train loss:0.025551657945138927\n",
      "train loss:0.01627808823072401\n",
      "train loss:0.06947083325563957\n",
      "train loss:0.01538848670042444\n",
      "train loss:0.0680928686525425\n",
      "train loss:0.010399099089735195\n",
      "train loss:0.11633677013383698\n",
      "train loss:0.03217536418421954\n",
      "train loss:0.023261199293962417\n",
      "train loss:0.03688375975384895\n",
      "train loss:0.06537418420618868\n",
      "train loss:0.02081193618740301\n",
      "train loss:0.015429134822963092\n",
      "train loss:0.05909077454609027\n",
      "train loss:0.009102469638999732\n",
      "train loss:0.05843920033759534\n",
      "train loss:0.03837701612444995\n",
      "train loss:0.04392651685622379\n",
      "train loss:0.047244809590612544\n",
      "train loss:0.0584712111124891\n",
      "train loss:0.012488902054424086\n",
      "train loss:0.01617500691366788\n",
      "train loss:0.0788479879507823\n",
      "train loss:0.02037544801311399\n",
      "train loss:0.01516413730441502\n",
      "train loss:0.023201447830356464\n",
      "train loss:0.016689150279752\n",
      "train loss:0.03569711991035645\n",
      "train loss:0.09804240313297935\n",
      "train loss:0.02813255614721823\n",
      "train loss:0.029060674369190277\n",
      "train loss:0.04822185800929669\n",
      "train loss:0.029260639246679515\n",
      "train loss:0.041729697341966146\n",
      "train loss:0.05986431117883197\n",
      "train loss:0.008093226830214219\n",
      "train loss:0.04063560264270344\n",
      "train loss:0.06184238829868905\n",
      "train loss:0.03447703973629938\n",
      "train loss:0.05594160334893031\n",
      "train loss:0.02076285069020229\n",
      "train loss:0.015461433017340355\n",
      "train loss:0.016930492318867382\n",
      "train loss:0.035793465722219475\n",
      "train loss:0.013298297076318253\n",
      "train loss:0.018703119714826265\n",
      "train loss:0.008058672101177286\n",
      "train loss:0.01853116113045218\n",
      "train loss:0.020435527898388147\n",
      "train loss:0.013882678608736326\n",
      "train loss:0.01326588829748289\n",
      "train loss:0.020175621823653775\n",
      "train loss:0.015645529407101094\n",
      "train loss:0.07458904335657185\n",
      "train loss:0.021754035833392308\n",
      "train loss:0.015323881434466566\n",
      "train loss:0.0984914501632467\n",
      "train loss:0.02522573300172681\n",
      "train loss:0.009930045058476384\n",
      "train loss:0.026317586642035443\n",
      "train loss:0.033115739360068557\n",
      "train loss:0.05890340499333017\n",
      "train loss:0.03441392027480216\n",
      "train loss:0.018466541781767477\n",
      "train loss:0.03425153666959644\n",
      "train loss:0.0666210121200909\n",
      "train loss:0.06506149121261279\n",
      "train loss:0.04255472102923161\n",
      "train loss:0.055508450561396645\n",
      "train loss:0.00763640360830469\n",
      "train loss:0.014411391391780867\n",
      "train loss:0.014166840529418407\n",
      "train loss:0.08105970362241104\n",
      "train loss:0.021304705081067018\n",
      "train loss:0.01431661813548193\n",
      "train loss:0.018556890565049083\n",
      "train loss:0.04364879687372073\n",
      "train loss:0.017472698704314657\n",
      "train loss:0.029435097397928822\n",
      "train loss:0.1629791378536086\n",
      "train loss:0.01887853642424906\n",
      "train loss:0.03926868147649007\n",
      "train loss:0.015964530078538517\n",
      "train loss:0.04997127134099245\n",
      "train loss:0.04405238516990205\n",
      "train loss:0.05054299790059736\n",
      "train loss:0.04210046013913406\n",
      "train loss:0.014844637635639583\n",
      "train loss:0.11588008685938878\n",
      "train loss:0.008312157510835522\n",
      "train loss:0.06317178736441659\n",
      "train loss:0.021605115957293797\n",
      "train loss:0.05010277157855919\n",
      "train loss:0.03593514421498771\n",
      "train loss:0.01894172286203066\n",
      "train loss:0.030329644285180576\n",
      "train loss:0.015314724428510418\n",
      "train loss:0.022799773813606584\n",
      "train loss:0.03606764820554639\n",
      "train loss:0.036774803097717294\n",
      "train loss:0.06299118137818484\n",
      "train loss:0.020583127928677905\n",
      "train loss:0.04514596227584245\n",
      "train loss:0.1444829816343319\n",
      "train loss:0.04540786204925687\n",
      "train loss:0.044295165440448175\n",
      "train loss:0.07856998490020366\n",
      "train loss:0.030122216096346303\n",
      "train loss:0.04485955037130249\n",
      "train loss:0.011932090409780277\n",
      "train loss:0.010888969147382738\n",
      "train loss:0.04641770175285285\n",
      "train loss:0.11141807215497389\n",
      "train loss:0.04486117243266159\n",
      "train loss:0.10205131548384587\n",
      "train loss:0.025240762658941797\n",
      "train loss:0.012307782610724554\n",
      "train loss:0.04046803974770616\n",
      "train loss:0.013540808800557868\n",
      "train loss:0.027501607941295303\n",
      "train loss:0.05973131404724873\n",
      "train loss:0.014826892461475514\n",
      "train loss:0.01465827873983997\n",
      "train loss:0.09798750854137125\n",
      "train loss:0.012885767596789539\n",
      "train loss:0.007649767521123554\n",
      "train loss:0.007174898925414834\n",
      "train loss:0.046206882687938294\n",
      "train loss:0.049167681457608456\n",
      "train loss:0.02051969937824418\n",
      "train loss:0.07244585622573592\n",
      "train loss:0.047766062934954084\n",
      "train loss:0.04652723693523177\n",
      "train loss:0.03483540364510081\n",
      "train loss:0.02233499959119993\n",
      "train loss:0.054383381371130246\n",
      "train loss:0.016942508524957055\n",
      "train loss:0.0349924503430747\n",
      "train loss:0.05055425170453454\n",
      "train loss:0.03393831209094845\n",
      "train loss:0.029987313413142824\n",
      "train loss:0.02589958342054581\n",
      "train loss:0.013081818787111192\n",
      "train loss:0.038422864420398814\n",
      "train loss:0.013539110331856946\n",
      "train loss:0.06315965746705857\n",
      "train loss:0.022701993328869755\n",
      "train loss:0.02220931669691717\n",
      "train loss:0.034992785218592434\n",
      "train loss:0.08209063811564002\n",
      "train loss:0.04071119390592037\n",
      "train loss:0.016358845519997837\n",
      "train loss:0.04084377386996927\n",
      "train loss:0.036748572568200806\n",
      "train loss:0.026068433400770138\n",
      "train loss:0.047341205124122904\n",
      "train loss:0.02738771265417318\n",
      "train loss:0.07982367749278794\n",
      "train loss:0.06042749321265271\n",
      "train loss:0.011511278457120846\n",
      "train loss:0.052266468952230236\n",
      "train loss:0.0805668783502559\n",
      "train loss:0.04081901733206849\n",
      "train loss:0.012838888196889407\n",
      "train loss:0.013547399539185592\n",
      "train loss:0.027412085655070723\n",
      "train loss:0.029693048571718568\n",
      "train loss:0.037883599010855584\n",
      "train loss:0.030447377089011716\n",
      "train loss:0.03697405976517173\n",
      "train loss:0.03588951065346609\n",
      "train loss:0.05887398842202594\n",
      "train loss:0.01952662511413512\n",
      "train loss:0.051744994561720575\n",
      "train loss:0.05938094830976398\n",
      "train loss:0.010103391704726582\n",
      "train loss:0.01164679245764528\n",
      "train loss:0.0410667653007293\n",
      "train loss:0.021054031739802956\n",
      "train loss:0.0365391661480837\n",
      "train loss:0.052632440596635056\n",
      "train loss:0.0361701384653597\n",
      "train loss:0.016578440868674084\n",
      "train loss:0.013282709273586728\n",
      "train loss:0.01608218958533754\n",
      "train loss:0.07806944559600386\n",
      "train loss:0.07949206110925926\n",
      "train loss:0.10188354935514149\n",
      "train loss:0.029903364733700113\n",
      "train loss:0.02959108804946034\n",
      "train loss:0.01515633671794502\n",
      "train loss:0.11844645775597339\n",
      "train loss:0.045114492633516946\n",
      "train loss:0.06596801724071226\n",
      "train loss:0.047519286925941706\n",
      "train loss:0.02981913658653937\n",
      "train loss:0.0676360627531092\n",
      "train loss:0.02684381179126508\n",
      "train loss:0.07041606787982496\n",
      "train loss:0.05037346568373088\n",
      "train loss:0.01265850968780031\n",
      "train loss:0.04663246605165787\n",
      "train loss:0.018335714294268043\n",
      "train loss:0.06882372995994643\n",
      "train loss:0.020292601322986464\n",
      "train loss:0.04141203967028475\n",
      "train loss:0.03686168235507996\n",
      "train loss:0.06292082124212303\n",
      "train loss:0.023014449850948943\n",
      "train loss:0.043756783213257384\n",
      "train loss:0.011998946403642304\n",
      "train loss:0.01732537304827346\n",
      "train loss:0.03246466565718834\n",
      "train loss:0.06168167223712996\n",
      "train loss:0.012386025241913241\n",
      "train loss:0.030833308827599333\n",
      "train loss:0.009481522953231009\n",
      "train loss:0.060976063238555575\n",
      "train loss:0.033384450334186556\n",
      "train loss:0.035705528222089236\n",
      "train loss:0.07868410529507658\n",
      "train loss:0.01839503925657529\n",
      "train loss:0.028637119626622895\n",
      "train loss:0.026751322928856798\n",
      "train loss:0.035291109050011225\n",
      "train loss:0.016163402514888646\n",
      "train loss:0.06479626748426384\n",
      "train loss:0.0032147496244039645\n",
      "train loss:0.017982748989507965\n",
      "train loss:0.06337943297744766\n",
      "train loss:0.012550114432690575\n",
      "train loss:0.08084175471096952\n",
      "train loss:0.10955773624419232\n",
      "train loss:0.01838538751084091\n",
      "train loss:0.012480153847952636\n",
      "train loss:0.010120534298982693\n",
      "train loss:0.02421301301490783\n",
      "train loss:0.029042169783129596\n",
      "train loss:0.01978515851167861\n",
      "train loss:0.017316780915842878\n",
      "train loss:0.042470578402014424\n",
      "train loss:0.016025619446121644\n",
      "train loss:0.032261780304665685\n",
      "train loss:0.006773476296961738\n",
      "train loss:0.02608664445469365\n",
      "train loss:0.011062304857089587\n",
      "train loss:0.024177820420697146\n",
      "train loss:0.01660728500549409\n",
      "train loss:0.010161387491357315\n",
      "train loss:0.010363193009262089\n",
      "train loss:0.010133419709541307\n",
      "train loss:0.050485906309346865\n",
      "train loss:0.0715951289959022\n",
      "train loss:0.0214424260146109\n",
      "train loss:0.021365040510514716\n",
      "train loss:0.023161456818327045\n",
      "train loss:0.008153907245518524\n",
      "train loss:0.01981677448293689\n",
      "train loss:0.010471911022020757\n",
      "train loss:0.020310209524198247\n",
      "train loss:0.018058384221484803\n",
      "train loss:0.009356668657467572\n",
      "train loss:0.011868525893719508\n",
      "train loss:0.001318649194104347\n",
      "train loss:0.016424471210815594\n",
      "train loss:0.020586416145127608\n",
      "train loss:0.045617760284437585\n",
      "train loss:0.11983272510295767\n",
      "train loss:0.03182791693203191\n",
      "train loss:0.017841638848520622\n",
      "train loss:0.008841621220700072\n",
      "train loss:0.01809690609866566\n",
      "train loss:0.019402536708396832\n",
      "train loss:0.02729935469334944\n",
      "train loss:0.02268063991152984\n",
      "train loss:0.03383886687139544\n",
      "train loss:0.01751839471451856\n",
      "train loss:0.020508429660755466\n",
      "train loss:0.013731826874673593\n",
      "train loss:0.021615562586177785\n",
      "train loss:0.007489943382711305\n",
      "train loss:0.07753762850730606\n",
      "train loss:0.008892109984089026\n",
      "train loss:0.017313454801344257\n",
      "train loss:0.005302390179542212\n",
      "train loss:0.04505396398017959\n",
      "train loss:0.06472080981242556\n",
      "train loss:0.015730763751010367\n",
      "train loss:0.010080766969432909\n",
      "train loss:0.015344582353842326\n",
      "train loss:0.02020837182387561\n",
      "train loss:0.07134402913548218\n",
      "train loss:0.019145479638131072\n",
      "train loss:0.013517981239569687\n",
      "train loss:0.02512918793833415\n",
      "train loss:0.01789782768174747\n",
      "train loss:0.04554062084605412\n",
      "train loss:0.036466629418636626\n",
      "train loss:0.07004633148789091\n",
      "train loss:0.08605940381628203\n",
      "train loss:0.009484406293630449\n",
      "train loss:0.007619070877743181\n",
      "train loss:0.05429329718404854\n",
      "train loss:0.008657606376688592\n",
      "train loss:0.1860924033973336\n",
      "train loss:0.06059977193231489\n",
      "train loss:0.02816792178109677\n",
      "train loss:0.043900089594589325\n",
      "train loss:0.013412049613109425\n",
      "train loss:0.01468330565654923\n",
      "train loss:0.028352329492498596\n",
      "train loss:0.03174228734684336\n",
      "train loss:0.01389871412298936\n",
      "train loss:0.03553181977434676\n",
      "train loss:0.010390841565915257\n",
      "train loss:0.0197488190834156\n",
      "train loss:0.01548371863678715\n",
      "train loss:0.12347812789186569\n",
      "train loss:0.01588667552837304\n",
      "train loss:0.033227510215004495\n",
      "train loss:0.022809577891128727\n",
      "train loss:0.017121979100826624\n",
      "train loss:0.06154238362012086\n",
      "train loss:0.03413597666920314\n",
      "train loss:0.029692756186776945\n",
      "train loss:0.01661630730647587\n",
      "train loss:0.02962662623857225\n",
      "train loss:0.026581052373734506\n",
      "train loss:0.04789720940295741\n",
      "train loss:0.050528158940961826\n",
      "train loss:0.0037253306978708937\n",
      "train loss:0.011216746754544243\n",
      "train loss:0.04093657975885287\n",
      "train loss:0.012449357812397492\n",
      "train loss:0.026405943211389483\n",
      "train loss:0.01068813361546972\n",
      "train loss:0.004322075214474209\n",
      "train loss:0.04814146026696381\n",
      "train loss:0.014345184456100977\n",
      "train loss:0.006944700531443516\n",
      "train loss:0.027271351163007794\n",
      "train loss:0.19627519741122526\n",
      "train loss:0.011147205107697322\n",
      "train loss:0.0262599433777139\n",
      "train loss:0.04104351009186161\n",
      "train loss:0.07080555605581616\n",
      "train loss:0.04916072042849767\n",
      "train loss:0.02181360894760841\n",
      "train loss:0.027558486763496492\n",
      "train loss:0.046721943196873304\n",
      "train loss:0.018915156554262288\n",
      "train loss:0.014533141183152007\n",
      "train loss:0.03653666866758765\n",
      "train loss:0.1688609604500499\n",
      "train loss:0.02650814175448652\n",
      "train loss:0.016289269602874124\n",
      "train loss:0.06226628535097684\n",
      "train loss:0.025825300581229668\n",
      "train loss:0.01349750041512496\n",
      "train loss:0.029713258415925186\n",
      "train loss:0.01152758327797674\n",
      "train loss:0.05978256956366424\n",
      "train loss:0.02908745551564015\n",
      "train loss:0.05172311689241559\n",
      "train loss:0.05181237841625406\n",
      "train loss:0.04376071828960585\n",
      "train loss:0.022541447619901015\n",
      "train loss:0.01968309136334224\n",
      "train loss:0.014180466264901577\n",
      "train loss:0.06287741507116291\n",
      "train loss:0.011580507485632573\n",
      "train loss:0.01183902640695497\n",
      "train loss:0.029375846479446167\n",
      "train loss:0.02342130390587528\n",
      "train loss:0.011072194259912986\n",
      "train loss:0.009627966466625114\n",
      "train loss:0.03173756221698073\n",
      "train loss:0.07152492561066698\n",
      "train loss:0.031210594772035388\n",
      "train loss:0.01661018164705104\n",
      "train loss:0.06739223606061237\n",
      "train loss:0.01051162651215112\n",
      "train loss:0.021971818236343102\n",
      "train loss:0.06018195327529814\n",
      "train loss:0.02047097689365167\n",
      "train loss:0.029949824477011847\n",
      "train loss:0.027426316269181843\n",
      "train loss:0.027454060223264666\n",
      "train loss:0.013134913202346634\n",
      "train loss:0.009576068898709513\n",
      "train loss:0.059175394024015116\n",
      "train loss:0.10945158723882777\n",
      "train loss:0.05117482270543012\n",
      "train loss:0.016616662249596847\n",
      "train loss:0.03341454302400304\n",
      "train loss:0.03911972162512215\n",
      "train loss:0.020049318673580934\n",
      "train loss:0.029658365479238627\n",
      "train loss:0.0068532135455661395\n",
      "train loss:0.016349899272443773\n",
      "train loss:0.038631211450945904\n",
      "train loss:0.009790954024206624\n",
      "train loss:0.0288320158145714\n",
      "train loss:0.06665488990636118\n",
      "train loss:0.00851124462065805\n",
      "train loss:0.015745125412009627\n",
      "train loss:0.049092410018582874\n",
      "train loss:0.012927288538625603\n",
      "train loss:0.013982186093433187\n",
      "train loss:0.01725566480815155\n",
      "train loss:0.010261307048856843\n",
      "train loss:0.046488378974350215\n",
      "train loss:0.04211363826764548\n",
      "train loss:0.0574878684074692\n",
      "train loss:0.01307794201947731\n",
      "train loss:0.004219448166922644\n",
      "train loss:0.04010046303857226\n",
      "train loss:0.05450517622174598\n",
      "train loss:0.05587960527951589\n",
      "train loss:0.01762208433004533\n",
      "train loss:0.0645139657089628\n",
      "train loss:0.017103241803305313\n",
      "train loss:0.030348737235255406\n",
      "train loss:0.013358071612581427\n",
      "train loss:0.03490056460145408\n",
      "train loss:0.020400408453699094\n",
      "train loss:0.007714818962620345\n",
      "train loss:0.019287356088099842\n",
      "train loss:0.02275752466808047\n",
      "train loss:0.0060490783825635185\n",
      "train loss:0.06796379230021758\n",
      "train loss:0.07473196917271098\n",
      "train loss:0.10330606902554491\n",
      "train loss:0.019827000223017775\n",
      "train loss:0.024149990123017127\n",
      "train loss:0.013737161887867227\n",
      "train loss:0.01795008207945871\n",
      "train loss:0.05766398981048721\n",
      "train loss:0.009119123665306548\n",
      "train loss:0.03025617256824127\n",
      "train loss:0.0480233302323633\n",
      "train loss:0.015100607265065312\n",
      "train loss:0.025894680481694642\n",
      "train loss:0.014070396956445557\n",
      "train loss:0.032380605706467884\n",
      "train loss:0.03235838264645677\n",
      "train loss:0.01855726532592365\n",
      "train loss:0.017781122484907014\n",
      "train loss:0.03223894523254703\n",
      "train loss:0.025186477270949973\n",
      "train loss:0.089973519404046\n",
      "train loss:0.05033560316035223\n",
      "train loss:0.06345517146575602\n",
      "train loss:0.03289479505190979\n",
      "train loss:0.009646349181796729\n",
      "train loss:0.011493028166454571\n",
      "train loss:0.0283623687036125\n",
      "train loss:0.022059081259449366\n",
      "train loss:0.026962208723563665\n",
      "train loss:0.04940506712437302\n",
      "train loss:0.022535224697763482\n",
      "train loss:0.04328601927866264\n",
      "train loss:0.027133952818323207\n",
      "train loss:0.015097426701896944\n",
      "=== epoch:5, train acc:0.985, test acc:0.984 ===\n",
      "train loss:0.02139633356343718\n",
      "train loss:0.03208290385078841\n",
      "train loss:0.020499264017142065\n",
      "train loss:0.09778029781642615\n",
      "train loss:0.04887090742920796\n",
      "train loss:0.022884931872589807\n",
      "train loss:0.023608864831140563\n",
      "train loss:0.009639944855305735\n",
      "train loss:0.01037308587694465\n",
      "train loss:0.027555550994977706\n",
      "train loss:0.0031816398413230173\n",
      "train loss:0.0655459509872306\n",
      "train loss:0.03439899740868958\n",
      "train loss:0.00627321624047143\n",
      "train loss:0.04498684173090469\n",
      "train loss:0.010814091196618462\n",
      "train loss:0.011998858971584932\n",
      "train loss:0.0373835823613185\n",
      "train loss:0.016879412945388857\n",
      "train loss:0.013640189654975958\n",
      "train loss:0.037046292877492594\n",
      "train loss:0.0455547893890484\n",
      "train loss:0.007427265780216158\n",
      "train loss:0.02607627615095893\n",
      "train loss:0.07845488127805457\n",
      "train loss:0.019098362961027304\n",
      "train loss:0.022967611016663086\n",
      "train loss:0.021526276619400923\n",
      "train loss:0.04442689022605929\n",
      "train loss:0.015137110643098077\n",
      "train loss:0.02408598536212581\n",
      "train loss:0.021753928649157882\n",
      "train loss:0.058408477630284006\n",
      "train loss:0.01869866366712109\n",
      "train loss:0.0278862754445646\n",
      "train loss:0.1287081926535298\n",
      "train loss:0.016119749198481876\n",
      "train loss:0.01920491558594616\n",
      "train loss:0.015454908058172661\n",
      "train loss:0.018487865431254386\n",
      "train loss:0.015060543711115362\n",
      "train loss:0.026656847341594556\n",
      "train loss:0.01641008982184079\n",
      "train loss:0.006427502828680391\n",
      "train loss:0.03934851296236414\n",
      "train loss:0.060095453988860716\n",
      "train loss:0.06632442299773122\n",
      "train loss:0.01633909510348957\n",
      "train loss:0.051652079434829246\n",
      "train loss:0.035588770148754695\n",
      "train loss:0.014830970405117409\n",
      "train loss:0.014002820533270217\n",
      "train loss:0.060749651203284974\n",
      "train loss:0.06748085345602098\n",
      "train loss:0.019695897334610336\n",
      "train loss:0.1200375148936325\n",
      "train loss:0.02714546516734289\n",
      "train loss:0.010405234466470332\n",
      "train loss:0.06878446896529468\n",
      "train loss:0.008516239667132813\n",
      "train loss:0.08450993193086954\n",
      "train loss:0.012237371848583051\n",
      "train loss:0.05741408142822694\n",
      "train loss:0.014124945581358829\n",
      "train loss:0.033512893616118096\n",
      "train loss:0.0430894247493755\n",
      "train loss:0.0197886025134185\n",
      "train loss:0.017634644181604927\n",
      "train loss:0.02533643431718381\n",
      "train loss:0.05424755533229823\n",
      "train loss:0.007665666685458856\n",
      "train loss:0.05113232645419668\n",
      "train loss:0.02346202180060296\n",
      "train loss:0.0339638545340368\n",
      "train loss:0.077485845241127\n",
      "train loss:0.011712954728078984\n",
      "train loss:0.005752997833504652\n",
      "train loss:0.047986392022547245\n",
      "train loss:0.03488324618432265\n",
      "train loss:0.030173610085516892\n",
      "train loss:0.040622541485467505\n",
      "train loss:0.03685542585337247\n",
      "train loss:0.011699039402958446\n",
      "train loss:0.008470971724054081\n",
      "train loss:0.025338580017621112\n",
      "train loss:0.015111055548052784\n",
      "train loss:0.008603871958414751\n",
      "train loss:0.01749492150679934\n",
      "train loss:0.00981384190391738\n",
      "train loss:0.011419440791017883\n",
      "train loss:0.04768959700081355\n",
      "train loss:0.014235301112789091\n",
      "train loss:0.012769608612660847\n",
      "train loss:0.03280710753642637\n",
      "train loss:0.011972932851239758\n",
      "train loss:0.03716167718787897\n",
      "train loss:0.08669760169108769\n",
      "train loss:0.041405348203280797\n",
      "train loss:0.010267729605270002\n",
      "train loss:0.03826573462922068\n",
      "train loss:0.020645981396188826\n",
      "train loss:0.02981162453499553\n",
      "train loss:0.011259572496156382\n",
      "train loss:0.02785543930487772\n",
      "train loss:0.011257097150088208\n",
      "train loss:0.02094102759863314\n",
      "train loss:0.025948855492295052\n",
      "train loss:0.02324691497680006\n",
      "train loss:0.005877052960491725\n",
      "train loss:0.034646055778649536\n",
      "train loss:0.02316736116737514\n",
      "train loss:0.01849742470619116\n",
      "train loss:0.04299372963595606\n",
      "train loss:0.029355482772275746\n",
      "train loss:0.012079446920351898\n",
      "train loss:0.014035603482232041\n",
      "train loss:0.014818985381259126\n",
      "train loss:0.014123400683592559\n",
      "train loss:0.09213048856301226\n",
      "train loss:0.004421737258479846\n",
      "train loss:0.011057620295589664\n",
      "train loss:0.010665027525535435\n",
      "train loss:0.10096759537314375\n",
      "train loss:0.010267404783105682\n",
      "train loss:0.005749340053976252\n",
      "train loss:0.014754818566479396\n",
      "train loss:0.00606608123997796\n",
      "train loss:0.0031379759977936466\n",
      "train loss:0.01438978832942722\n",
      "train loss:0.02187255945838086\n",
      "train loss:0.017202521485412417\n",
      "train loss:0.03699650525634879\n",
      "train loss:0.03184386029276785\n",
      "train loss:0.012017413382606423\n",
      "train loss:0.08640599133618294\n",
      "train loss:0.039432652877013676\n",
      "train loss:0.019196614023520134\n",
      "train loss:0.018129918727322482\n",
      "train loss:0.010678770078769592\n",
      "train loss:0.06515724906963173\n",
      "train loss:0.01873951032908968\n",
      "train loss:0.018830100029562105\n",
      "train loss:0.010346479550539286\n",
      "train loss:0.007553499487342339\n",
      "train loss:0.019395921467276162\n",
      "train loss:0.02083342309422081\n",
      "train loss:0.013913521399809382\n",
      "train loss:0.1630507632111901\n",
      "train loss:0.016392272578076066\n",
      "train loss:0.06377294236621717\n",
      "train loss:0.01147951268933578\n",
      "train loss:0.05890363498784861\n",
      "train loss:0.015945636645346303\n",
      "train loss:0.03671132329365281\n",
      "train loss:0.06675946718231772\n",
      "train loss:0.018034640048840436\n",
      "train loss:0.003677799452421788\n",
      "train loss:0.05129781593384965\n",
      "train loss:0.054822471793960104\n",
      "train loss:0.08385566188888108\n",
      "train loss:0.0140346422123848\n",
      "train loss:0.015850296395738168\n",
      "train loss:0.046081108988113885\n",
      "train loss:0.0244587929431336\n",
      "train loss:0.015163710482572496\n",
      "train loss:0.0450446970898834\n",
      "train loss:0.006914330140835725\n",
      "train loss:0.012276034088117258\n",
      "train loss:0.03180540314430605\n",
      "train loss:0.05028809569945976\n",
      "train loss:0.057812446043206143\n",
      "train loss:0.02424935373319643\n",
      "train loss:0.012168981947423036\n",
      "train loss:0.029298573446318744\n",
      "train loss:0.09792547263869901\n",
      "train loss:0.02241613905986641\n",
      "train loss:0.019091864488336913\n",
      "train loss:0.0067970715315893125\n",
      "train loss:0.01833913582905834\n",
      "train loss:0.010314324751199573\n",
      "train loss:0.03884014505409886\n",
      "train loss:0.018220275657346532\n",
      "train loss:0.05675428779028417\n",
      "train loss:0.018451971908226214\n",
      "train loss:0.008635894430512143\n",
      "train loss:0.02693719629707048\n",
      "train loss:0.005553991974819748\n",
      "train loss:0.03823805954086641\n",
      "train loss:0.01576860473224529\n",
      "train loss:0.0238457112625276\n",
      "train loss:0.029765296436523103\n",
      "train loss:0.033677221542659744\n",
      "train loss:0.06651553974442062\n",
      "train loss:0.05507761810642747\n",
      "train loss:0.030730343766596988\n",
      "train loss:0.0782272991037301\n",
      "train loss:0.010318199553846464\n",
      "train loss:0.03539408609754471\n",
      "train loss:0.035528600289354645\n",
      "train loss:0.016957974270617442\n",
      "train loss:0.014901712552332594\n",
      "train loss:0.018171851545059067\n",
      "train loss:0.032655804102544185\n",
      "train loss:0.015657872482245462\n",
      "train loss:0.021812418657156822\n",
      "train loss:0.013183130716745407\n",
      "train loss:0.09801796934343303\n",
      "train loss:0.01163099345198085\n",
      "train loss:0.01587916784247399\n",
      "train loss:0.008152836517482418\n",
      "train loss:0.010631741371794446\n",
      "train loss:0.007121030858586988\n",
      "train loss:0.014558667155384633\n",
      "train loss:0.012085044657733128\n",
      "train loss:0.07745749211852082\n",
      "train loss:0.0684830002641324\n",
      "train loss:0.022869576912651762\n",
      "train loss:0.01396814228304028\n",
      "train loss:0.03111699891636999\n",
      "train loss:0.015121441740965554\n",
      "train loss:0.02174615302305097\n",
      "train loss:0.0331711055759813\n",
      "train loss:0.010098588432745392\n",
      "train loss:0.008204121366312609\n",
      "train loss:0.009326119228824158\n",
      "train loss:0.026240833140834745\n",
      "train loss:0.009411110624559902\n",
      "train loss:0.03339565756835641\n",
      "train loss:0.010990674626956756\n",
      "train loss:0.011642405579752475\n",
      "train loss:0.053234043208413066\n",
      "train loss:0.017845939956272365\n",
      "train loss:0.005912310476454523\n",
      "train loss:0.03771412905648493\n",
      "train loss:0.00410236260480925\n",
      "train loss:0.05529132227692571\n",
      "train loss:0.12538932692921612\n",
      "train loss:0.023153833067653184\n",
      "train loss:0.05728422798834031\n",
      "train loss:0.036626939494277866\n",
      "train loss:0.023515974371021587\n",
      "train loss:0.008576826988912269\n",
      "train loss:0.03403639353550811\n",
      "train loss:0.009183725795800684\n",
      "train loss:0.011408734332668806\n",
      "train loss:0.010954050117113999\n",
      "train loss:0.00841688151645266\n",
      "train loss:0.017408134328238525\n",
      "train loss:0.03848089100945555\n",
      "train loss:0.003045958740037435\n",
      "train loss:0.004022256307102781\n",
      "train loss:0.008391551386571746\n",
      "train loss:0.01220832607456413\n",
      "train loss:0.009588127559324595\n",
      "train loss:0.016192752918633358\n",
      "train loss:0.0328010975601067\n",
      "train loss:0.007733505216983973\n",
      "train loss:0.01777457644105219\n",
      "train loss:0.0282513336921724\n",
      "train loss:0.026828264235757997\n",
      "train loss:0.010252074941467357\n",
      "train loss:0.02163254324142028\n",
      "train loss:0.021027195949093663\n",
      "train loss:0.007738793496459807\n",
      "train loss:0.013922537986916037\n",
      "train loss:0.00852593249984313\n",
      "train loss:0.015091185753836292\n",
      "train loss:0.022183852482650625\n",
      "train loss:0.022979980275540723\n",
      "train loss:0.004693289838272813\n",
      "train loss:0.0013562520801315373\n",
      "train loss:0.04257840133103837\n",
      "train loss:0.006521500160297875\n",
      "train loss:0.027483042868907362\n",
      "train loss:0.020282329220498788\n",
      "train loss:0.07998165049809808\n",
      "train loss:0.08290034951760651\n",
      "train loss:0.01129627400796791\n",
      "train loss:0.02274585676195987\n",
      "train loss:0.009398088776955752\n",
      "train loss:0.03363918474039376\n",
      "train loss:0.018944208266342816\n",
      "train loss:0.028700014738166416\n",
      "train loss:0.01463540800990853\n",
      "train loss:0.014565698245544123\n",
      "train loss:0.015510181598453424\n",
      "train loss:0.02251693753003053\n",
      "train loss:0.02878288764646836\n",
      "train loss:0.025595333116283498\n",
      "train loss:0.0218589715694414\n",
      "train loss:0.02688100218568696\n",
      "train loss:0.04803840383177115\n",
      "train loss:0.0061479630757113\n",
      "train loss:0.0042949964976968695\n",
      "train loss:0.09393181271537758\n",
      "train loss:0.006758469927765975\n",
      "train loss:0.005248234295191657\n",
      "train loss:0.03691643537856945\n",
      "train loss:0.02663846428131811\n",
      "train loss:0.2205205348821759\n",
      "train loss:0.011866065764087075\n",
      "train loss:0.06764731994591448\n",
      "train loss:0.006094283399748792\n",
      "train loss:0.0312551334820676\n",
      "train loss:0.022585089006212283\n",
      "train loss:0.017840401942684977\n",
      "train loss:0.0051387388659101\n",
      "train loss:0.025666749035238766\n",
      "train loss:0.10822620336695234\n",
      "train loss:0.038899892879926554\n",
      "train loss:0.006886907339002251\n",
      "train loss:0.05255822856051932\n",
      "train loss:0.028502245883847654\n",
      "train loss:0.019328935475057468\n",
      "train loss:0.021054514025453785\n",
      "train loss:0.0632944799364897\n",
      "train loss:0.019915393865738363\n",
      "train loss:0.06583574946058228\n",
      "train loss:0.016528112646715908\n",
      "train loss:0.039401063932727014\n",
      "train loss:0.09977990172041203\n",
      "train loss:0.009547706394638719\n",
      "train loss:0.011115540734185813\n",
      "train loss:0.026164684846332772\n",
      "train loss:0.015879982812968204\n",
      "train loss:0.021433919350427454\n",
      "train loss:0.022995713255052765\n",
      "train loss:0.007564698636342424\n",
      "train loss:0.019427427927552008\n",
      "train loss:0.010354385886420467\n",
      "train loss:0.0058821923735826575\n",
      "train loss:0.04118573788494035\n",
      "train loss:0.04237849348917742\n",
      "train loss:0.030150199394439196\n",
      "train loss:0.01866464613313144\n",
      "train loss:0.003765376725976456\n",
      "train loss:0.022620500383159717\n",
      "train loss:0.004795201222779996\n",
      "train loss:0.012666050575058303\n",
      "train loss:0.052955749741789085\n",
      "train loss:0.02833975675256357\n",
      "train loss:0.007221263040658035\n",
      "train loss:0.007577547856755278\n",
      "train loss:0.015818917608657234\n",
      "train loss:0.012490407654744828\n",
      "train loss:0.09494588653939287\n",
      "train loss:0.08982265978375142\n",
      "train loss:0.007748448305213169\n",
      "train loss:0.018768392270501512\n",
      "train loss:0.020120742624999296\n",
      "train loss:0.03766801071466079\n",
      "train loss:0.01377087953666976\n",
      "train loss:0.03873075799485057\n",
      "train loss:0.02684592688231622\n",
      "train loss:0.03564925659441219\n",
      "train loss:0.016335495988058172\n",
      "train loss:0.022358181125111586\n",
      "train loss:0.08212220908183855\n",
      "train loss:0.03833778428712041\n",
      "train loss:0.01552080808782974\n",
      "train loss:0.027006569876246042\n",
      "train loss:0.009985014738545175\n",
      "train loss:0.015406261849242875\n",
      "train loss:0.017897236259071757\n",
      "train loss:0.021460826963806703\n",
      "train loss:0.007566165138506022\n",
      "train loss:0.02279999311894451\n",
      "train loss:0.010286881388167725\n",
      "train loss:0.00407361265424922\n",
      "train loss:0.03420174926913321\n",
      "train loss:0.019513838606486453\n",
      "train loss:0.03428115211759474\n",
      "train loss:0.003607118585104912\n",
      "train loss:0.015368469042272586\n",
      "train loss:0.03015563373516908\n",
      "train loss:0.028186160510977963\n",
      "train loss:0.03149028951596924\n",
      "train loss:0.020101929454449288\n",
      "train loss:0.09377653154714415\n",
      "train loss:0.04870350468531996\n",
      "train loss:0.013311561425531826\n",
      "train loss:0.019728533846510778\n",
      "train loss:0.01817405101616923\n",
      "train loss:0.010524921215861556\n",
      "train loss:0.018675320762742177\n",
      "train loss:0.008084477043673202\n",
      "train loss:0.033601613152196876\n",
      "train loss:0.04172885554745136\n",
      "train loss:0.018531920668203326\n",
      "train loss:0.011076860667127639\n",
      "train loss:0.019659073242139037\n",
      "train loss:0.0076673314084060775\n",
      "train loss:0.04870055284754337\n",
      "train loss:0.0732443373537809\n",
      "train loss:0.008579801190054614\n",
      "train loss:0.016671641939097863\n",
      "train loss:0.00430894828174398\n",
      "train loss:0.10945280076825037\n",
      "train loss:0.014379163213167578\n",
      "train loss:0.05721075397385065\n",
      "train loss:0.01716738086641316\n",
      "train loss:0.019366862727095303\n",
      "train loss:0.018276022836777664\n",
      "train loss:0.01750210528102113\n",
      "train loss:0.05234536076940754\n",
      "train loss:0.04950338064767545\n",
      "train loss:0.0481822714655682\n",
      "train loss:0.020367337139462722\n",
      "train loss:0.010116489343346817\n",
      "train loss:0.027906701149929748\n",
      "train loss:0.008343850982773954\n",
      "train loss:0.010834563006800479\n",
      "train loss:0.008632857051017007\n",
      "train loss:0.026632639284308337\n",
      "train loss:0.009947968995216794\n",
      "train loss:0.016750049414135722\n",
      "train loss:0.030330628597590642\n",
      "train loss:0.04138809557934016\n",
      "train loss:0.027137692144162822\n",
      "train loss:0.012409963163385399\n",
      "train loss:0.007300957428724896\n",
      "train loss:0.01784216977851166\n",
      "train loss:0.17679544152361004\n",
      "train loss:0.029067046381612505\n",
      "train loss:0.008905367753368814\n",
      "train loss:0.01689675016005161\n",
      "train loss:0.011220646760006758\n",
      "train loss:0.022084190175795156\n",
      "train loss:0.05439217303876268\n",
      "train loss:0.03765098999601866\n",
      "train loss:0.09273772037420328\n",
      "train loss:0.08027453261526216\n",
      "train loss:0.009582598738468522\n",
      "train loss:0.03184754208391477\n",
      "train loss:0.014464513157921292\n",
      "train loss:0.016268733046477978\n",
      "train loss:0.021448490009732892\n",
      "train loss:0.03027995571351084\n",
      "train loss:0.019225140797132664\n",
      "train loss:0.02260478357152819\n",
      "train loss:0.002691798056939718\n",
      "train loss:0.046377998528848545\n",
      "train loss:0.027501825350172808\n",
      "train loss:0.03228262118755986\n",
      "train loss:0.01335286064282059\n",
      "train loss:0.03787057929524082\n",
      "train loss:0.006427802544629133\n",
      "train loss:0.005996683877720642\n",
      "train loss:0.007824076296432414\n",
      "train loss:0.010291223999777877\n",
      "train loss:0.017164704576960718\n",
      "train loss:0.02110961698081407\n",
      "train loss:0.03061334633235721\n",
      "train loss:0.008462918234362711\n",
      "train loss:0.015380901761910886\n",
      "train loss:0.01725774149033431\n",
      "train loss:0.008095634011955039\n",
      "train loss:0.02977778397664764\n",
      "train loss:0.019647342847869047\n",
      "train loss:0.023034457476858065\n",
      "train loss:0.018534573610217982\n",
      "train loss:0.03089092981453911\n",
      "train loss:0.014317234119198847\n",
      "train loss:0.01494506667664548\n",
      "train loss:0.02191987766618599\n",
      "train loss:0.015319227268852646\n",
      "train loss:0.015846242725785328\n",
      "train loss:0.03128062138741116\n",
      "train loss:0.012919286282019547\n",
      "train loss:0.0031982567300968667\n",
      "train loss:0.007181056271193539\n",
      "train loss:0.017315011158420678\n",
      "train loss:0.023874041731693676\n",
      "train loss:0.016219086828121433\n",
      "train loss:0.01031878729405027\n",
      "train loss:0.06286460985499266\n",
      "train loss:0.0057128194252179295\n",
      "train loss:0.007232381179219192\n",
      "train loss:0.011729027712423424\n",
      "train loss:0.0603399711442263\n",
      "train loss:0.028773378477821403\n",
      "train loss:0.032469059911454885\n",
      "train loss:0.0509534852376671\n",
      "train loss:0.01315546126403242\n",
      "train loss:0.029112521913883787\n",
      "train loss:0.018276344453262153\n",
      "train loss:0.011866482806534467\n",
      "train loss:0.027453480070768855\n",
      "train loss:0.019270613953069962\n",
      "train loss:0.017693014858845686\n",
      "train loss:0.006611893931486436\n",
      "train loss:0.03964734420768329\n",
      "train loss:0.010735320540917312\n",
      "train loss:0.011677734016049492\n",
      "train loss:0.008997002978754463\n",
      "train loss:0.0474539745573052\n",
      "train loss:0.01282623961472371\n",
      "train loss:0.008473977599319947\n",
      "train loss:0.015724172252138055\n",
      "train loss:0.024161967261909383\n",
      "train loss:0.0075006573579297605\n",
      "train loss:0.01800455532779253\n",
      "train loss:0.03462573143212709\n",
      "train loss:0.009960341489072648\n",
      "train loss:0.043779998159743407\n",
      "train loss:0.0931673035799081\n",
      "train loss:0.0177442565701008\n",
      "train loss:0.03219015129618559\n",
      "train loss:0.02965020220511422\n",
      "train loss:0.007498154494998448\n",
      "train loss:0.047562605297329384\n",
      "train loss:0.00306671526067632\n",
      "train loss:0.032640861675360816\n",
      "train loss:0.02563430474245081\n",
      "train loss:0.06584250805929451\n",
      "train loss:0.014378140826346739\n",
      "train loss:0.00902120784568029\n",
      "train loss:0.0019362938139355032\n",
      "train loss:0.04133675045876105\n",
      "train loss:0.008883842561679898\n",
      "train loss:0.04053776760440227\n",
      "train loss:0.009833202902661048\n",
      "train loss:0.018156246889505383\n",
      "train loss:0.019268974458938312\n",
      "train loss:0.007039446887582053\n",
      "train loss:0.0048509619364898145\n",
      "train loss:0.04769544231527182\n",
      "train loss:0.015336653420831126\n",
      "train loss:0.0016655836174721622\n",
      "train loss:0.02422955290159249\n",
      "train loss:0.011941395473650784\n",
      "train loss:0.0680331181921106\n",
      "train loss:0.02334893436052243\n",
      "train loss:0.008171299199112013\n",
      "train loss:0.01597849970348792\n",
      "train loss:0.017463129234498855\n",
      "train loss:0.009917465365246491\n",
      "train loss:0.0038695681254932706\n",
      "train loss:0.08749585909113242\n",
      "train loss:0.13699770871178588\n",
      "train loss:0.07527573493386211\n",
      "train loss:0.032380927591723015\n",
      "train loss:0.007831189690051801\n",
      "train loss:0.02304694013895831\n",
      "train loss:0.02864737110875202\n",
      "train loss:0.021866119095871307\n",
      "train loss:0.025258052362219424\n",
      "train loss:0.010452809117517337\n",
      "train loss:0.008499873673817415\n",
      "train loss:0.00821763147646725\n",
      "train loss:0.018726372350359344\n",
      "train loss:0.024841494026579244\n",
      "train loss:0.02271056684356831\n",
      "train loss:0.030603056780037573\n",
      "train loss:0.012725694193977297\n",
      "train loss:0.04640994783943133\n",
      "train loss:0.01611736448772264\n",
      "train loss:0.004699147131224814\n",
      "train loss:0.025766352943961773\n",
      "train loss:0.009211959557324715\n",
      "train loss:0.04924764750279391\n",
      "train loss:0.028415456739209786\n",
      "train loss:0.008032376794432623\n",
      "train loss:0.010334176326376177\n",
      "train loss:0.003621690956300407\n",
      "train loss:0.014315321418908122\n",
      "train loss:0.04331243393207094\n",
      "train loss:0.12433154150679089\n",
      "train loss:0.013974295859197452\n",
      "train loss:0.014809464075231617\n",
      "train loss:0.007313913252223964\n",
      "train loss:0.01963460890383224\n",
      "train loss:0.015582961187202093\n",
      "train loss:0.006824211883625636\n",
      "train loss:0.009404585728905412\n",
      "train loss:0.006244018507655736\n",
      "train loss:0.24438020875078678\n",
      "train loss:0.007582688516518891\n",
      "train loss:0.002563384989570995\n",
      "train loss:0.011827806914624038\n",
      "train loss:0.040429634248555085\n",
      "train loss:0.009500453531635924\n",
      "train loss:0.06295049711072784\n",
      "train loss:0.014703019318684792\n",
      "train loss:0.032342817116309916\n",
      "train loss:0.06291949376597716\n",
      "train loss:0.04740435936215979\n",
      "train loss:0.058649630435585756\n",
      "train loss:0.03796311986432454\n",
      "train loss:0.09263011747161512\n",
      "train loss:0.030116000772128903\n",
      "train loss:0.028094539700167682\n",
      "train loss:0.03846265663187126\n",
      "train loss:0.022417352702456202\n",
      "train loss:0.009958823307653507\n",
      "train loss:0.07230349359695748\n",
      "train loss:0.05943856857647749\n",
      "train loss:0.020801651406543234\n",
      "train loss:0.0732469906232886\n",
      "train loss:0.005928523833418212\n",
      "=== epoch:6, train acc:0.991, test acc:0.983 ===\n",
      "train loss:0.0063072134160805935\n",
      "train loss:0.06895060747645428\n",
      "train loss:0.013948387911763775\n",
      "train loss:0.009053080506072984\n",
      "train loss:0.05985915300691546\n",
      "train loss:0.016065013791981934\n",
      "train loss:0.009587361233348224\n",
      "train loss:0.01181395077690006\n",
      "train loss:0.11089230207995296\n",
      "train loss:0.014779920377683855\n",
      "train loss:0.018396897155954585\n",
      "train loss:0.013627212347797988\n",
      "train loss:0.01982567263531281\n",
      "train loss:0.06449141821113019\n",
      "train loss:0.016897719535259516\n",
      "train loss:0.06985151748246948\n",
      "train loss:0.022942681600889397\n",
      "train loss:0.016167993649805007\n",
      "train loss:0.05611966025211599\n",
      "train loss:0.027918343660867713\n",
      "train loss:0.02767394725223718\n",
      "train loss:0.01270173326551221\n",
      "train loss:0.022779738903539043\n",
      "train loss:0.028527588762948475\n",
      "train loss:0.05891223575439163\n",
      "train loss:0.038102707438853536\n",
      "train loss:0.0227331668991543\n",
      "train loss:0.012003231970947957\n",
      "train loss:0.02834945309849795\n",
      "train loss:0.027376361434956777\n",
      "train loss:0.0349631406015422\n",
      "train loss:0.029048503965834624\n",
      "train loss:0.014804682397303752\n",
      "train loss:0.013661664845567514\n",
      "train loss:0.03551178991747883\n",
      "train loss:0.01564751795537187\n",
      "train loss:0.01650972462853792\n",
      "train loss:0.06318293242243375\n",
      "train loss:0.007109239171915836\n",
      "train loss:0.012900740739731232\n",
      "train loss:0.036036722678321684\n",
      "train loss:0.015020692253657868\n",
      "train loss:0.05836215674987339\n",
      "train loss:0.012631607645704852\n",
      "train loss:0.03546846726233494\n",
      "train loss:0.03882366732844286\n",
      "train loss:0.03209535219619108\n",
      "train loss:0.027674498654430276\n",
      "train loss:0.028411349164527124\n",
      "train loss:0.027392162057702805\n",
      "train loss:0.039236627581886195\n",
      "train loss:0.07086881452958774\n",
      "train loss:0.07939276175245163\n",
      "train loss:0.013092057530873598\n",
      "train loss:0.0074974870105759895\n",
      "train loss:0.03722351257572669\n",
      "train loss:0.005906079223205773\n",
      "train loss:0.030552067825898553\n",
      "train loss:0.01735231080924069\n",
      "train loss:0.03734458519847541\n",
      "train loss:0.014275458975239741\n",
      "train loss:0.017974506309982635\n",
      "train loss:0.030957757531941278\n",
      "train loss:0.02392268888543407\n",
      "train loss:0.011338375547854593\n",
      "train loss:0.042866926004927086\n",
      "train loss:0.027717017192217704\n",
      "train loss:0.018815384738228396\n",
      "train loss:0.003604925927487518\n",
      "train loss:0.03364971743144758\n",
      "train loss:0.03604101339890895\n",
      "train loss:0.09957799787729515\n",
      "train loss:0.04108676390839412\n",
      "train loss:0.15914924280874168\n",
      "train loss:0.01720455315805043\n",
      "train loss:0.05093523941991182\n",
      "train loss:0.019494239298421024\n",
      "train loss:0.015089588758850758\n",
      "train loss:0.008402087923512533\n",
      "train loss:0.015022764436424934\n",
      "train loss:0.014768312375488889\n",
      "train loss:0.022615030923866967\n",
      "train loss:0.01486230228011839\n",
      "train loss:0.016248127631981586\n",
      "train loss:0.021737750833932323\n",
      "train loss:0.03681608308142953\n",
      "train loss:0.09278809187862055\n",
      "train loss:0.10302847910432482\n",
      "train loss:0.022323495781737618\n",
      "train loss:0.025456361787254807\n",
      "train loss:0.0072697074272926095\n",
      "train loss:0.0029739625331952125\n",
      "train loss:0.01988343663567036\n",
      "train loss:0.02910208705414297\n",
      "train loss:0.03526748878355629\n",
      "train loss:0.05474738796070102\n",
      "train loss:0.0042870355769021535\n",
      "train loss:0.007823342144893665\n",
      "train loss:0.005534714898952058\n",
      "train loss:0.036105722855543816\n",
      "train loss:0.01309017174467959\n",
      "train loss:0.004750650215269566\n",
      "train loss:0.01238434859536106\n",
      "train loss:0.03238294740015036\n",
      "train loss:0.010912847349965895\n",
      "train loss:0.022146357094384048\n",
      "train loss:0.005160722191454124\n",
      "train loss:0.0056799604702179665\n",
      "train loss:0.009831723753444576\n",
      "train loss:0.011924803775454552\n",
      "train loss:0.03187376571704621\n",
      "train loss:0.005024480246793937\n",
      "train loss:0.035836207646741974\n",
      "train loss:0.01269704022710868\n",
      "train loss:0.059302216136809235\n",
      "train loss:0.006690593199673099\n",
      "train loss:0.05302642602544476\n",
      "train loss:0.003949319759429642\n",
      "train loss:0.010466910984187226\n",
      "train loss:0.02822240573003633\n",
      "train loss:0.02890463042717528\n",
      "train loss:0.014025262854485465\n",
      "train loss:0.029681910233813315\n",
      "train loss:0.01709862608093784\n",
      "train loss:0.013205284882000866\n",
      "train loss:0.03261581413825162\n",
      "train loss:0.009324346060455579\n",
      "train loss:0.020811406288033307\n",
      "train loss:0.00991147609521507\n",
      "train loss:0.010425588904303893\n",
      "train loss:0.0014917525768605743\n",
      "train loss:0.00799920417328014\n",
      "train loss:0.06107295327906994\n",
      "train loss:0.03746732231048548\n",
      "train loss:0.005245345989824539\n",
      "train loss:0.021715914210685257\n",
      "train loss:0.01414198431392363\n",
      "train loss:0.01103077174192713\n",
      "train loss:0.00974976472817968\n",
      "train loss:0.03471022434679512\n",
      "train loss:0.00626382323014325\n",
      "train loss:0.01780448262682322\n",
      "train loss:0.009168461729340847\n",
      "train loss:0.006923916981089203\n",
      "train loss:0.00783827548169943\n",
      "train loss:0.006314482511533487\n",
      "train loss:0.004569393211879401\n",
      "train loss:0.009717493469655409\n",
      "train loss:0.010020896544079868\n",
      "train loss:0.016960899656612415\n",
      "train loss:0.009150097583354874\n",
      "train loss:0.009271598617034122\n",
      "train loss:0.02151572380544759\n",
      "train loss:0.019137026162990414\n",
      "train loss:0.03925980438265014\n",
      "train loss:0.013864347466762983\n",
      "train loss:0.004610486333800486\n",
      "train loss:0.04732272605114091\n",
      "train loss:0.00288603192334761\n",
      "train loss:0.005542164487094491\n",
      "train loss:0.012109241126724329\n",
      "train loss:0.008807672534907711\n",
      "train loss:0.005111581762921849\n",
      "train loss:0.024282170937417743\n",
      "train loss:0.032668183619610894\n",
      "train loss:0.01234243216440601\n",
      "train loss:0.011830722595655605\n",
      "train loss:0.005799410042149944\n",
      "train loss:0.011426735026875879\n",
      "train loss:0.003945976368739936\n",
      "train loss:0.008555564111188508\n",
      "train loss:0.02152009898847083\n",
      "train loss:0.024607687932392933\n",
      "train loss:0.024803358861740534\n",
      "train loss:0.003764563731728992\n",
      "train loss:0.016083686717100153\n",
      "train loss:0.008088424295225476\n",
      "train loss:0.006944041366165537\n",
      "train loss:0.012454830606440067\n",
      "train loss:0.022926183215329434\n",
      "train loss:0.032812855659193285\n",
      "train loss:0.016226797047503235\n",
      "train loss:0.022112491725806566\n",
      "train loss:0.005419902103862586\n",
      "train loss:0.0030657118997046064\n",
      "train loss:0.02003320130340545\n",
      "train loss:0.012229695117728723\n",
      "train loss:0.08597344523746724\n",
      "train loss:0.005094386005543259\n",
      "train loss:0.019172075133705745\n",
      "train loss:0.03824401827014341\n",
      "train loss:0.04610211795788593\n",
      "train loss:0.020825885230753634\n",
      "train loss:0.03585559902087201\n",
      "train loss:0.0032685969706012143\n",
      "train loss:0.007264257570607025\n",
      "train loss:0.008444273000493786\n",
      "train loss:0.011113365238910149\n",
      "train loss:0.01099994142071427\n",
      "train loss:0.03234618708697501\n",
      "train loss:0.039126648675897414\n",
      "train loss:0.009730643951558872\n",
      "train loss:0.023846422921229814\n",
      "train loss:0.015586624267912654\n",
      "train loss:0.045195883791808285\n",
      "train loss:0.045211729250402725\n",
      "train loss:0.0285284730476821\n",
      "train loss:0.023362186291894814\n",
      "train loss:0.010895477072634652\n",
      "train loss:0.011932962303646613\n",
      "train loss:0.012954662072618939\n",
      "train loss:0.00535394243876102\n",
      "train loss:0.011507214986303537\n",
      "train loss:0.06254715489177982\n",
      "train loss:0.009754203812588635\n",
      "train loss:0.006874623296431135\n",
      "train loss:0.00212759280610452\n",
      "train loss:0.009676490944225659\n",
      "train loss:0.04335448285019163\n",
      "train loss:0.024936767575179576\n",
      "train loss:0.01092713789526291\n",
      "train loss:0.02922638463460079\n",
      "train loss:0.025177835312707116\n",
      "train loss:0.0345719630362859\n",
      "train loss:0.1303670029793855\n",
      "train loss:0.07748065473612487\n",
      "train loss:0.030062446053965783\n",
      "train loss:0.1207913829944377\n",
      "train loss:0.01215797180096993\n",
      "train loss:0.006759772700371628\n",
      "train loss:0.026733516132332304\n",
      "train loss:0.008575223408701529\n",
      "train loss:0.02286966448156905\n",
      "train loss:0.006492578602940711\n",
      "train loss:0.027152541524069575\n",
      "train loss:0.047222132743613775\n",
      "train loss:0.007707523487472187\n",
      "train loss:0.0206584514331258\n",
      "train loss:0.013491668431795561\n",
      "train loss:0.013151831838070411\n",
      "train loss:0.06006416719585801\n",
      "train loss:0.01724339601869368\n",
      "train loss:0.013965865724005216\n",
      "train loss:0.0030824174022282412\n",
      "train loss:0.004648479954189174\n",
      "train loss:0.01926716878368842\n",
      "train loss:0.027740802607553138\n",
      "train loss:0.010353305027262767\n",
      "train loss:0.012081105274836398\n",
      "train loss:0.012600391904246418\n",
      "train loss:0.020000019851123117\n",
      "train loss:0.017438161576582713\n",
      "train loss:0.008939810076110279\n",
      "train loss:0.01596583586059275\n",
      "train loss:0.003103876880898736\n",
      "train loss:0.010520113111012206\n",
      "train loss:0.010505761454437743\n",
      "train loss:0.023223046979035957\n",
      "train loss:0.03181174877190311\n",
      "train loss:0.012986544743423797\n",
      "train loss:0.049213765125121774\n",
      "train loss:0.027200195840048\n",
      "train loss:0.01551811718783913\n",
      "train loss:0.009066828468504933\n",
      "train loss:0.01918559852975783\n",
      "train loss:0.03441330702249298\n",
      "train loss:0.03437503169789919\n",
      "train loss:0.004758461507960613\n",
      "train loss:0.00508713844075103\n",
      "train loss:0.0040388606380029396\n",
      "train loss:0.01617389921929999\n",
      "train loss:0.026308136610369178\n",
      "train loss:0.05691679041183097\n",
      "train loss:0.023029482326899813\n",
      "train loss:0.009741035556183749\n",
      "train loss:0.04408945173302066\n",
      "train loss:0.01064282700264626\n",
      "train loss:0.029448886432840108\n",
      "train loss:0.001252981734267637\n",
      "train loss:0.06924630629678535\n",
      "train loss:0.005983079279252453\n",
      "train loss:0.01268692291307976\n",
      "train loss:0.017152438629846622\n",
      "train loss:0.005162474231110273\n",
      "train loss:0.017168684492470224\n",
      "train loss:0.010531840556154857\n",
      "train loss:0.010113382383521946\n",
      "train loss:0.06422256175516013\n",
      "train loss:0.04228491074938305\n",
      "train loss:0.01780576324895179\n",
      "train loss:0.011648960589833666\n",
      "train loss:0.011729228744118662\n",
      "train loss:0.008051635998738546\n",
      "train loss:0.13043715332320552\n",
      "train loss:0.032792548470307416\n",
      "train loss:0.014283992610120215\n",
      "train loss:0.004268975404110982\n",
      "train loss:0.008983738949334949\n",
      "train loss:0.012424276744544662\n",
      "train loss:0.04025818814151582\n",
      "train loss:0.03169899268414394\n",
      "train loss:0.017628631678581558\n",
      "train loss:0.0022893542324664974\n",
      "train loss:0.010542289772430049\n",
      "train loss:0.005582240172822737\n",
      "train loss:0.016758043793696557\n",
      "train loss:0.010585714668117798\n",
      "train loss:0.00856359314167903\n",
      "train loss:0.008631381183318222\n",
      "train loss:0.012536577484998345\n",
      "train loss:0.003557813806545149\n",
      "train loss:0.008498850895323939\n",
      "train loss:0.005234271676415312\n",
      "train loss:0.025697802077281104\n",
      "train loss:0.006472375182630552\n",
      "train loss:0.019181353332607076\n",
      "train loss:0.014036665368880324\n",
      "train loss:0.0030194326903194555\n",
      "train loss:0.005257235776501102\n",
      "train loss:0.043838533953157184\n",
      "train loss:0.006459872101531117\n",
      "train loss:0.023223755980453384\n",
      "train loss:0.01367240021262109\n",
      "train loss:0.009533772828010429\n",
      "train loss:0.037908750593503855\n",
      "train loss:0.002233961348713856\n",
      "train loss:0.005232859214530732\n",
      "train loss:0.024346383757306488\n",
      "train loss:0.011177447836194294\n",
      "train loss:0.0341707908573715\n",
      "train loss:0.02966504332044393\n",
      "train loss:0.03563297750167939\n",
      "train loss:0.027609614391899857\n",
      "train loss:0.02136180917404\n",
      "train loss:0.01520142196518073\n",
      "train loss:0.07467859364879781\n",
      "train loss:0.03498820036599592\n",
      "train loss:0.0017181725914336453\n",
      "train loss:0.016368118799921817\n",
      "train loss:0.04310318210494036\n",
      "train loss:0.011422867639065004\n",
      "train loss:0.016805800922865183\n",
      "train loss:0.0310164108264795\n",
      "train loss:0.031482406904527346\n",
      "train loss:0.10319998437858423\n",
      "train loss:0.023072024401712868\n",
      "train loss:0.006251728537495302\n",
      "train loss:0.019716893961385075\n",
      "train loss:0.019006135199129335\n",
      "train loss:0.004092332431534083\n",
      "train loss:0.008112556047188474\n",
      "train loss:0.011293947893024252\n",
      "train loss:0.04662096919459887\n",
      "train loss:0.021610308328393172\n",
      "train loss:0.02227470664340224\n",
      "train loss:0.021279014541922592\n",
      "train loss:0.004513703402173283\n",
      "train loss:0.009924431447628812\n",
      "train loss:0.004084285666342379\n",
      "train loss:0.016085421771521648\n",
      "train loss:0.013814020819254978\n",
      "train loss:0.0015046380823683558\n",
      "train loss:0.008381300312188714\n",
      "train loss:0.010136642725994871\n",
      "train loss:0.08229683539508674\n",
      "train loss:0.005688810385299708\n",
      "train loss:0.09855880116076372\n",
      "train loss:0.004681247020028378\n",
      "train loss:0.005940719796487745\n",
      "train loss:0.01055316679438116\n",
      "train loss:0.03194950867483168\n",
      "train loss:0.005136070609898863\n",
      "train loss:0.03398736387836821\n",
      "train loss:0.011882064275553985\n",
      "train loss:0.0038661969698500836\n",
      "train loss:0.011537026475144591\n",
      "train loss:0.016753469000201044\n",
      "train loss:0.008664152586870219\n",
      "train loss:0.022287418878774296\n",
      "train loss:0.028909514679639696\n",
      "train loss:0.004066408258466157\n",
      "train loss:0.03255435380507422\n",
      "train loss:0.04224562501303918\n",
      "train loss:0.012381461877188573\n",
      "train loss:0.05346049604555383\n",
      "train loss:0.006139666437255418\n",
      "train loss:0.029596262040232853\n",
      "train loss:0.027197180710231538\n",
      "train loss:0.0030819778793514246\n",
      "train loss:0.013523752713269619\n",
      "train loss:0.011098823072192439\n",
      "train loss:0.009593529740575493\n",
      "train loss:0.012360680077836366\n",
      "train loss:0.04987174140388273\n",
      "train loss:0.01827174359416782\n",
      "train loss:0.005200266632837562\n",
      "train loss:0.009257074873810472\n",
      "train loss:0.007978400465572653\n",
      "train loss:0.003316072031112559\n",
      "train loss:0.011307654966206886\n",
      "train loss:0.001403065198326525\n",
      "train loss:0.0057500219067382445\n",
      "train loss:0.03071812384486571\n",
      "train loss:0.00696516945445306\n",
      "train loss:0.009006425575668824\n",
      "train loss:0.02884775466871329\n",
      "train loss:0.007947535401716097\n",
      "train loss:0.03246031629524496\n",
      "train loss:0.009450476782562577\n",
      "train loss:0.010590936473427588\n",
      "train loss:0.01027113086899193\n",
      "train loss:0.04049021467984235\n",
      "train loss:0.009129692506263522\n",
      "train loss:0.02203230988571787\n",
      "train loss:0.01619253896543067\n",
      "train loss:0.0030759006149885487\n",
      "train loss:0.009493773679131757\n",
      "train loss:0.023819534306246726\n",
      "train loss:0.06079048163592373\n",
      "train loss:0.013564626332691246\n",
      "train loss:0.02676816831184568\n",
      "train loss:0.015356152776983331\n",
      "train loss:0.02462901153774881\n",
      "train loss:0.008495613778683077\n",
      "train loss:0.0016571157442680697\n",
      "train loss:0.005803649188441427\n",
      "train loss:0.0048055694251143135\n",
      "train loss:0.005903389229242765\n",
      "train loss:0.03610830348286834\n",
      "train loss:0.02694236353026034\n",
      "train loss:0.009633136513825899\n",
      "train loss:0.014852256724103756\n",
      "train loss:0.07300162967788279\n",
      "train loss:0.02842673008392485\n",
      "train loss:0.1043611551949094\n",
      "train loss:0.009950511514813482\n",
      "train loss:0.01367829850026586\n",
      "train loss:0.004676493441367998\n",
      "train loss:0.0006924910102735031\n",
      "train loss:0.028477195698002233\n",
      "train loss:0.0042497848742783385\n",
      "train loss:0.009559160426197115\n",
      "train loss:0.001504022646778316\n",
      "train loss:0.021824695477219803\n",
      "train loss:0.011321762505081817\n",
      "train loss:0.0068888878879074696\n",
      "train loss:0.0032656472180464264\n",
      "train loss:0.010928519407670374\n",
      "train loss:0.0027634488562083516\n",
      "train loss:0.005556149039857283\n",
      "train loss:0.09642862910093875\n",
      "train loss:0.03147283319481654\n",
      "train loss:0.012878064230248572\n",
      "train loss:0.010923317437420903\n",
      "train loss:0.01700010518890681\n",
      "train loss:0.010506270911679445\n",
      "train loss:0.017966883698745113\n",
      "train loss:0.00918562033431966\n",
      "train loss:0.0009730045679564224\n",
      "train loss:0.011195332668200785\n",
      "train loss:0.0043697843195539855\n",
      "train loss:0.025160465196732984\n",
      "train loss:0.010215018322653945\n",
      "train loss:0.005500147486799833\n",
      "train loss:0.0055146439796667805\n",
      "train loss:0.0037906825696195612\n",
      "train loss:0.0043099022006320604\n",
      "train loss:0.016242913844218883\n",
      "train loss:0.008246845651176345\n",
      "train loss:0.04227965347005911\n",
      "train loss:0.009801497668375346\n",
      "train loss:0.0030253123055346055\n",
      "train loss:0.0049746541187465085\n",
      "train loss:0.0189545560942688\n",
      "train loss:0.0061339401578510274\n",
      "train loss:0.056481007933686656\n",
      "train loss:0.017704267058555684\n",
      "train loss:0.06201116760422127\n",
      "train loss:0.028905831233644368\n",
      "train loss:0.013286099474976592\n",
      "train loss:0.0059804737603217795\n",
      "train loss:0.023587419671663355\n",
      "train loss:0.01746827272149427\n",
      "train loss:0.034193874585512554\n",
      "train loss:0.002760540745710033\n",
      "train loss:0.049108179979733206\n",
      "train loss:0.020600127622386263\n",
      "train loss:0.01145896860367357\n",
      "train loss:0.028090620777078662\n",
      "train loss:0.014619228014095315\n",
      "train loss:0.010005963155477044\n",
      "train loss:0.026379967507860314\n",
      "train loss:0.05916886823632145\n",
      "train loss:0.02487011991168668\n",
      "train loss:0.01184045980127511\n",
      "train loss:0.020342709180857406\n",
      "train loss:0.01456458971429805\n",
      "train loss:0.006411813276066956\n",
      "train loss:0.01830038919870562\n",
      "train loss:0.010418844380696362\n",
      "train loss:0.010886996510550067\n",
      "train loss:0.013944090261412212\n",
      "train loss:0.014201575737403903\n",
      "train loss:0.011276425179576546\n",
      "train loss:0.0307503814115782\n",
      "train loss:0.026737577257105884\n",
      "train loss:0.008890362420395813\n",
      "train loss:0.03118539667725374\n",
      "train loss:0.017347625639534802\n",
      "train loss:0.008487152093803282\n",
      "train loss:0.012017884062821347\n",
      "train loss:0.0015290808738247135\n",
      "train loss:0.0037215620780377857\n",
      "train loss:0.0016372621585190284\n",
      "train loss:0.037015019589700875\n",
      "train loss:0.020319908693813223\n",
      "train loss:0.026469195155509846\n",
      "train loss:0.028808547813351786\n",
      "train loss:0.0132532486737356\n",
      "train loss:0.007545559822720656\n",
      "train loss:0.023172394271332684\n",
      "train loss:0.03427549137050292\n",
      "train loss:0.023102939804403682\n",
      "train loss:0.010351220936819465\n",
      "train loss:0.02231993823497326\n",
      "train loss:0.008086215766727571\n",
      "train loss:0.007698757244759939\n",
      "train loss:0.004429200957780078\n",
      "train loss:0.02468100221127864\n",
      "train loss:0.003118368557561\n",
      "train loss:0.01288886012255428\n",
      "train loss:0.020121867022407744\n",
      "train loss:0.012703097856146943\n",
      "train loss:0.010153663502278002\n",
      "train loss:0.053070430640947526\n",
      "train loss:0.015025491780716991\n",
      "train loss:0.006914128207291418\n",
      "train loss:0.014938498570937818\n",
      "train loss:0.007566475131468314\n",
      "train loss:0.06543780849154271\n",
      "train loss:0.004309376108907875\n",
      "train loss:0.018540683642953908\n",
      "train loss:0.01342089756194643\n",
      "train loss:0.05048508394498305\n",
      "train loss:0.005293336336354748\n",
      "train loss:0.010798404276878228\n",
      "train loss:0.0034624953762852086\n",
      "train loss:0.008546542956057075\n",
      "train loss:0.009364687759785743\n",
      "train loss:0.011452709344770464\n",
      "train loss:0.004676914670052793\n",
      "train loss:0.009455908128302423\n",
      "train loss:0.018228031804456122\n",
      "train loss:0.03157012331978657\n",
      "train loss:0.001579854867804198\n",
      "train loss:0.005821904434224446\n",
      "train loss:0.01693221257892551\n",
      "train loss:0.010041854922556787\n",
      "train loss:0.03226623157611559\n",
      "train loss:0.018390134727383253\n",
      "train loss:0.0018642040446224678\n",
      "train loss:0.004240892613103091\n",
      "train loss:0.003962589531139457\n",
      "train loss:0.010845034220043903\n",
      "train loss:0.01686374224908865\n",
      "train loss:0.031972508454515165\n",
      "train loss:0.033096768199734596\n",
      "train loss:0.05185959334354728\n",
      "train loss:0.029027363919234203\n",
      "train loss:0.05333491646401206\n",
      "train loss:0.01676909842915015\n",
      "train loss:0.016887214627667502\n",
      "train loss:0.03865565573073345\n",
      "train loss:0.006654922821661874\n",
      "train loss:0.0063556132298339795\n",
      "train loss:0.024978497733426374\n",
      "train loss:0.01804305769858028\n",
      "train loss:0.08268040163673812\n",
      "train loss:0.03608280977331087\n",
      "train loss:0.0034692051393824465\n",
      "train loss:0.03258805433637813\n",
      "train loss:0.024586922407670096\n",
      "train loss:0.007350486125267207\n",
      "train loss:0.008922938742280246\n",
      "train loss:0.020927063189454663\n",
      "train loss:0.01301944124511774\n",
      "train loss:0.008250535484588867\n",
      "train loss:0.022285949678726973\n",
      "train loss:0.007540395667699103\n",
      "train loss:0.030929552586819505\n",
      "train loss:0.01112446749804831\n",
      "train loss:0.007928592743914872\n",
      "train loss:0.004324392554328709\n",
      "train loss:0.01781546199677432\n",
      "train loss:0.010461247856307438\n",
      "train loss:0.007531152170111733\n",
      "train loss:0.012094563091230979\n",
      "train loss:0.0289199313882061\n",
      "train loss:0.0105086095576143\n",
      "train loss:0.008002796420502379\n",
      "=== epoch:7, train acc:0.992, test acc:0.983 ===\n",
      "train loss:0.01270134445823601\n",
      "train loss:0.006293671191523739\n",
      "train loss:0.008016443364356012\n",
      "train loss:0.012798731965668783\n",
      "train loss:0.012208945466922447\n",
      "train loss:0.017185847570097387\n",
      "train loss:0.00895090614926531\n",
      "train loss:0.005456539587796837\n",
      "train loss:0.022009870497558426\n",
      "train loss:0.04927987396559413\n",
      "train loss:0.005014275641356758\n",
      "train loss:0.016753838494248174\n",
      "train loss:0.021134001854206153\n",
      "train loss:0.023185939248261546\n",
      "train loss:0.005115703177458758\n",
      "train loss:0.027599652002918206\n",
      "train loss:0.005393630880405982\n",
      "train loss:0.036914022232881746\n",
      "train loss:0.010438164403587389\n",
      "train loss:0.029621162803797462\n",
      "train loss:0.025441939513194324\n",
      "train loss:0.013762833917114112\n",
      "train loss:0.011748752921516867\n",
      "train loss:0.0030822593697824737\n",
      "train loss:0.043942527958197246\n",
      "train loss:0.031300355179960236\n",
      "train loss:0.011575972386392748\n",
      "train loss:0.023895814397783082\n",
      "train loss:0.006544678704188025\n",
      "train loss:0.004517152726402748\n",
      "train loss:0.005348282081311316\n",
      "train loss:0.010009838440150293\n",
      "train loss:0.013214297088021616\n",
      "train loss:0.04171196677483979\n",
      "train loss:0.010297477437722056\n",
      "train loss:0.006835248782262847\n",
      "train loss:0.014146974481782846\n",
      "train loss:0.0022971038199226146\n",
      "train loss:0.006029646048816843\n",
      "train loss:0.01121763824541278\n",
      "train loss:0.008400766055984684\n",
      "train loss:0.03646293805779051\n",
      "train loss:0.014303995890830937\n",
      "train loss:0.015339058214010411\n",
      "train loss:0.016493717115122777\n",
      "train loss:0.007635462284332537\n",
      "train loss:0.053921983035025926\n",
      "train loss:0.020174157282699702\n",
      "train loss:0.005465200415477826\n",
      "train loss:0.005094277270178202\n",
      "train loss:0.004843649828916181\n",
      "train loss:0.01072668317193812\n",
      "train loss:0.013657397170310908\n",
      "train loss:0.02486901605378777\n",
      "train loss:0.01987572478063056\n",
      "train loss:0.015028591135477781\n",
      "train loss:0.0793206778048431\n",
      "train loss:0.011315290422725093\n",
      "train loss:0.006864393680019659\n",
      "train loss:0.007446164088720306\n",
      "train loss:0.038239234724640636\n",
      "train loss:0.03848063644811745\n",
      "train loss:0.005308195362922669\n",
      "train loss:0.008009524215042061\n",
      "train loss:0.023289721429116294\n",
      "train loss:0.001950552139872144\n",
      "train loss:0.003297173974403051\n",
      "train loss:0.019476886911846288\n",
      "train loss:0.0018751249932447533\n",
      "train loss:0.021486141774248853\n",
      "train loss:0.005374749662375746\n",
      "train loss:0.008138267610858025\n",
      "train loss:0.046065624262349454\n",
      "train loss:0.022015903862489177\n",
      "train loss:0.02221297804330505\n",
      "train loss:0.019817683667562144\n",
      "train loss:0.0326036709165102\n",
      "train loss:0.02253651877133151\n",
      "train loss:0.028193645896387606\n",
      "train loss:0.02705410590869947\n",
      "train loss:0.022922784571730977\n",
      "train loss:0.004124598801565753\n",
      "train loss:0.0028002643269285986\n",
      "train loss:0.027076832642194598\n",
      "train loss:0.012297949659708691\n",
      "train loss:0.013119633301862832\n",
      "train loss:0.00396964368653934\n",
      "train loss:0.010742306037283671\n",
      "train loss:0.08840718316501141\n",
      "train loss:0.0034790341646501566\n",
      "train loss:0.019303476236433092\n",
      "train loss:0.0066529752844390385\n",
      "train loss:0.01220040333081265\n",
      "train loss:0.047107329069874256\n",
      "train loss:0.005354784334823164\n",
      "train loss:0.019265657992178345\n",
      "train loss:0.02673513762750173\n",
      "train loss:0.0056939053886433865\n",
      "train loss:0.006115077386271542\n",
      "train loss:0.039853314711519705\n",
      "train loss:0.009240893267791537\n",
      "train loss:0.004572303712077229\n",
      "train loss:0.00849190756345264\n",
      "train loss:0.07478272464557105\n",
      "train loss:0.06467562939518051\n",
      "train loss:0.01958749411501279\n",
      "train loss:0.024018438461317043\n",
      "train loss:0.017959926555281603\n",
      "train loss:0.02436533991092358\n",
      "train loss:0.03308037458015368\n",
      "train loss:0.018175175516567298\n",
      "train loss:0.04556494593396958\n",
      "train loss:0.017226907006124396\n",
      "train loss:0.009835002431101992\n",
      "train loss:0.006782494847658954\n",
      "train loss:0.04770141882795202\n",
      "train loss:0.00940767490546269\n",
      "train loss:0.0017968202242284507\n",
      "train loss:0.012790531502408428\n",
      "train loss:0.006478774583944607\n",
      "train loss:0.015115302680420994\n",
      "train loss:0.0037522782936238387\n",
      "train loss:0.04268055447962507\n",
      "train loss:0.004726093136839289\n",
      "train loss:0.029956903529805817\n",
      "train loss:0.021830510934335027\n",
      "train loss:0.007475198189592277\n",
      "train loss:0.00894045685861334\n",
      "train loss:0.03183491938750734\n",
      "train loss:0.005790116574632222\n",
      "train loss:0.006267061753963167\n",
      "train loss:0.0021992321580698326\n",
      "train loss:0.022470517608327398\n",
      "train loss:0.006798462152671306\n",
      "train loss:0.02946398950304475\n",
      "train loss:0.023349681088134306\n",
      "train loss:0.0070697261174357704\n",
      "train loss:0.022800529443441304\n",
      "train loss:0.009282207886370953\n",
      "train loss:0.00618372691636216\n",
      "train loss:0.006376901053237768\n",
      "train loss:0.006372191372977527\n",
      "train loss:0.024507786440876873\n",
      "train loss:0.01764029715367831\n",
      "train loss:0.007233268618967334\n",
      "train loss:0.0018223511541741475\n",
      "train loss:0.007538820687481278\n",
      "train loss:0.006495665337791102\n",
      "train loss:0.03733377588475319\n",
      "train loss:0.024371393103415104\n",
      "train loss:0.03290921934494539\n",
      "train loss:0.004254167745091356\n",
      "train loss:0.004593276073623816\n",
      "train loss:0.04346554571411147\n",
      "train loss:0.015233734540597645\n",
      "train loss:0.04716404926431956\n",
      "train loss:0.003145342341202411\n",
      "train loss:0.005372634829823665\n",
      "train loss:0.01154532417986876\n",
      "train loss:0.0478704762880413\n",
      "train loss:0.010202799026850496\n",
      "train loss:0.00723785222450041\n",
      "train loss:0.004670568289388312\n",
      "train loss:0.007976314374110307\n",
      "train loss:0.03504526916743158\n",
      "train loss:0.008231939236555132\n",
      "train loss:0.008575227189919812\n",
      "train loss:0.002515406273260047\n",
      "train loss:0.008816788305560895\n",
      "train loss:0.006911867504542506\n",
      "train loss:0.013644366366331696\n",
      "train loss:0.046049274145742045\n",
      "train loss:0.00394130593584325\n",
      "train loss:0.016455740844030703\n",
      "train loss:0.004781612768050462\n",
      "train loss:0.01812521839298964\n",
      "train loss:0.00892151205619976\n",
      "train loss:0.009762881880674095\n",
      "train loss:0.007126179212527939\n",
      "train loss:0.006262205011720043\n",
      "train loss:0.06937340259582098\n",
      "train loss:0.01430110091975237\n",
      "train loss:0.005094409922849863\n",
      "train loss:0.014630912736468762\n",
      "train loss:0.02610693788395211\n",
      "train loss:0.03263153812904563\n",
      "train loss:0.010210770961675074\n",
      "train loss:0.0022008623606956435\n",
      "train loss:0.0033816509621001946\n",
      "train loss:0.007316071366777259\n",
      "train loss:0.010487402503061717\n",
      "train loss:0.006239550685669491\n",
      "train loss:0.008480878218305395\n",
      "train loss:0.006599027248931293\n",
      "train loss:0.004542852577654923\n",
      "train loss:0.023857611870440817\n",
      "train loss:0.015149727546228538\n",
      "train loss:0.0170574046034327\n",
      "train loss:0.10458205678527008\n",
      "train loss:0.009087655382093142\n",
      "train loss:0.017523556118186998\n",
      "train loss:0.008224603717978925\n",
      "train loss:0.003944009940800694\n",
      "train loss:0.0308149893595859\n",
      "train loss:0.010852135426854603\n",
      "train loss:0.027140610906530624\n",
      "train loss:0.029479243454717675\n",
      "train loss:0.004245334863955768\n",
      "train loss:0.0026151916712695185\n",
      "train loss:0.08270634293262798\n",
      "train loss:0.018380353082244255\n",
      "train loss:0.01285975313313591\n",
      "train loss:0.011806621079968674\n",
      "train loss:0.010145089185255356\n",
      "train loss:0.0026050421671621527\n",
      "train loss:0.010400778047628392\n",
      "train loss:0.048201075094907724\n",
      "train loss:0.002226674497639595\n",
      "train loss:0.006464196272006744\n",
      "train loss:0.013763569750362931\n",
      "train loss:0.0017896807467035856\n",
      "train loss:0.012617245815322992\n",
      "train loss:0.003720211776911834\n",
      "train loss:0.011273103252829663\n",
      "train loss:0.03126763551576768\n",
      "train loss:0.023366349795698575\n",
      "train loss:0.023108787423661833\n",
      "train loss:0.053769116453034914\n",
      "train loss:0.008108263228913467\n",
      "train loss:0.007868081762745843\n",
      "train loss:0.025886182401703085\n",
      "train loss:0.03086718651336572\n",
      "train loss:0.01716291100093936\n",
      "train loss:0.09548154506724633\n",
      "train loss:0.014701558918259972\n",
      "train loss:0.006719724743031968\n",
      "train loss:0.00910432681056867\n",
      "train loss:0.009726268691002689\n",
      "train loss:0.05852126504747788\n",
      "train loss:0.020460202201887066\n",
      "train loss:0.016838169622330375\n",
      "train loss:0.008965854109146281\n",
      "train loss:0.03196717297992355\n",
      "train loss:0.010922944851683295\n",
      "train loss:0.005853305461178606\n",
      "train loss:0.008752717147213124\n",
      "train loss:0.0055980325608443885\n",
      "train loss:0.034332581913576986\n",
      "train loss:0.009306363053612909\n",
      "train loss:0.009704412816022478\n",
      "train loss:0.028586301704063195\n",
      "train loss:0.0268548277954349\n",
      "train loss:0.008398840306300866\n",
      "train loss:0.0016816194038319326\n",
      "train loss:0.011212671516665697\n",
      "train loss:0.005385613987408205\n",
      "train loss:0.027625754313471945\n",
      "train loss:0.01951959471389548\n",
      "train loss:0.004725591496963034\n",
      "train loss:0.018598368977015167\n",
      "train loss:0.007092938420838761\n",
      "train loss:0.02871798908278119\n",
      "train loss:0.08265961216820067\n",
      "train loss:0.01265253588754412\n",
      "train loss:0.017400420879535503\n",
      "train loss:0.0033550250364546706\n",
      "train loss:0.004784543916503462\n",
      "train loss:0.005286875000481237\n",
      "train loss:0.0011034967609486336\n",
      "train loss:0.0045257083170401205\n",
      "train loss:0.0032755035735005434\n",
      "train loss:0.009229275902139632\n",
      "train loss:0.012164565146913284\n",
      "train loss:0.030496427489946472\n",
      "train loss:0.004809081405669158\n",
      "train loss:0.006593124037119223\n",
      "train loss:0.0024006041822582907\n",
      "train loss:0.002075008962542794\n",
      "train loss:0.0037754121581361783\n",
      "train loss:0.0012550764210668003\n",
      "train loss:0.019399975442841097\n",
      "train loss:0.01000000961692345\n",
      "train loss:0.010572635711830236\n",
      "train loss:0.005697254989405234\n",
      "train loss:0.005381063068339299\n",
      "train loss:0.013316048084898661\n",
      "train loss:0.024956138351980944\n",
      "train loss:0.0013918702140861224\n",
      "train loss:0.002829410514009096\n",
      "train loss:0.008070707443770874\n",
      "train loss:0.041434894610351145\n",
      "train loss:0.0029257015771651275\n",
      "train loss:0.014151457168786916\n",
      "train loss:0.005723778070737467\n",
      "train loss:0.0016448562721506125\n",
      "train loss:0.022417449856948757\n",
      "train loss:0.0077735008347992966\n",
      "train loss:0.001661739794410711\n",
      "train loss:0.00536761187606819\n",
      "train loss:0.034949634188095574\n",
      "train loss:0.04360739592042506\n",
      "train loss:0.008309495352191302\n",
      "train loss:0.02441654323062728\n",
      "train loss:0.004407709107790428\n",
      "train loss:0.008826102373104636\n",
      "train loss:0.009596382250615985\n",
      "train loss:0.012090573740593137\n",
      "train loss:0.12670271194189664\n",
      "train loss:0.006254440569102829\n",
      "train loss:0.061023438679006746\n",
      "train loss:0.010691714127833969\n",
      "train loss:0.005257904540116044\n",
      "train loss:0.0033762742894439817\n",
      "train loss:0.009960432916149427\n",
      "train loss:0.014585674484083731\n",
      "train loss:0.004497721441533371\n",
      "train loss:0.028936268518809132\n",
      "train loss:0.027942070842538493\n",
      "train loss:0.0006574367980176239\n",
      "train loss:0.005475188113095621\n",
      "train loss:0.01620931353948195\n",
      "train loss:0.015759664818152722\n",
      "train loss:0.004748125021797812\n",
      "train loss:0.002527972576765538\n",
      "train loss:0.00657844410860739\n",
      "train loss:0.029211860028903594\n",
      "train loss:0.0015904399128591844\n",
      "train loss:0.024564607410961427\n",
      "train loss:0.013587316277627532\n",
      "train loss:0.0067441363390598995\n",
      "train loss:0.013848192710047407\n",
      "train loss:0.016940559895008075\n",
      "train loss:0.007417109980704446\n",
      "train loss:0.015448395852137477\n",
      "train loss:0.0034355662622635157\n",
      "train loss:0.014784395885646182\n",
      "train loss:0.0025123042664353516\n",
      "train loss:0.10673683510343591\n",
      "train loss:0.027451734755463073\n",
      "train loss:0.020571194081163716\n",
      "train loss:0.0017136843919137426\n",
      "train loss:0.01546232774317239\n",
      "train loss:0.008548314065779895\n",
      "train loss:0.027832378677445764\n",
      "train loss:0.027379767474788652\n",
      "train loss:0.004299937962479682\n",
      "train loss:0.0161722048322343\n",
      "train loss:0.03179525180791811\n",
      "train loss:0.00644070944621462\n",
      "train loss:0.0063566244611322886\n",
      "train loss:0.03096465277918657\n",
      "train loss:0.0039110691194804\n",
      "train loss:0.014873419032536998\n",
      "train loss:0.0036172973171313045\n",
      "train loss:0.011569828030849588\n",
      "train loss:0.016467101431474417\n",
      "train loss:0.011117913967133668\n",
      "train loss:0.028008209950870135\n",
      "train loss:0.05861470633122161\n",
      "train loss:0.002431274478207715\n",
      "train loss:0.019871266159307864\n",
      "train loss:0.003696630219687547\n",
      "train loss:0.0042178096242391225\n",
      "train loss:0.021044702795624478\n",
      "train loss:0.0334399667468564\n",
      "train loss:0.01422733411602356\n",
      "train loss:0.009873832268307441\n",
      "train loss:0.010286206049042103\n",
      "train loss:0.018494073985986795\n",
      "train loss:0.026681583591321147\n",
      "train loss:0.020697384439351846\n",
      "train loss:0.01459708255844051\n",
      "train loss:0.0033811285376475187\n",
      "train loss:0.0034403793963587006\n",
      "train loss:0.009219345801314937\n",
      "train loss:0.005747219814842271\n",
      "train loss:0.009358415896030273\n",
      "train loss:0.006754712661227899\n",
      "train loss:0.018302789603222337\n",
      "train loss:0.009019383217010598\n",
      "train loss:0.009119479872210673\n",
      "train loss:0.020893526880623625\n",
      "train loss:0.02066373820670891\n",
      "train loss:0.009869437743985273\n",
      "train loss:0.005644401266522334\n",
      "train loss:0.0028190946472139555\n",
      "train loss:0.011530315907511822\n",
      "train loss:0.007641807390550612\n",
      "train loss:0.011497026734613081\n",
      "train loss:0.010474934989033678\n",
      "train loss:0.018585390786713295\n",
      "train loss:0.015372405235700704\n",
      "train loss:0.012834202582987002\n",
      "train loss:0.012332838851158903\n",
      "train loss:0.009835817623106882\n",
      "train loss:0.012054148920911122\n",
      "train loss:0.004944333368351882\n",
      "train loss:0.004493202349073765\n",
      "train loss:0.004830089875216475\n",
      "train loss:0.013611447379657034\n",
      "train loss:0.017045615047411904\n",
      "train loss:0.01928924935952313\n",
      "train loss:0.022621198817162406\n",
      "train loss:0.007045661970558934\n",
      "train loss:0.005009722776682047\n",
      "train loss:0.005955572850739602\n",
      "train loss:0.01845909885480866\n",
      "train loss:0.004284493879209149\n",
      "train loss:0.007374755473785851\n",
      "train loss:0.007069331020911998\n",
      "train loss:0.01364162989757505\n",
      "train loss:0.0021716247367030337\n",
      "train loss:0.0017108617328901179\n",
      "train loss:0.006431345573866058\n",
      "train loss:0.015370313740052462\n",
      "train loss:0.004013390098147464\n",
      "train loss:0.014051965275790163\n",
      "train loss:0.0031289516131042684\n",
      "train loss:0.017193614355259342\n",
      "train loss:0.015374015341361808\n",
      "train loss:0.005050863364648634\n",
      "train loss:0.03064728874629858\n",
      "train loss:0.002612170594604506\n",
      "train loss:0.0009019916042155694\n",
      "train loss:0.044055330157502764\n",
      "train loss:0.017112824467310276\n",
      "train loss:0.01255877602708721\n",
      "train loss:0.01931427559116751\n",
      "train loss:0.002894126714736585\n",
      "train loss:0.01573483297745131\n",
      "train loss:0.025586944545267637\n",
      "train loss:0.0018955857061174264\n",
      "train loss:0.014017169256885459\n",
      "train loss:0.013370562108536647\n",
      "train loss:0.013390948047118491\n",
      "train loss:0.017214440952376203\n",
      "train loss:0.01649260982326682\n",
      "train loss:0.0022926122562540547\n",
      "train loss:0.004237109097973978\n",
      "train loss:0.016630882616450307\n",
      "train loss:0.006078609128956135\n",
      "train loss:0.010134534019279553\n",
      "train loss:0.006151382319500652\n",
      "train loss:0.010443780765886486\n",
      "train loss:0.07358550037561228\n",
      "train loss:0.004906245400269058\n",
      "train loss:0.022845139791357442\n",
      "train loss:0.003082178254417841\n",
      "train loss:0.013378619283355668\n",
      "train loss:0.01957640429646568\n",
      "train loss:0.00775479055925626\n",
      "train loss:0.005421415063602868\n",
      "train loss:0.01538649577955007\n",
      "train loss:0.008751927192480734\n",
      "train loss:0.0032801683839914306\n",
      "train loss:0.07332836076787645\n",
      "train loss:0.019178882057702486\n",
      "train loss:0.0015155320670357558\n",
      "train loss:0.004091869113853499\n",
      "train loss:0.022625837400598578\n",
      "train loss:0.017219495514335784\n",
      "train loss:0.0016277202431494763\n",
      "train loss:0.06920467656188813\n",
      "train loss:0.007692864820442181\n",
      "train loss:0.004164218209743115\n",
      "train loss:0.014131153347440417\n",
      "train loss:0.01865215430628578\n",
      "train loss:0.00846809451123482\n",
      "train loss:0.006021506076351341\n",
      "train loss:0.008446141254433904\n",
      "train loss:0.0010576390958912895\n",
      "train loss:0.03149794432806175\n",
      "train loss:0.012889505258404819\n",
      "train loss:0.008256542572900915\n",
      "train loss:0.010537152438026089\n",
      "train loss:0.005074182544917155\n",
      "train loss:0.06569802534580117\n",
      "train loss:0.01406922917548934\n",
      "train loss:0.00934850083631688\n",
      "train loss:0.026499673246676788\n",
      "train loss:0.04058092924001404\n",
      "train loss:0.0027393288765429685\n",
      "train loss:0.0034297884255863613\n",
      "train loss:0.006909459164769094\n",
      "train loss:0.009860930372239746\n",
      "train loss:0.018965378483916103\n",
      "train loss:0.07169463934871426\n",
      "train loss:0.007734467416513401\n",
      "train loss:0.007781082481745441\n",
      "train loss:0.06329967998471336\n",
      "train loss:0.016409727517082157\n",
      "train loss:0.009519216368682746\n",
      "train loss:0.023177929265654117\n",
      "train loss:0.015777960013254225\n",
      "train loss:0.006606544543489527\n",
      "train loss:0.018511104448995765\n",
      "train loss:0.005908277726099773\n",
      "train loss:0.04978741603122648\n",
      "train loss:0.007348682569313552\n",
      "train loss:0.01731921361168527\n",
      "train loss:0.0036317584304452174\n",
      "train loss:0.009089630165027647\n",
      "train loss:0.012830014860700921\n",
      "train loss:0.010567577147364393\n",
      "train loss:0.0017772731610977341\n",
      "train loss:0.010768988327132425\n",
      "train loss:0.016011317350364318\n",
      "train loss:0.003137035988810054\n",
      "train loss:0.006667912230904485\n",
      "train loss:0.010670923898377588\n",
      "train loss:0.01125066410057458\n",
      "train loss:0.01070498180440203\n",
      "train loss:0.01081233754673942\n",
      "train loss:0.01627258633467907\n",
      "train loss:0.01515521405801138\n",
      "train loss:0.003214506116127129\n",
      "train loss:0.016313595798181913\n",
      "train loss:0.007262594216470943\n",
      "train loss:0.010035020906581014\n",
      "train loss:0.01296322843538968\n",
      "train loss:0.02061577047791447\n",
      "train loss:0.0035983448162827648\n",
      "train loss:0.02090069689407724\n",
      "train loss:0.005278748880042083\n",
      "train loss:0.04075954049417931\n",
      "train loss:0.009932286813963754\n",
      "train loss:0.01893516212305653\n",
      "train loss:0.002831482840285799\n",
      "train loss:0.04075661749436102\n",
      "train loss:0.003360523978404177\n",
      "train loss:0.010147512016936942\n",
      "train loss:0.00870701722259743\n",
      "train loss:0.003854648564286642\n",
      "train loss:0.007802061849265569\n",
      "train loss:0.0040257427028007435\n",
      "train loss:0.018265938228335186\n",
      "train loss:0.004575237064085125\n",
      "train loss:0.01161623804193437\n",
      "train loss:0.013879802034853325\n",
      "train loss:0.013980095815585897\n",
      "train loss:0.002515437340635755\n",
      "train loss:0.003858037384878015\n",
      "train loss:0.007313690597750175\n",
      "train loss:0.01271566849835426\n",
      "train loss:0.034461955504272404\n",
      "train loss:0.0076823492294392825\n",
      "train loss:0.010276479483589014\n",
      "train loss:0.00722876564273469\n",
      "train loss:0.001871934055247245\n",
      "train loss:0.0026643855729359474\n",
      "train loss:0.024254945874154485\n",
      "train loss:0.0057615200329670935\n",
      "train loss:0.0036465699161079353\n",
      "train loss:0.0026926340823760653\n",
      "train loss:0.004023653506727419\n",
      "train loss:0.007278641961030214\n",
      "train loss:0.008207889009894479\n",
      "train loss:0.004344959131856765\n",
      "train loss:0.011964794900250637\n",
      "train loss:0.003882286060493551\n",
      "train loss:0.0018750318697130328\n",
      "train loss:0.013989043284417784\n",
      "train loss:0.01117794668844643\n",
      "train loss:0.0019581211621026605\n",
      "train loss:0.004346929268478618\n",
      "train loss:0.008602719382789425\n",
      "train loss:0.002788182897276602\n",
      "train loss:0.016627136920989747\n",
      "train loss:0.0029922769752637134\n",
      "train loss:0.0024855940618726045\n",
      "train loss:0.008010439558336345\n",
      "train loss:0.013607430462538624\n",
      "train loss:0.0025557037312153017\n",
      "train loss:0.009848941872023616\n",
      "train loss:0.0030366487701696115\n",
      "train loss:0.011019922773725337\n",
      "train loss:0.012577266482092366\n",
      "train loss:0.024184060688594286\n",
      "train loss:0.01726332694043657\n",
      "train loss:0.014391841461339922\n",
      "train loss:0.013834595312934472\n",
      "train loss:0.045998667229181465\n",
      "train loss:0.011942826572423602\n",
      "train loss:0.005398559064553774\n",
      "train loss:0.01783784545802863\n",
      "train loss:0.022376487858395456\n",
      "train loss:0.024092868597771773\n",
      "train loss:0.01835206423422406\n",
      "train loss:0.03088237444241523\n",
      "train loss:0.0325085140984449\n",
      "train loss:0.008985590719658185\n",
      "train loss:0.0043095336035111785\n",
      "train loss:0.009939742624704677\n",
      "train loss:0.0018387076721144316\n",
      "train loss:0.09009298608120993\n",
      "train loss:0.01380380366703992\n",
      "train loss:0.018407538497968584\n",
      "train loss:0.0013807459239293096\n",
      "train loss:0.013760671706999891\n",
      "train loss:0.007489061862310098\n",
      "=== epoch:8, train acc:0.99, test acc:0.993 ===\n",
      "train loss:0.022725431769173646\n",
      "train loss:0.06527541668013369\n",
      "train loss:0.014332411079401964\n",
      "train loss:0.013273704771709445\n",
      "train loss:0.008795041553601272\n",
      "train loss:0.018455220963691742\n",
      "train loss:0.020871730614947896\n",
      "train loss:0.004620085355943578\n",
      "train loss:0.07731419913175042\n",
      "train loss:0.008905414297705756\n",
      "train loss:0.010378294968052166\n",
      "train loss:0.000981907945934692\n",
      "train loss:0.00296588469961751\n",
      "train loss:0.014991018231008906\n",
      "train loss:0.020882590651850087\n",
      "train loss:0.006510642183055585\n",
      "train loss:0.006806774606808214\n",
      "train loss:0.007414969787837222\n",
      "train loss:0.02196727589863653\n",
      "train loss:0.00868742289792599\n",
      "train loss:0.04787719589359508\n",
      "train loss:0.006186307039896668\n",
      "train loss:0.020804861217003406\n",
      "train loss:0.010357937087839246\n",
      "train loss:0.07155044381516883\n",
      "train loss:0.008977994476200409\n",
      "train loss:0.006516139878061932\n",
      "train loss:0.013204829093342745\n",
      "train loss:0.009060109277513217\n",
      "train loss:0.056220838398116306\n",
      "train loss:0.015091544274556511\n",
      "train loss:0.00896556055988878\n",
      "train loss:0.025924185487619936\n",
      "train loss:0.01936321500318949\n",
      "train loss:0.0029492154483569876\n",
      "train loss:0.0065289316616398765\n",
      "train loss:0.028661902556005647\n",
      "train loss:0.022067674843002552\n",
      "train loss:0.010375009713402893\n",
      "train loss:0.004832458463531187\n",
      "train loss:0.02390793759062547\n",
      "train loss:0.006411096425754586\n",
      "train loss:0.011806668765336346\n",
      "train loss:0.00253939965626774\n",
      "train loss:0.017399026868320514\n",
      "train loss:0.011464844020292164\n",
      "train loss:0.012679050396624236\n",
      "train loss:0.03174951885293316\n",
      "train loss:0.0027362871505731234\n",
      "train loss:0.003321037379611147\n",
      "train loss:0.006210345983364779\n",
      "train loss:0.06259391359360922\n",
      "train loss:0.015477008622985029\n",
      "train loss:0.0049974044652467305\n",
      "train loss:0.03559072978776565\n",
      "train loss:0.07677891752060399\n",
      "train loss:0.00492338703492302\n",
      "train loss:0.023827530887751306\n",
      "train loss:0.00903713426306387\n",
      "train loss:0.012296134425538487\n",
      "train loss:0.013023950471381773\n",
      "train loss:0.0203553559309578\n",
      "train loss:0.0039653346346317795\n",
      "train loss:0.004773775370799431\n",
      "train loss:0.016424176162475875\n",
      "train loss:0.013382515431756383\n",
      "train loss:0.008651123017729885\n",
      "train loss:0.007410288229294086\n",
      "train loss:0.024270163886649203\n",
      "train loss:0.0012165160277993166\n",
      "train loss:0.0031301833582276896\n",
      "train loss:0.03002223364996083\n",
      "train loss:0.01701038701014882\n",
      "train loss:0.02510610389420258\n",
      "train loss:0.0035538211672347265\n",
      "train loss:0.006059432025759398\n",
      "train loss:0.032644883190444764\n",
      "train loss:0.002861040670535908\n",
      "train loss:0.007768395910042126\n",
      "train loss:0.039746669310498216\n",
      "train loss:0.02475155197593542\n",
      "train loss:0.008522686121969684\n",
      "train loss:0.0034068338993985593\n",
      "train loss:0.022200202449258022\n",
      "train loss:0.005113909908499765\n",
      "train loss:0.004212207954248269\n",
      "train loss:0.0056077163379987145\n",
      "train loss:0.0026193414457119594\n",
      "train loss:0.0019365938289180298\n",
      "train loss:0.003802436317274294\n",
      "train loss:0.007213542752742754\n",
      "train loss:0.05563512789503064\n",
      "train loss:0.005299591818750246\n",
      "train loss:0.023492839441845284\n",
      "train loss:0.050066177826402276\n",
      "train loss:0.027299210882557996\n",
      "train loss:0.004629840851391724\n",
      "train loss:0.006013465183959576\n",
      "train loss:0.020926121510283807\n",
      "train loss:0.010087293270998703\n",
      "train loss:0.005766417173213979\n",
      "train loss:0.006717581323467536\n",
      "train loss:0.02437354607715601\n",
      "train loss:0.019951775959566483\n",
      "train loss:0.0025872515987111155\n",
      "train loss:0.012682395910905302\n",
      "train loss:0.011807946315608813\n",
      "train loss:0.010254978140354315\n",
      "train loss:0.004718233799625027\n",
      "train loss:0.008907488114746898\n",
      "train loss:0.032665513485782435\n",
      "train loss:0.0033124685811970703\n",
      "train loss:0.06502780140179551\n",
      "train loss:0.03002253570542352\n",
      "train loss:0.0043512554941373535\n",
      "train loss:0.004918893681917508\n",
      "train loss:0.010053554352920826\n",
      "train loss:0.010167765815268088\n",
      "train loss:0.07649503259326523\n",
      "train loss:0.009551317275240466\n",
      "train loss:0.0026483792115003153\n",
      "train loss:0.06406451933585307\n",
      "train loss:0.02094756638810047\n",
      "train loss:0.015456017234423136\n",
      "train loss:0.016678764067277786\n",
      "train loss:0.035810631342535884\n",
      "train loss:0.07836989057711505\n",
      "train loss:0.004509608437823155\n",
      "train loss:0.03217725045361759\n",
      "train loss:0.004222628135980419\n",
      "train loss:0.05234607218128016\n",
      "train loss:0.007960180182508086\n",
      "train loss:0.025190509555974776\n",
      "train loss:0.0219040695674175\n",
      "train loss:0.004149525307131252\n",
      "train loss:0.005634401012761003\n",
      "train loss:0.0007081679486210455\n",
      "train loss:0.008027862929419871\n",
      "train loss:0.009637273921444008\n",
      "train loss:0.0051527086790646714\n",
      "train loss:0.005261207486251981\n",
      "train loss:0.02605971243354019\n",
      "train loss:0.004994913419005137\n",
      "train loss:0.010094108094700066\n",
      "train loss:0.017572230528703894\n",
      "train loss:0.012028049892270489\n",
      "train loss:0.00375912564093905\n",
      "train loss:0.0025782255082471904\n",
      "train loss:0.014195732341554529\n",
      "train loss:0.012098973990552701\n",
      "train loss:0.011573645110193941\n",
      "train loss:0.007661531455103819\n",
      "train loss:0.005590872739792509\n",
      "train loss:0.01579712564762624\n",
      "train loss:0.0003520215625804738\n",
      "train loss:0.007126230616609132\n",
      "train loss:0.006233650783131725\n",
      "train loss:0.03244413431134795\n",
      "train loss:0.014256400239804916\n",
      "train loss:0.003976255884218063\n",
      "train loss:0.0037518314705268824\n",
      "train loss:0.004880886929386702\n",
      "train loss:0.04045697391076669\n",
      "train loss:0.008607602046208616\n",
      "train loss:0.003541783644721162\n",
      "train loss:0.021250985064280442\n",
      "train loss:0.002235389416785437\n",
      "train loss:0.01678504417050216\n",
      "train loss:0.011651647439065327\n",
      "train loss:0.025693432652959206\n",
      "train loss:0.008311530933592853\n",
      "train loss:0.10542112743154307\n",
      "train loss:0.007310058440364078\n",
      "train loss:0.021104044056567406\n",
      "train loss:0.01211462247034181\n",
      "train loss:0.007311292064411409\n",
      "train loss:0.0069998874949962105\n",
      "train loss:0.005776119808347548\n",
      "train loss:0.003289390961414439\n",
      "train loss:0.003897738581258494\n",
      "train loss:0.010424457334866516\n",
      "train loss:0.0054216852856244\n",
      "train loss:0.005551255271423382\n",
      "train loss:0.025359014069519095\n",
      "train loss:0.012499214171446582\n",
      "train loss:0.004290561339131972\n",
      "train loss:0.00554942680414787\n",
      "train loss:0.025805178642738423\n",
      "train loss:0.06978367748490835\n",
      "train loss:0.003703057522019419\n",
      "train loss:0.0062649780299301105\n",
      "train loss:0.00929065211195983\n",
      "train loss:0.036037581070866936\n",
      "train loss:0.016620667389704132\n",
      "train loss:0.00573615656822858\n",
      "train loss:0.03752628269712603\n",
      "train loss:0.005911629329833389\n",
      "train loss:0.005530930411408191\n",
      "train loss:0.0011653984094950843\n",
      "train loss:0.002544833431838629\n",
      "train loss:0.008424728470330083\n",
      "train loss:0.036497062852456914\n",
      "train loss:0.10034931494615257\n",
      "train loss:0.0056884217164210734\n",
      "train loss:0.010204137006608218\n",
      "train loss:0.11123947130836234\n",
      "train loss:0.012001347222932867\n",
      "train loss:0.004952738012532043\n",
      "train loss:0.008760060712818775\n",
      "train loss:0.002105983608442857\n",
      "train loss:0.0073713813717476455\n",
      "train loss:0.014780115064516266\n",
      "train loss:0.009087829067323432\n",
      "train loss:0.008640089680906599\n",
      "train loss:0.014724977104605914\n",
      "train loss:0.015062083494245832\n",
      "train loss:0.015253448745010778\n",
      "train loss:0.029372607567904642\n",
      "train loss:0.02704825416860879\n",
      "train loss:0.029564655313302417\n",
      "train loss:0.004585793684478519\n",
      "train loss:0.0020788462349525983\n",
      "train loss:0.023060535977210903\n",
      "train loss:0.008796190857582592\n",
      "train loss:0.013196442458287416\n",
      "train loss:0.011852915137742696\n",
      "train loss:0.025570746878679426\n",
      "train loss:0.004925207806379558\n",
      "train loss:0.006804530080529758\n",
      "train loss:0.008695587538224154\n",
      "train loss:0.0069779160876169526\n",
      "train loss:0.06698082702628795\n",
      "train loss:0.033685139816524275\n",
      "train loss:0.024645511996463552\n",
      "train loss:0.0069661479296952026\n",
      "train loss:0.029800670461662238\n",
      "train loss:0.01924242088926167\n",
      "train loss:0.00370013687081067\n",
      "train loss:0.0036141834840135796\n",
      "train loss:0.014137903410217199\n",
      "train loss:0.02769087470880862\n",
      "train loss:0.03725187497738506\n",
      "train loss:0.011579663338011558\n",
      "train loss:0.006312303462403285\n",
      "train loss:0.005054332763372196\n",
      "train loss:0.05282080157501273\n",
      "train loss:0.021262981295437376\n",
      "train loss:0.027451651494337065\n",
      "train loss:0.012787307596505178\n",
      "train loss:0.016898622550977262\n",
      "train loss:0.01792730061050704\n",
      "train loss:0.006433650201356079\n",
      "train loss:0.039429748603383295\n",
      "train loss:0.005084595820360753\n",
      "train loss:0.0063792689267707404\n",
      "train loss:0.0030771053702971863\n",
      "train loss:0.022580022950330365\n",
      "train loss:0.017792619350751757\n",
      "train loss:0.002463088417204009\n",
      "train loss:0.029090891400830224\n",
      "train loss:0.005308564755741493\n",
      "train loss:0.008579397077745889\n",
      "train loss:0.05601027500793904\n",
      "train loss:0.010524261796289923\n",
      "train loss:0.010440568902353209\n",
      "train loss:0.02518774468626201\n",
      "train loss:0.033265980066680675\n",
      "train loss:0.0026891028038467137\n",
      "train loss:0.002758012980943456\n",
      "train loss:0.016066748506390945\n",
      "train loss:0.004206846828216744\n",
      "train loss:0.011088376026963241\n",
      "train loss:0.011220662409166722\n",
      "train loss:0.018007479404492488\n",
      "train loss:0.015100465682443777\n",
      "train loss:0.005687899499168145\n",
      "train loss:0.038160881617414544\n",
      "train loss:0.02630446706588079\n",
      "train loss:0.005534530322777934\n",
      "train loss:0.00565155557559722\n",
      "train loss:0.003018507883159006\n",
      "train loss:0.010197514321036041\n",
      "train loss:0.0022334298855266168\n",
      "train loss:0.013990463594551316\n",
      "train loss:0.009878360843642311\n",
      "train loss:0.020827211225666963\n",
      "train loss:0.016020731239456912\n",
      "train loss:0.005200942568886254\n",
      "train loss:0.05822650652843228\n",
      "train loss:0.0036217001503417723\n",
      "train loss:0.004965577533429606\n",
      "train loss:0.021885417217412457\n",
      "train loss:0.03187651954962694\n",
      "train loss:0.0042578481518453296\n",
      "train loss:0.004007024653630518\n",
      "train loss:0.006801421234821842\n",
      "train loss:0.007589072976334012\n",
      "train loss:0.01435611542098257\n",
      "train loss:0.022242915234933353\n",
      "train loss:0.0949372798690989\n",
      "train loss:0.009374857391191354\n",
      "train loss:0.05317293220589347\n",
      "train loss:0.01421303851157411\n",
      "train loss:0.017411449017242245\n",
      "train loss:0.004976553481295101\n",
      "train loss:0.03464655165874863\n",
      "train loss:0.009523373321388442\n",
      "train loss:0.013520758095310352\n",
      "train loss:0.005192597754605731\n",
      "train loss:0.001784568708773136\n",
      "train loss:0.019791359549918525\n",
      "train loss:0.09032772819991478\n",
      "train loss:0.004736262980547018\n",
      "train loss:0.023360167689536367\n",
      "train loss:0.009232303785486826\n",
      "train loss:0.0038557977617079088\n",
      "train loss:0.004024040725832586\n",
      "train loss:0.001493613696925051\n",
      "train loss:0.02525932489441026\n",
      "train loss:0.019982169639047385\n",
      "train loss:0.03345666505898207\n",
      "train loss:0.012548759968489616\n",
      "train loss:0.009103378759215868\n",
      "train loss:0.06882779226722839\n",
      "train loss:0.009415663547365935\n",
      "train loss:0.012531326019377634\n",
      "train loss:0.014363457511168248\n",
      "train loss:0.0044411456754745735\n",
      "train loss:0.011090877183820447\n",
      "train loss:0.01631243378916245\n",
      "train loss:0.005380547003426434\n",
      "train loss:0.02187295102052605\n",
      "train loss:0.04317718877116571\n",
      "train loss:0.12091224620455905\n",
      "train loss:0.013662641126981845\n",
      "train loss:0.013587534504985148\n",
      "train loss:0.007327285406702783\n",
      "train loss:0.010026250354144062\n",
      "train loss:0.020247792245023995\n",
      "train loss:0.005651005276174941\n",
      "train loss:0.004380883286549508\n",
      "train loss:0.007122402949520518\n",
      "train loss:0.008495773711984534\n",
      "train loss:0.012303874998902873\n",
      "train loss:0.014263592174048658\n",
      "train loss:0.012657311722727554\n",
      "train loss:0.026742865248618422\n",
      "train loss:0.00429891747816405\n",
      "train loss:0.008678148618232873\n",
      "train loss:0.00859123025466205\n",
      "train loss:0.002000755752899126\n",
      "train loss:0.00859848008065061\n",
      "train loss:0.0038799258207531224\n",
      "train loss:0.024677515312584605\n",
      "train loss:0.004817761179349981\n",
      "train loss:0.0031165249995037704\n",
      "train loss:0.03891049999903823\n",
      "train loss:0.005037160835303322\n",
      "train loss:0.0016541341574820368\n",
      "train loss:0.009946091344622125\n",
      "train loss:0.00411847793417003\n",
      "train loss:0.01846033051581618\n",
      "train loss:0.0009934059076702256\n",
      "train loss:0.021781508058759984\n",
      "train loss:0.04752032933515395\n",
      "train loss:0.017638496732643602\n",
      "train loss:0.055724406759568294\n",
      "train loss:0.00151360575956166\n",
      "train loss:0.01697170166038793\n",
      "train loss:0.057578959856432806\n",
      "train loss:0.005405209256093827\n",
      "train loss:0.09954792774261126\n",
      "train loss:0.010187741426798702\n",
      "train loss:0.0023208837689132015\n",
      "train loss:0.011087853744832702\n",
      "train loss:0.021084461110754935\n",
      "train loss:0.0072827635654694\n",
      "train loss:0.005323618297599078\n",
      "train loss:0.006105527023683594\n",
      "train loss:0.00219871993233721\n",
      "train loss:0.0023894711252848803\n",
      "train loss:0.0062026596504241634\n",
      "train loss:0.004775470227853461\n",
      "train loss:0.009668021121911813\n",
      "train loss:0.014316999598189415\n",
      "train loss:0.004496711224407746\n",
      "train loss:0.004126434739496778\n",
      "train loss:0.0032751353486382005\n",
      "train loss:0.005663505746734643\n",
      "train loss:0.00857750623749977\n",
      "train loss:0.0050304930456551815\n",
      "train loss:0.0051717775199207365\n",
      "train loss:0.005032173050739428\n",
      "train loss:0.001605227062767401\n",
      "train loss:0.009697340110439429\n",
      "train loss:0.0026974653062307188\n",
      "train loss:0.013688680114732453\n",
      "train loss:0.0034997092173391824\n",
      "train loss:0.046329692531121645\n",
      "train loss:0.01212276142265245\n",
      "train loss:0.013961930411176209\n",
      "train loss:0.011848847700719478\n",
      "train loss:0.01016039349294861\n",
      "train loss:0.038271796293070155\n",
      "train loss:0.005768625501153428\n",
      "train loss:0.036277898481694076\n",
      "train loss:0.0018287008287538825\n",
      "train loss:0.01768140399617019\n",
      "train loss:0.002285751725724796\n",
      "train loss:0.05736910999735307\n",
      "train loss:0.02525716350884782\n",
      "train loss:0.014632495173687738\n",
      "train loss:0.028563712993601303\n",
      "train loss:0.014425309894726943\n",
      "train loss:0.001113969595524462\n",
      "train loss:0.010599505198142907\n",
      "train loss:0.02294131449440314\n",
      "train loss:0.003594983100810523\n",
      "train loss:0.008408449215331425\n",
      "train loss:0.027882219675339295\n",
      "train loss:0.0024493627725999355\n",
      "train loss:0.014050461637674967\n",
      "train loss:0.03880153252763481\n",
      "train loss:0.013621265959752877\n",
      "train loss:0.035001317105602545\n",
      "train loss:0.01298078898788179\n",
      "train loss:0.01103804978458034\n",
      "train loss:0.019837942078341515\n",
      "train loss:0.004239217377458807\n",
      "train loss:0.0021905851086471946\n",
      "train loss:0.015491345488581682\n",
      "train loss:0.01369013906307\n",
      "train loss:0.006249146913247977\n",
      "train loss:0.014496604284521819\n",
      "train loss:0.011816303535899741\n",
      "train loss:0.005536207834719472\n",
      "train loss:0.05480020763398898\n",
      "train loss:0.0037833318481627198\n",
      "train loss:0.010777887337209113\n",
      "train loss:0.03692097501220373\n",
      "train loss:0.0009537681396110505\n",
      "train loss:0.008269726307374999\n",
      "train loss:0.004160219464914311\n",
      "train loss:0.016858952093337858\n",
      "train loss:0.011424419116563595\n",
      "train loss:0.0013494636318607388\n",
      "train loss:0.012265261843571976\n",
      "train loss:0.02018108183200167\n",
      "train loss:0.008637059055973758\n",
      "train loss:0.011866468336068834\n",
      "train loss:0.003482333878636909\n",
      "train loss:0.038756940126293264\n",
      "train loss:0.018967793516652252\n",
      "train loss:0.011418096121435694\n",
      "train loss:0.011074600561287047\n",
      "train loss:0.017032143992662466\n",
      "train loss:0.003231305386591868\n",
      "train loss:0.01011238432856365\n",
      "train loss:0.008778862340202113\n",
      "train loss:0.028647956668910856\n",
      "train loss:0.01671897956313605\n",
      "train loss:0.004277403667563662\n",
      "train loss:0.005563687448160563\n",
      "train loss:0.003823398764757701\n",
      "train loss:0.005686214053028619\n",
      "train loss:0.004333630305555999\n",
      "train loss:0.017235215124010755\n",
      "train loss:0.02408129410376704\n",
      "train loss:0.019587208289022807\n",
      "train loss:0.04948589608782413\n",
      "train loss:0.028603217427907817\n",
      "train loss:0.0021616759074678613\n",
      "train loss:0.004373276544114022\n",
      "train loss:0.010918549224109297\n",
      "train loss:0.019533377348837033\n",
      "train loss:0.04923190242446633\n",
      "train loss:0.028962942158807996\n",
      "train loss:0.019915256120441358\n",
      "train loss:0.03471631239147933\n",
      "train loss:0.010821098386043518\n",
      "train loss:0.024535143194161238\n",
      "train loss:0.01829841047827772\n",
      "train loss:0.004959058802221513\n",
      "train loss:0.012812162727727935\n",
      "train loss:0.009345949743015745\n",
      "train loss:0.005446609117742839\n",
      "train loss:0.011269931926100896\n",
      "train loss:0.008842590298874799\n",
      "train loss:0.0019325387414767527\n",
      "train loss:0.005842100197767652\n",
      "train loss:0.006312622287254697\n",
      "train loss:0.009459800882577222\n",
      "train loss:0.008772920596242555\n",
      "train loss:0.02053409747560853\n",
      "train loss:0.025627494293033917\n",
      "train loss:0.011173058655939466\n",
      "train loss:0.029510060266100778\n",
      "train loss:0.006454138727322128\n",
      "train loss:0.007559434728295365\n",
      "train loss:0.009886113248978179\n",
      "train loss:0.0055768070394310535\n",
      "train loss:0.001227790319511849\n",
      "train loss:0.017478717236793125\n",
      "train loss:0.0015272658111510945\n",
      "train loss:0.004046703345784736\n",
      "train loss:0.0036985056300315403\n",
      "train loss:0.011703444281000681\n",
      "train loss:0.001726287426633554\n",
      "train loss:0.011403329127960264\n",
      "train loss:0.006525312671327597\n",
      "train loss:0.0019127161930857048\n",
      "train loss:0.003946910302543511\n",
      "train loss:0.0035091189464830203\n",
      "train loss:0.006622547477327368\n",
      "train loss:0.01044596724685959\n",
      "train loss:0.006617382544918984\n",
      "train loss:0.0027366714119485404\n",
      "train loss:0.003942304779372728\n",
      "train loss:0.018143614302481417\n",
      "train loss:0.0026706382835996363\n",
      "train loss:0.03819319014031866\n",
      "train loss:0.006249221689244234\n",
      "train loss:0.054444900416675227\n",
      "train loss:0.026732442013702354\n",
      "train loss:0.0019051717285278966\n",
      "train loss:0.00746742599753628\n",
      "train loss:0.03344133697935147\n",
      "train loss:0.008933437851837306\n",
      "train loss:0.0019791995758413703\n",
      "train loss:0.0022337319258558426\n",
      "train loss:0.009627402586745826\n",
      "train loss:0.023747894877436507\n",
      "train loss:0.008434318172146685\n",
      "train loss:0.01106986431317976\n",
      "train loss:0.04154178606652455\n",
      "train loss:0.05742901376431503\n",
      "train loss:0.009722818218423152\n",
      "train loss:0.006535102538719405\n",
      "train loss:0.007871526938753884\n",
      "train loss:0.00802591659791113\n",
      "train loss:0.0028329021058780234\n",
      "train loss:0.010382337412375042\n",
      "train loss:0.004153846714230658\n",
      "train loss:0.004156007725144382\n",
      "train loss:0.030601798512156317\n",
      "train loss:0.0010369798645273323\n",
      "train loss:0.0030919595094351378\n",
      "train loss:0.008636666936930415\n",
      "train loss:0.005304891207772033\n",
      "train loss:0.04025685675189292\n",
      "train loss:0.008310248544281534\n",
      "train loss:0.010227938884922736\n",
      "train loss:0.007905778547817788\n",
      "train loss:0.006754847827763048\n",
      "train loss:0.0011860706736900992\n",
      "train loss:0.005859970554336851\n",
      "train loss:0.006703809097838838\n",
      "train loss:0.013622947180494081\n",
      "train loss:0.0044990227035814085\n",
      "train loss:0.0014250407328045681\n",
      "train loss:0.0008459810660353861\n",
      "train loss:0.0020498192213873044\n",
      "train loss:0.03774808372789948\n",
      "train loss:0.008548681920842608\n",
      "train loss:0.0024655137463863762\n",
      "train loss:0.0008568049687806607\n",
      "train loss:0.026351749400024237\n",
      "train loss:0.02058133674881456\n",
      "train loss:0.00534842817070828\n",
      "train loss:0.018135508878588207\n",
      "train loss:0.012095972287866035\n",
      "train loss:0.05877109338573293\n",
      "train loss:0.033887583308398556\n",
      "train loss:0.01032183147339484\n",
      "train loss:0.00477721670903082\n",
      "train loss:0.0035509843682251744\n",
      "train loss:0.0061447995889043535\n",
      "train loss:0.0031304978050494536\n",
      "train loss:0.038018404331675616\n",
      "train loss:0.014415808592210793\n",
      "train loss:0.01551413517738058\n",
      "train loss:0.006388599966686543\n",
      "train loss:0.005906818381797377\n",
      "train loss:0.0019518889653792782\n",
      "train loss:0.08419737626544649\n",
      "train loss:0.03064036625866771\n",
      "train loss:0.007513926157670795\n",
      "train loss:0.024742626290125296\n",
      "train loss:0.0038696824284374675\n",
      "train loss:0.020008074561248198\n",
      "train loss:0.003318815297325686\n",
      "train loss:0.008767150305442147\n",
      "train loss:0.0037327703988355933\n",
      "train loss:0.009960978223382249\n",
      "train loss:0.011504705011010967\n",
      "train loss:0.014304877071802486\n",
      "train loss:0.013529981285224013\n",
      "train loss:0.0033698720453074742\n",
      "train loss:0.0064850373760693605\n",
      "train loss:0.0034360107232601182\n",
      "=== epoch:9, train acc:0.992, test acc:0.983 ===\n",
      "train loss:0.02861838466923141\n",
      "train loss:0.008281305182614947\n",
      "train loss:0.017686471407386918\n",
      "train loss:0.007157748629497347\n",
      "train loss:0.00707345505080545\n",
      "train loss:0.010336287960696635\n",
      "train loss:0.02902549055735291\n",
      "train loss:0.003484340415570005\n",
      "train loss:0.009387156353533837\n",
      "train loss:0.06003859224080666\n",
      "train loss:0.005244322292629334\n",
      "train loss:0.007811168604302688\n",
      "train loss:0.019384561036910924\n",
      "train loss:0.007647014728900673\n",
      "train loss:0.0271703475023537\n",
      "train loss:0.00962512003984282\n",
      "train loss:0.03431153414384205\n",
      "train loss:0.015874176074105812\n",
      "train loss:0.02197288963966789\n",
      "train loss:0.012963826046631903\n",
      "train loss:0.0019874181639877764\n",
      "train loss:0.008550447068971451\n",
      "train loss:0.0023078941299080466\n",
      "train loss:0.00178842139123747\n",
      "train loss:0.005421948163057132\n",
      "train loss:0.02698325821799647\n",
      "train loss:0.022983212306202035\n",
      "train loss:0.009492962803060312\n",
      "train loss:0.0027381463167635324\n",
      "train loss:0.005973994272684405\n",
      "train loss:0.003647594931887758\n",
      "train loss:0.00398731931168792\n",
      "train loss:0.006442432316796943\n",
      "train loss:0.016769354568707137\n",
      "train loss:0.006011830802205479\n",
      "train loss:0.0020407575759850954\n",
      "train loss:0.010866630307885802\n",
      "train loss:0.009408913742858212\n",
      "train loss:0.00628481768991462\n",
      "train loss:0.004427285285465169\n",
      "train loss:0.0011956269743634619\n",
      "train loss:0.004419730858859064\n",
      "train loss:0.002847293461077578\n",
      "train loss:0.007985949149892015\n",
      "train loss:0.07896548744025467\n",
      "train loss:0.007737943976347412\n",
      "train loss:0.007155443713694939\n",
      "train loss:0.004453244106350768\n",
      "train loss:0.022945245162458057\n",
      "train loss:0.0059967387827870935\n",
      "train loss:0.008077533762877166\n",
      "train loss:0.007427892389164703\n",
      "train loss:0.004206403160990825\n",
      "train loss:0.03644093552438532\n",
      "train loss:0.010761829408745434\n",
      "train loss:0.001768718317584858\n",
      "train loss:0.006742607928081698\n",
      "train loss:0.006849378631985176\n",
      "train loss:0.015098290796653806\n",
      "train loss:0.006464553864564019\n",
      "train loss:0.01167806427248757\n",
      "train loss:0.03015458371562585\n",
      "train loss:0.01732199346332429\n",
      "train loss:0.03453506672077913\n",
      "train loss:0.007335393219438214\n",
      "train loss:0.03296776014066166\n",
      "train loss:0.0035006848545479597\n",
      "train loss:0.01582398389739423\n",
      "train loss:0.008889696603255521\n",
      "train loss:0.004286138623309227\n",
      "train loss:0.024077775111628442\n",
      "train loss:0.07679301342158426\n",
      "train loss:0.005453766153338505\n",
      "train loss:0.013141364074895134\n",
      "train loss:0.0032705628901689376\n",
      "train loss:0.011748112985703031\n",
      "train loss:0.0789255922641969\n",
      "train loss:0.0015757796986402624\n",
      "train loss:0.028007001154942417\n",
      "train loss:0.0026457299764538443\n",
      "train loss:0.010514794885452655\n",
      "train loss:0.008874703974226359\n",
      "train loss:0.017551074554942554\n",
      "train loss:0.0024705030098602946\n",
      "train loss:0.011851434356747346\n",
      "train loss:0.0004702365813041211\n",
      "train loss:0.0015594585193048174\n",
      "train loss:0.006114251065864974\n",
      "train loss:0.0038620013971450862\n",
      "train loss:0.004225054159086456\n",
      "train loss:0.014236227023740129\n",
      "train loss:0.010474167233410929\n",
      "train loss:0.010760462895485068\n",
      "train loss:0.011991700414630442\n",
      "train loss:0.0027638833600461717\n",
      "train loss:0.013554801725640098\n",
      "train loss:0.0023499838230985524\n",
      "train loss:0.02470180873427175\n",
      "train loss:0.005044840397939566\n",
      "train loss:0.013191788769695418\n",
      "train loss:0.0027914770285203828\n",
      "train loss:0.003062934607881172\n",
      "train loss:0.006971641455869265\n",
      "train loss:0.014080778137446364\n",
      "train loss:0.017273963859192533\n",
      "train loss:0.006494703648107484\n",
      "train loss:0.005400582361482438\n",
      "train loss:0.009013898361401264\n",
      "train loss:0.004378418841217218\n",
      "train loss:0.006538829263929994\n",
      "train loss:0.015329996542884305\n",
      "train loss:0.019551762927489162\n",
      "train loss:0.024598457050103533\n",
      "train loss:0.00849096638995261\n",
      "train loss:0.010318456574562847\n",
      "train loss:0.02142804872727878\n",
      "train loss:0.010876336953177215\n",
      "train loss:0.007920935498383973\n",
      "train loss:0.0034256124568343323\n",
      "train loss:0.013285698152424417\n",
      "train loss:0.027227549225778098\n",
      "train loss:0.0067378442472906044\n",
      "train loss:0.020050388854549846\n",
      "train loss:0.026232186706432317\n",
      "train loss:0.008897949255126256\n",
      "train loss:0.027040006346017297\n",
      "train loss:0.018489285431341804\n",
      "train loss:0.003899245111609016\n",
      "train loss:0.001306440015067336\n",
      "train loss:0.004296504830232028\n",
      "train loss:0.009118637997542195\n",
      "train loss:0.0028693869242231245\n",
      "train loss:0.043553424349730994\n",
      "train loss:0.03475398962625\n",
      "train loss:0.010856616486775352\n",
      "train loss:0.007605861088013664\n",
      "train loss:0.0021974389289362876\n",
      "train loss:0.00845007174427263\n",
      "train loss:0.006078227862619702\n",
      "train loss:0.0049461760260919915\n",
      "train loss:0.004706020062296092\n",
      "train loss:0.014242765750808713\n",
      "train loss:0.013072100356614014\n",
      "train loss:0.031357498895230845\n",
      "train loss:0.011935369756469425\n",
      "train loss:0.0011388085108950602\n",
      "train loss:0.0012612847514251399\n",
      "train loss:0.023979851923112222\n",
      "train loss:0.002879720113726524\n",
      "train loss:0.00795979053026299\n",
      "train loss:0.0058947020722553535\n",
      "train loss:0.008074928946850905\n",
      "train loss:0.008254276481049316\n",
      "train loss:0.032640978995177525\n",
      "train loss:0.007025129453961333\n",
      "train loss:0.0017331088182057273\n",
      "train loss:0.025283514288702905\n",
      "train loss:0.005124561809143711\n",
      "train loss:0.04604992585484371\n",
      "train loss:0.01567880234432953\n",
      "train loss:0.012745963736458943\n",
      "train loss:0.011286829629394311\n",
      "train loss:0.0014753351421881594\n",
      "train loss:0.007565660563672884\n",
      "train loss:0.01514645009766338\n",
      "train loss:0.021496434278096426\n",
      "train loss:0.020033046234198687\n",
      "train loss:0.0030794614034900785\n",
      "train loss:0.007070269663876558\n",
      "train loss:0.010601913258187823\n",
      "train loss:0.0015787306489836042\n",
      "train loss:0.005837056385071823\n",
      "train loss:0.0010061780445449519\n",
      "train loss:0.0032924103296784273\n",
      "train loss:0.008885645852767191\n",
      "train loss:0.017243628073909553\n",
      "train loss:0.02958897556880061\n",
      "train loss:0.06440698232601268\n",
      "train loss:0.01577601304090184\n",
      "train loss:0.01211471386121977\n",
      "train loss:0.0014311013730004929\n",
      "train loss:0.005034182670044001\n",
      "train loss:0.030295044780085444\n",
      "train loss:0.02931278490496541\n",
      "train loss:0.034618964624360225\n",
      "train loss:0.003425694730292912\n",
      "train loss:0.006209520353788099\n",
      "train loss:0.008542612081847919\n",
      "train loss:0.0023192869585083515\n",
      "train loss:0.006462862173076198\n",
      "train loss:0.021134332499446417\n",
      "train loss:0.008970618513773615\n",
      "train loss:0.014258003157324879\n",
      "train loss:0.09788035151872546\n",
      "train loss:0.0032427701790719936\n",
      "train loss:0.0023976134097337494\n",
      "train loss:0.040165269972436066\n",
      "train loss:0.011587602301378954\n",
      "train loss:0.004088692498771352\n",
      "train loss:0.009501559035353144\n",
      "train loss:0.03166057658049737\n",
      "train loss:0.0072837795061936285\n",
      "train loss:0.008669237422866568\n",
      "train loss:0.005890064934633185\n",
      "train loss:0.0020051874152946045\n",
      "train loss:0.01787873420509332\n",
      "train loss:0.004927190346083023\n",
      "train loss:0.030706451028075708\n",
      "train loss:0.008523532678609063\n",
      "train loss:0.028384605782507726\n",
      "train loss:0.008188566061085789\n",
      "train loss:0.0007004728161912839\n",
      "train loss:0.0017134875346171386\n",
      "train loss:0.002488013147214646\n",
      "train loss:0.005154231036633641\n",
      "train loss:0.023568494261244837\n",
      "train loss:0.011137472000149404\n",
      "train loss:0.025842060129596\n",
      "train loss:0.0018347747107614223\n",
      "train loss:0.014299255151275295\n",
      "train loss:0.0016812951727279307\n",
      "train loss:0.013439462079290403\n",
      "train loss:0.008865407284950007\n",
      "train loss:0.010776844532057414\n",
      "train loss:0.04887988013835282\n",
      "train loss:0.0021182642698753472\n",
      "train loss:0.0011662317905926215\n",
      "train loss:0.003932306718783741\n",
      "train loss:0.002454965711386108\n",
      "train loss:0.01186956876951901\n",
      "train loss:0.01670370556356703\n",
      "train loss:0.015102308269850125\n",
      "train loss:0.008435186752512678\n",
      "train loss:0.0027291335430179443\n",
      "train loss:0.0025396608309894574\n",
      "train loss:0.021374240308560385\n",
      "train loss:0.01994586619778941\n",
      "train loss:0.011528354446918316\n",
      "train loss:0.007768485346758825\n",
      "train loss:0.00407620684552209\n",
      "train loss:0.012094378795419174\n",
      "train loss:0.0024511338696033666\n",
      "train loss:0.006337643565925842\n",
      "train loss:0.0024578550436576046\n",
      "train loss:0.035325607965804535\n",
      "train loss:0.007394578677734884\n",
      "train loss:0.0039204943913139995\n",
      "train loss:0.006131750368863685\n",
      "train loss:0.014954299912740516\n",
      "train loss:0.021983298987431007\n",
      "train loss:0.011227714400340403\n",
      "train loss:0.012519651753120989\n",
      "train loss:0.008645244156319327\n",
      "train loss:0.003530023596637621\n",
      "train loss:0.005520561902147298\n",
      "train loss:0.003294949790553462\n",
      "train loss:0.0028318334698124166\n",
      "train loss:0.0013701802100252848\n",
      "train loss:0.016498828612056645\n",
      "train loss:0.00692091557861723\n",
      "train loss:0.004592653904954841\n",
      "train loss:0.009706080213340103\n",
      "train loss:0.0030337599755910715\n",
      "train loss:0.008257028743441058\n",
      "train loss:0.007433514981218117\n",
      "train loss:0.0015370965234315099\n",
      "train loss:0.00934927447143829\n",
      "train loss:0.00136313804566289\n",
      "train loss:0.012025764659835368\n",
      "train loss:0.0019085186579059735\n",
      "train loss:0.008487107755915576\n",
      "train loss:0.0012546388656938933\n",
      "train loss:0.0029487720236099717\n",
      "train loss:0.03242001603107929\n",
      "train loss:0.00840230614003755\n",
      "train loss:0.06994982356626236\n",
      "train loss:0.009155373325198253\n",
      "train loss:0.006418720404870139\n",
      "train loss:0.011792328970292929\n",
      "train loss:0.0023314806563905204\n",
      "train loss:0.002362493258380994\n",
      "train loss:0.016756556163036205\n",
      "train loss:0.0020626462601766034\n",
      "train loss:0.000990001357947853\n",
      "train loss:0.003271361631776211\n",
      "train loss:0.004311817409294494\n",
      "train loss:0.01862999381404059\n",
      "train loss:0.005500731842632162\n",
      "train loss:0.003501991268893935\n",
      "train loss:0.005270607666695134\n",
      "train loss:0.053966738464877935\n",
      "train loss:0.0046877483836323865\n",
      "train loss:0.014990153293749444\n",
      "train loss:0.005006503269972373\n",
      "train loss:0.006693477203744698\n",
      "train loss:0.008617530626299597\n",
      "train loss:0.058429358879927944\n",
      "train loss:0.007020098564821774\n",
      "train loss:0.03388811672289229\n",
      "train loss:0.0013911640145867587\n",
      "train loss:0.0020286872988256755\n",
      "train loss:0.03171336980839839\n",
      "train loss:0.012916288479358575\n",
      "train loss:0.01248598564737216\n",
      "train loss:0.032542895725445414\n",
      "train loss:0.0025035884458848344\n",
      "train loss:0.002033170221762911\n",
      "train loss:0.008345303044147899\n",
      "train loss:0.005506996094261651\n",
      "train loss:0.006301646478042877\n",
      "train loss:0.0023305301018748436\n",
      "train loss:0.005572782864787047\n",
      "train loss:0.0063483830688844615\n",
      "train loss:0.01607488915683882\n",
      "train loss:0.02934402404955965\n",
      "train loss:0.006148134238654863\n",
      "train loss:0.01800151909252302\n",
      "train loss:0.005158656495632036\n",
      "train loss:0.017277905736549155\n",
      "train loss:0.021599193087508444\n",
      "train loss:0.0051217889505901695\n",
      "train loss:0.030858173696773496\n",
      "train loss:0.0015519999704855575\n",
      "train loss:0.01679213676521648\n",
      "train loss:0.0044868679657123255\n",
      "train loss:0.01917386668794706\n",
      "train loss:0.018602162752003253\n",
      "train loss:0.008763413659353373\n",
      "train loss:0.008087131296705359\n",
      "train loss:0.005453782894221634\n",
      "train loss:0.004026251772852468\n",
      "train loss:0.002134200282320114\n",
      "train loss:0.021419729401340987\n",
      "train loss:0.04107868414838038\n",
      "train loss:0.012417161015106332\n",
      "train loss:0.002989701373108892\n",
      "train loss:0.0056505954813977155\n",
      "train loss:0.002907873339050283\n",
      "train loss:0.005184285800626063\n",
      "train loss:0.018581680670671518\n",
      "train loss:0.006283008346638832\n",
      "train loss:0.0016810895037296838\n",
      "train loss:0.004198942835097395\n",
      "train loss:0.011312081649299713\n",
      "train loss:0.007442896811705018\n",
      "train loss:0.005665040595685217\n",
      "train loss:0.003014855309955209\n",
      "train loss:0.0009485941530336764\n",
      "train loss:0.004904266407386076\n",
      "train loss:0.002391329393568942\n",
      "train loss:0.0031094506299513902\n",
      "train loss:0.007120288526000182\n",
      "train loss:0.0053862924764437525\n",
      "train loss:0.004170355770798964\n",
      "train loss:0.0017124944850533525\n",
      "train loss:0.020904805723983778\n",
      "train loss:0.005160233738075701\n",
      "train loss:0.004250221483520629\n",
      "train loss:0.020800076428641016\n",
      "train loss:0.010995311832272269\n",
      "train loss:0.0112924382572827\n",
      "train loss:0.005784910411339784\n",
      "train loss:0.004172545842346756\n",
      "train loss:0.006836402491928299\n",
      "train loss:0.009896617227441206\n",
      "train loss:0.004289339807558102\n",
      "train loss:0.002345803249244025\n",
      "train loss:0.013749522568995571\n",
      "train loss:0.008780028648157932\n",
      "train loss:0.030317411491640227\n",
      "train loss:0.053645609898756774\n",
      "train loss:0.009195187457150547\n",
      "train loss:0.002274828761046509\n",
      "train loss:0.0009660508034468625\n",
      "train loss:0.006007662327445196\n",
      "train loss:0.00942494898912644\n",
      "train loss:0.0059771984431419125\n",
      "train loss:0.002592814443718609\n",
      "train loss:0.014678237273342287\n",
      "train loss:0.003039954022594098\n",
      "train loss:0.01570189661832798\n",
      "train loss:0.006440885687629922\n",
      "train loss:0.008401553155708109\n",
      "train loss:0.001275861153191908\n",
      "train loss:0.00837620416914858\n",
      "train loss:0.005621059478591242\n",
      "train loss:0.011287025667863269\n",
      "train loss:0.006930876896887359\n",
      "train loss:0.0027314046755528964\n",
      "train loss:0.00446445136841142\n",
      "train loss:0.011647819403831916\n",
      "train loss:0.008072545096157405\n",
      "train loss:0.004258838369856898\n",
      "train loss:0.004403290203722272\n",
      "train loss:0.00157196297907371\n",
      "train loss:0.002784903177200718\n",
      "train loss:0.00977916826538725\n",
      "train loss:0.0027033354313575264\n",
      "train loss:0.004000775117137045\n",
      "train loss:0.0038207006458771987\n",
      "train loss:0.005340951204317485\n",
      "train loss:0.007677599362126486\n",
      "train loss:0.031814898122090235\n",
      "train loss:0.011941788791000248\n",
      "train loss:0.033070393063242914\n",
      "train loss:0.016079299117289336\n",
      "train loss:0.002918221153658143\n",
      "train loss:0.01590951653736814\n",
      "train loss:0.002121043302064676\n",
      "train loss:0.002755644817270883\n",
      "train loss:0.006498938741437327\n",
      "train loss:0.004250873008347653\n",
      "train loss:0.028653167100483965\n",
      "train loss:0.003930281501305767\n",
      "train loss:0.004327594152365455\n",
      "train loss:0.006344796673197233\n",
      "train loss:0.01966209359877777\n",
      "train loss:0.023582854533956053\n",
      "train loss:0.00528317311051196\n",
      "train loss:0.004448162917985716\n",
      "train loss:0.0036059719012634123\n",
      "train loss:0.011784930218298306\n",
      "train loss:0.004342290859724755\n",
      "train loss:0.004214366941925399\n",
      "train loss:0.0006848608963064961\n",
      "train loss:0.0016301259928038414\n",
      "train loss:0.004279108674000315\n",
      "train loss:0.01200383607492388\n",
      "train loss:0.04269906012045164\n",
      "train loss:0.018800935592446368\n",
      "train loss:0.0050943979300491745\n",
      "train loss:0.0028043795879681725\n",
      "train loss:0.011049236487185327\n",
      "train loss:0.002051497808929097\n",
      "train loss:0.011273367417998776\n",
      "train loss:0.0011335420376874226\n",
      "train loss:0.019942105049831526\n",
      "train loss:0.007336465288069851\n",
      "train loss:0.0064749958223993265\n",
      "train loss:0.018625788890346186\n",
      "train loss:0.014864945194895405\n",
      "train loss:0.0017325548682169457\n",
      "train loss:0.014232386060112035\n",
      "train loss:0.001660441537888287\n",
      "train loss:0.012456415795036717\n",
      "train loss:0.0256036040509871\n",
      "train loss:0.0025509684463090963\n",
      "train loss:0.008029971738589022\n",
      "train loss:0.013374876238894164\n",
      "train loss:0.0014463249090895655\n",
      "train loss:0.006344748602299555\n",
      "train loss:0.0033563930240977503\n",
      "train loss:0.0038889821076471616\n",
      "train loss:0.0014249101304870018\n",
      "train loss:0.0013243174712641054\n",
      "train loss:0.026045388022718937\n",
      "train loss:0.0020219567537386966\n",
      "train loss:0.01063384236187797\n",
      "train loss:0.005499616554007825\n",
      "train loss:0.000624873175238782\n",
      "train loss:0.004384157310343432\n",
      "train loss:0.018891898386981253\n",
      "train loss:0.011092251673921154\n",
      "train loss:0.003273277049080733\n",
      "train loss:0.004972632450447555\n",
      "train loss:0.02647451528701393\n",
      "train loss:0.003966446726364504\n",
      "train loss:0.00036291184086825864\n",
      "train loss:0.003650387326291997\n",
      "train loss:0.005391202649540555\n",
      "train loss:0.0012156454850380844\n",
      "train loss:0.00351490547028185\n",
      "train loss:0.0007185774683609407\n",
      "train loss:0.004030719696673308\n",
      "train loss:0.0006633058581512884\n",
      "train loss:0.004575021710980252\n",
      "train loss:0.012638312531820699\n",
      "train loss:0.0011536234689216909\n",
      "train loss:0.003019459712226211\n",
      "train loss:0.0014393592301197857\n",
      "train loss:0.006718686566506818\n",
      "train loss:0.005865782908480893\n",
      "train loss:0.0018191101245845765\n",
      "train loss:0.004740635498972601\n",
      "train loss:0.006609411159118402\n",
      "train loss:0.0008337871907454483\n",
      "train loss:0.006301255852031566\n",
      "train loss:0.014744943181417726\n",
      "train loss:0.0046760731482638875\n",
      "train loss:0.03661095526781898\n",
      "train loss:0.006304892836505581\n",
      "train loss:0.0022370133004643703\n",
      "train loss:0.0020735310314624316\n",
      "train loss:0.00435643455364276\n",
      "train loss:0.0023945788531471958\n",
      "train loss:0.030069031335137678\n",
      "train loss:0.001083467083371034\n",
      "train loss:0.003162206129755413\n",
      "train loss:0.003790408535076336\n",
      "train loss:0.007078975094683674\n",
      "train loss:0.0006942905007678545\n",
      "train loss:0.018282648354302936\n",
      "train loss:0.002353309188983763\n",
      "train loss:0.0034012913795185328\n",
      "train loss:0.0030717211923794764\n",
      "train loss:0.016728383255007948\n",
      "train loss:0.005351695027485447\n",
      "train loss:0.0061638307922019945\n",
      "train loss:0.0665074563424605\n",
      "train loss:0.004947502667901735\n",
      "train loss:0.004387565129788002\n",
      "train loss:0.009096118514774444\n",
      "train loss:0.01833942189010944\n",
      "train loss:0.14476778130471776\n",
      "train loss:0.004013860758821986\n",
      "train loss:0.00486029986915563\n",
      "train loss:0.003144603784765907\n",
      "train loss:0.0014749654251852062\n",
      "train loss:0.002663547701484902\n",
      "train loss:0.016163705585904117\n",
      "train loss:0.008792122580391904\n",
      "train loss:0.0016372285269239336\n",
      "train loss:0.00782035402753763\n",
      "train loss:0.008820598412014585\n",
      "train loss:0.005532499015751291\n",
      "train loss:0.001638563152942149\n",
      "train loss:0.006167162509988812\n",
      "train loss:0.0033191975013325144\n",
      "train loss:0.006954797708642265\n",
      "train loss:0.04290106870023414\n",
      "train loss:0.0031480224797428387\n",
      "train loss:0.006364014167638354\n",
      "train loss:0.007948156933711025\n",
      "train loss:0.01336395292503468\n",
      "train loss:0.005086973549488017\n",
      "train loss:0.013259684869461464\n",
      "train loss:0.0020607008289993626\n",
      "train loss:0.004408678520289608\n",
      "train loss:0.0025357677845390552\n",
      "train loss:0.0011017062011521974\n",
      "train loss:0.010541883537978039\n",
      "train loss:0.0010104301626469182\n",
      "train loss:0.010101743223548535\n",
      "train loss:0.0022652647796005242\n",
      "train loss:0.04316746001306982\n",
      "train loss:0.005983804850682831\n",
      "train loss:0.002499862744566719\n",
      "train loss:0.006523582056271891\n",
      "train loss:0.006536764495176921\n",
      "train loss:0.015374906402408812\n",
      "train loss:0.004228624735684908\n",
      "train loss:0.0007254029965885273\n",
      "train loss:0.0036766997681735715\n",
      "train loss:0.005882989396676763\n",
      "train loss:0.0035220672421443244\n",
      "train loss:0.011805211453637743\n",
      "train loss:0.012154860129310446\n",
      "train loss:0.0038463345184354325\n",
      "train loss:0.0023075881204997315\n",
      "train loss:0.026153750698073654\n",
      "train loss:0.0032509637988553074\n",
      "train loss:0.007682649953551726\n",
      "train loss:0.0442000483771763\n",
      "train loss:0.005339763033551106\n",
      "train loss:0.00238284161667741\n",
      "train loss:0.005910298044049082\n",
      "train loss:0.004298818172330468\n",
      "train loss:0.008149357695997459\n",
      "train loss:0.003518896219342057\n",
      "train loss:0.02591258660902668\n",
      "train loss:0.023324599675217775\n",
      "train loss:0.003254964486578862\n",
      "train loss:0.008141455289401306\n",
      "train loss:0.0017545289732516201\n",
      "train loss:0.014861308848590908\n",
      "train loss:0.006256769214425735\n",
      "train loss:0.003818070078099932\n",
      "train loss:0.015035442587496846\n",
      "train loss:0.005029650429788698\n",
      "train loss:0.002950113894170775\n",
      "train loss:0.017753157140511504\n",
      "train loss:0.009995246523191418\n",
      "train loss:0.0339927816052\n",
      "train loss:0.002466378170680304\n",
      "train loss:0.004644734900539768\n",
      "train loss:0.001999423013946164\n",
      "train loss:0.08101932211206318\n",
      "train loss:0.004104328124699657\n",
      "train loss:0.008614470596664288\n",
      "train loss:0.0015791239851240385\n",
      "train loss:0.0056002514871303175\n",
      "train loss:0.00391098333716885\n",
      "train loss:0.0017408958700146965\n",
      "train loss:0.01149655992027342\n",
      "train loss:0.010856570071000812\n",
      "train loss:0.0014527183933104699\n",
      "train loss:0.024935676632813278\n",
      "train loss:0.0037379227623407117\n",
      "train loss:0.021661088822371947\n",
      "train loss:0.0036841056434148\n",
      "=== epoch:10, train acc:0.993, test acc:0.99 ===\n",
      "train loss:0.005252096473052528\n",
      "train loss:0.0010840026954291942\n",
      "train loss:0.0006548968899983207\n",
      "train loss:0.02087332277561925\n",
      "train loss:0.016319167633116444\n",
      "train loss:0.005615723748437058\n",
      "train loss:0.0026691458149163427\n",
      "train loss:0.007979204063479814\n",
      "train loss:0.004923339290624266\n",
      "train loss:0.003950874715650765\n",
      "train loss:0.013380630381644054\n",
      "train loss:0.007374606795775528\n",
      "train loss:0.00723679862187008\n",
      "train loss:0.0028453456711994853\n",
      "train loss:0.009046810308389604\n",
      "train loss:0.030536190906042912\n",
      "train loss:0.005768880119588752\n",
      "train loss:0.00450012853357252\n",
      "train loss:0.0028176781567436876\n",
      "train loss:0.004182945895431383\n",
      "train loss:0.07204794354932666\n",
      "train loss:0.010655431792384071\n",
      "train loss:0.00370357858832981\n",
      "train loss:0.005284291381431677\n",
      "train loss:0.0008221615888381516\n",
      "train loss:0.009368897420048145\n",
      "train loss:0.003183397909408045\n",
      "train loss:0.08257293779754576\n",
      "train loss:0.005386587230493634\n",
      "train loss:0.037219842098974304\n",
      "train loss:0.007388784618056421\n",
      "train loss:0.010183964491818917\n",
      "train loss:0.005364506107702049\n",
      "train loss:0.010160716649566652\n",
      "train loss:0.003827119931937097\n",
      "train loss:0.007693319310728527\n",
      "train loss:0.007715296499244429\n",
      "train loss:0.0018981887417087412\n",
      "train loss:0.002105792899635592\n",
      "train loss:0.009135130543574262\n",
      "train loss:0.005828477817629966\n",
      "train loss:0.0014817945331302102\n",
      "train loss:0.005657157584341152\n",
      "train loss:0.000421020952440047\n",
      "train loss:0.0005353373209634874\n",
      "train loss:0.016140837178069443\n",
      "train loss:0.00291840983532443\n",
      "train loss:0.006896546182610109\n",
      "train loss:0.001023967811382134\n",
      "train loss:0.004335943743678765\n",
      "train loss:0.0002767919736142639\n",
      "train loss:0.016921967842931804\n",
      "train loss:0.00417322987580159\n",
      "train loss:0.010062516705316044\n",
      "train loss:0.0042656485786478635\n",
      "train loss:0.0008858743393218446\n",
      "train loss:0.01305606264929659\n",
      "train loss:0.008692468581938544\n",
      "train loss:0.0015661811825275652\n",
      "train loss:0.0028766718989737317\n",
      "train loss:0.0022960067918399015\n",
      "train loss:0.004722608187351872\n",
      "train loss:0.002780866384471026\n",
      "train loss:0.0009416906632077591\n",
      "train loss:0.011372763886922628\n",
      "train loss:0.014958387314758705\n",
      "train loss:0.0038800125105704574\n",
      "train loss:0.01720866444630617\n",
      "train loss:0.002080614700222843\n",
      "train loss:0.0055300968604566425\n",
      "train loss:0.002917460214547652\n",
      "train loss:0.0017362838891924616\n",
      "train loss:0.0198496626363691\n",
      "train loss:0.020446616676553123\n",
      "train loss:0.004237558657439596\n",
      "train loss:0.0018226155199649846\n",
      "train loss:0.012960409174046521\n",
      "train loss:0.003012870640878122\n",
      "train loss:0.004724123237199518\n",
      "train loss:0.0035444406494732654\n",
      "train loss:0.0046807956961181525\n",
      "train loss:0.0250724859172283\n",
      "train loss:0.004093681976295313\n",
      "train loss:0.0011501722436595794\n",
      "train loss:0.0038720089956718285\n",
      "train loss:0.018293509254405413\n",
      "train loss:0.005684813384408214\n",
      "train loss:0.007146673533070852\n",
      "train loss:0.006617454615711553\n",
      "train loss:0.003134561591065395\n",
      "train loss:0.06008366205909845\n",
      "train loss:0.09277239338258197\n",
      "train loss:0.0013288715749868265\n",
      "train loss:0.006321252203167406\n",
      "train loss:0.003066395865145352\n",
      "train loss:0.002309766990689467\n",
      "train loss:0.0019330519443648316\n",
      "train loss:0.020018122282811208\n",
      "train loss:0.0036642106782766616\n",
      "train loss:0.0027125612789386565\n",
      "train loss:0.001695860635068525\n",
      "train loss:0.0031277444107155887\n",
      "train loss:0.0010337135066432646\n",
      "train loss:0.02165031686232902\n",
      "train loss:0.0034566411557209113\n",
      "train loss:0.004345387259907499\n",
      "train loss:0.002689418107927319\n",
      "train loss:0.0016730169294046679\n",
      "train loss:0.0012211658792520323\n",
      "train loss:0.004854742526685333\n",
      "train loss:0.00974269913460828\n",
      "train loss:0.00837985290592997\n",
      "train loss:0.0004346335114834303\n",
      "train loss:0.0050908636094820015\n",
      "train loss:0.002941745957768963\n",
      "train loss:0.009144532590036999\n",
      "train loss:0.001149783367498434\n",
      "train loss:0.0007287063724398017\n",
      "train loss:0.004256199106692958\n",
      "train loss:0.004041004704851058\n",
      "train loss:0.006901855692003997\n",
      "train loss:0.0013704190861479387\n",
      "train loss:0.00029503263263613324\n",
      "train loss:0.031391227421087006\n",
      "train loss:0.004246582449402684\n",
      "train loss:0.00586213770179261\n",
      "train loss:0.002277249207731988\n",
      "train loss:0.00440860639275618\n",
      "train loss:0.010432427755391258\n",
      "train loss:0.0018627632626721333\n",
      "train loss:0.005488381261888982\n",
      "train loss:0.0021847669825575573\n",
      "train loss:0.008642555030609676\n",
      "train loss:0.00815545921071026\n",
      "train loss:0.006535348102815033\n",
      "train loss:0.01750353723069901\n",
      "train loss:0.0034279708801625204\n",
      "train loss:0.0012344639763433676\n",
      "train loss:0.01035488590202457\n",
      "train loss:0.004578901046903417\n",
      "train loss:0.013964805497468664\n",
      "train loss:0.0054378341234903715\n",
      "train loss:0.016527205547441283\n",
      "train loss:0.003739381030546036\n",
      "train loss:0.0030527118897924117\n",
      "train loss:0.0010183100209470036\n",
      "train loss:0.02029548130419913\n",
      "train loss:0.0053003718825894485\n",
      "train loss:0.007368236684906989\n",
      "train loss:0.01741614036132673\n",
      "train loss:0.013799072063752733\n",
      "train loss:0.0030808969688687123\n",
      "train loss:0.0039451471275764385\n",
      "train loss:0.012074289644767438\n",
      "train loss:0.0037077023122884596\n",
      "train loss:0.0007582001408357354\n",
      "train loss:0.01757968269771018\n",
      "train loss:0.025003168998327087\n",
      "train loss:0.0038729005917198635\n",
      "train loss:0.02088051907002554\n",
      "train loss:0.0032994577831471673\n",
      "train loss:0.008752788151645523\n",
      "train loss:0.001970834628107805\n",
      "train loss:0.013956965194011888\n",
      "train loss:0.00913549219491865\n",
      "train loss:0.006385622717626546\n",
      "train loss:0.0008023894336865638\n",
      "train loss:0.0023315321291663953\n",
      "train loss:0.019043841848074103\n",
      "train loss:0.0016602385769412184\n",
      "train loss:0.005325339535359458\n",
      "train loss:0.006765097573707036\n",
      "train loss:0.008052072284105729\n",
      "train loss:0.0025263026891914455\n",
      "train loss:0.00365583725487263\n",
      "train loss:0.006591995793797652\n",
      "train loss:0.01498673443399629\n",
      "train loss:0.008528681538505686\n",
      "train loss:0.003080213088359205\n",
      "train loss:0.0032657566384074323\n",
      "train loss:0.013816296633562337\n",
      "train loss:0.003981259311154689\n",
      "train loss:0.0034287747703721366\n",
      "train loss:0.006368823906259211\n",
      "train loss:0.0024150468013589867\n",
      "train loss:0.0006733390240588907\n",
      "train loss:0.009226652431245163\n",
      "train loss:0.004198355333248312\n",
      "train loss:0.003095704158643584\n",
      "train loss:0.004995031340451444\n",
      "train loss:0.002051552124230108\n",
      "train loss:0.004260558403694568\n",
      "train loss:0.0028731395654898197\n",
      "train loss:0.0038977302486111927\n",
      "train loss:0.027111437516110937\n",
      "train loss:0.005136986463869302\n",
      "train loss:0.000949476570219687\n",
      "train loss:0.0014451336109857368\n",
      "train loss:0.006796051600561044\n",
      "train loss:0.028658312844465274\n",
      "train loss:0.0031991285519787217\n",
      "train loss:0.003626497905611766\n",
      "train loss:0.0007191553550449559\n",
      "train loss:0.002024270024224264\n",
      "train loss:0.004865097044433902\n",
      "train loss:0.0014357592482299648\n",
      "train loss:0.01042390438542136\n",
      "train loss:0.002029570792879731\n",
      "train loss:0.010552592428427073\n",
      "train loss:0.020045794291697325\n",
      "train loss:0.007215497833946403\n",
      "train loss:0.02592893926545313\n",
      "train loss:0.018785933318649736\n",
      "train loss:0.014617427923366315\n",
      "train loss:0.002047249440679374\n",
      "train loss:0.011860568401622456\n",
      "train loss:0.00453496851412327\n",
      "train loss:0.002619466319250218\n",
      "train loss:0.006424629546130689\n",
      "train loss:0.0013939720946676898\n",
      "train loss:0.0036174568140319176\n",
      "train loss:0.0005727070725812294\n",
      "train loss:0.005240894214986742\n",
      "train loss:0.010023091889128297\n",
      "train loss:0.03393116219932339\n",
      "train loss:0.006963867366494559\n",
      "train loss:0.0040726262056544876\n",
      "train loss:0.004709981155040991\n",
      "train loss:0.013540914876581647\n",
      "train loss:0.016587583080028567\n",
      "train loss:0.0011974673742241833\n",
      "train loss:0.0011183742593156058\n",
      "train loss:0.006157758532393217\n",
      "train loss:0.03657902345104695\n",
      "train loss:0.0010902912131622268\n",
      "train loss:0.0007316822650720867\n",
      "train loss:0.0010663939630146336\n",
      "train loss:0.005484399705536899\n",
      "train loss:0.0021400452051127225\n",
      "train loss:0.0033429123446907364\n",
      "train loss:0.056321708999351766\n",
      "train loss:0.002629852726049871\n",
      "train loss:0.0003931807019665324\n",
      "train loss:0.01891454729526717\n",
      "train loss:0.004935219015889553\n",
      "train loss:0.004498470161394314\n",
      "train loss:0.01810688793423952\n",
      "train loss:0.02927107493790368\n",
      "train loss:0.004867425783846338\n",
      "train loss:0.0019496707140315263\n",
      "train loss:0.006806773011847935\n",
      "train loss:0.016003235550354374\n",
      "train loss:0.027621566443437166\n",
      "train loss:0.004322966446867933\n",
      "train loss:0.005261771427585589\n",
      "train loss:0.011691076598484925\n",
      "train loss:0.0372904364304348\n",
      "train loss:0.002070960809218059\n",
      "train loss:0.003987320814240555\n",
      "train loss:0.005728369488855738\n",
      "train loss:0.007738082911142628\n",
      "train loss:0.008509940443053941\n",
      "train loss:0.0004895679046763408\n",
      "train loss:0.01823832907339479\n",
      "train loss:0.009149766382499928\n",
      "train loss:0.008903996194232697\n",
      "train loss:0.0047102868023816205\n",
      "train loss:0.0011502794945617604\n",
      "train loss:0.003746173751402139\n",
      "train loss:0.001958222235103317\n",
      "train loss:0.004914917633617815\n",
      "train loss:0.0016343316791189403\n",
      "train loss:0.002721755288093135\n",
      "train loss:0.0019599258030284813\n",
      "train loss:0.0025675633839018007\n",
      "train loss:0.00933465408411993\n",
      "train loss:0.0005259994435711532\n",
      "train loss:0.0010115996695258442\n",
      "train loss:0.00665566263422257\n",
      "train loss:0.0030426687028054806\n",
      "train loss:0.011685522565869064\n",
      "train loss:0.0026280420078199683\n",
      "train loss:0.009134029928487154\n",
      "train loss:0.001962338479327014\n",
      "train loss:0.0023502213403530678\n",
      "train loss:0.00068130246164918\n",
      "train loss:0.026339679237527128\n",
      "train loss:0.005461741677012832\n",
      "train loss:0.0026508808762359605\n",
      "train loss:0.002120359684074621\n",
      "train loss:0.0019086360165757005\n",
      "train loss:0.007747001394437376\n",
      "train loss:0.0013771790944844722\n",
      "train loss:0.007868755173945486\n",
      "train loss:0.005164551825285998\n",
      "train loss:0.0008668950986551718\n",
      "train loss:0.04965585726444741\n",
      "train loss:0.006383610235583005\n",
      "train loss:0.004237346984219874\n",
      "train loss:0.0028914762382001176\n",
      "train loss:0.0118632118395103\n",
      "train loss:0.0021696533001832876\n",
      "train loss:0.047875008749127534\n",
      "train loss:0.00195526259543155\n",
      "train loss:0.006681263425358788\n",
      "train loss:0.010399984761529986\n",
      "train loss:0.0007133625147022059\n",
      "train loss:0.026383613862069874\n",
      "train loss:0.0024807758706151184\n",
      "train loss:0.0034138045802099264\n",
      "train loss:0.011780421521536934\n",
      "train loss:0.0011859667483753481\n",
      "train loss:0.0017554876194139717\n",
      "train loss:0.0010600858679815528\n",
      "train loss:0.0015350646648030544\n",
      "train loss:0.003554489170798606\n",
      "train loss:0.0013216146801571466\n",
      "train loss:0.0007221159644592843\n",
      "train loss:0.0219117194217246\n",
      "train loss:0.0028155470585626025\n",
      "train loss:0.007012352595836785\n",
      "train loss:0.015487823588329373\n",
      "train loss:0.011314499682962005\n",
      "train loss:0.0034376651894945194\n",
      "train loss:0.007967455182629883\n",
      "train loss:0.003889688361949465\n",
      "train loss:0.0025457065945070946\n",
      "train loss:0.04171418664801356\n",
      "train loss:0.0028663290360846166\n",
      "train loss:0.0018593904400396536\n",
      "train loss:0.0015277015238841505\n",
      "train loss:0.0024417220415910673\n",
      "train loss:0.0031445790172577003\n",
      "train loss:0.004257079818106756\n",
      "train loss:0.005236169291520844\n",
      "train loss:0.00410853153824637\n",
      "train loss:0.007811630007730757\n",
      "train loss:0.005988974596608281\n",
      "train loss:0.0074922636469443825\n",
      "train loss:0.0037809789152389805\n",
      "train loss:0.014715760920496286\n",
      "train loss:0.002939941437102405\n",
      "train loss:0.0013915288210488638\n",
      "train loss:0.008114783096253962\n",
      "train loss:0.001734772696590588\n",
      "train loss:0.001190430213358615\n",
      "train loss:0.008802322407217482\n",
      "train loss:0.0029400149612138038\n",
      "train loss:0.0018822950099153359\n",
      "train loss:0.006275496266522755\n",
      "train loss:0.00882814949448092\n",
      "train loss:0.0012279115178553874\n",
      "train loss:0.009018521830505806\n",
      "train loss:0.006110838915003528\n",
      "train loss:0.001157361215927361\n",
      "train loss:0.0023757001348590472\n",
      "train loss:0.0023008074393727563\n",
      "train loss:0.0009956629275500522\n",
      "train loss:0.011216975474885623\n",
      "train loss:0.006480801255847876\n",
      "train loss:0.006851112281229612\n",
      "train loss:0.013184795872188581\n",
      "train loss:0.005174446738730246\n",
      "train loss:0.007044446018699751\n",
      "train loss:0.003935890473774843\n",
      "train loss:0.009450748356567295\n",
      "train loss:0.001345067405366695\n",
      "train loss:0.0004368793349154082\n",
      "train loss:0.008339002174353764\n",
      "train loss:0.00425539685466147\n",
      "train loss:0.011307955874922383\n",
      "train loss:0.0011685158425929526\n",
      "train loss:0.003867089959675905\n",
      "train loss:0.01931682533989456\n",
      "train loss:0.010499791970602261\n",
      "train loss:0.008566337511560256\n",
      "train loss:0.0027072667419680697\n",
      "train loss:0.060880890420120196\n",
      "train loss:0.032313421332421086\n",
      "train loss:0.0027823437246901317\n",
      "train loss:0.005860321107859324\n",
      "train loss:0.010679579342299725\n",
      "train loss:0.002178761303904897\n",
      "train loss:0.005685277874284023\n",
      "train loss:0.005019103332532769\n",
      "train loss:0.003056489386405952\n",
      "train loss:0.0023854064446482454\n",
      "train loss:0.005223954558647671\n",
      "train loss:0.008738488950736187\n",
      "train loss:0.0026628951827229247\n",
      "train loss:0.004809281436232941\n",
      "train loss:0.003362958393362409\n",
      "train loss:0.03346420563438639\n",
      "train loss:0.001950358393280485\n",
      "train loss:0.0010598166205821003\n",
      "train loss:0.005785713060767449\n",
      "train loss:0.003921054430656753\n",
      "train loss:0.0007787577024526446\n",
      "train loss:0.0018946142738508326\n",
      "train loss:0.004007897480689967\n",
      "train loss:0.0051236982347184256\n",
      "train loss:0.03792124126200041\n",
      "train loss:0.012755466375185437\n",
      "train loss:0.010016289702291301\n",
      "train loss:0.0064963702129207605\n",
      "train loss:0.003919890803995823\n",
      "train loss:0.04258649313434803\n",
      "train loss:0.01460364164819129\n",
      "train loss:0.0006657573825631167\n",
      "train loss:0.009942626708425531\n",
      "train loss:0.0015921839931211886\n",
      "train loss:0.012868670675311632\n",
      "train loss:0.0024303542080731113\n",
      "train loss:0.014895530444520607\n",
      "train loss:0.01096132040373985\n",
      "train loss:0.0016727698131598545\n",
      "train loss:0.005037500228641353\n",
      "train loss:0.02321679661796621\n",
      "train loss:0.00418038796908646\n",
      "train loss:0.003324473494648081\n",
      "train loss:0.003639697678976626\n",
      "train loss:0.0017580566761705766\n",
      "train loss:0.007199894981397945\n",
      "train loss:0.008135679317455395\n",
      "train loss:0.031770080316198004\n",
      "train loss:0.007390385681515469\n",
      "train loss:0.020099240499402593\n",
      "train loss:0.003974427343898347\n",
      "train loss:0.006696677187101375\n",
      "train loss:0.001996025821237149\n",
      "train loss:0.004168252831077082\n",
      "train loss:0.008846477399477595\n",
      "train loss:0.001672544765766613\n",
      "train loss:0.007989469858925504\n",
      "train loss:0.0036898383907775587\n",
      "train loss:0.0009389754466779134\n",
      "train loss:0.044025003368014376\n",
      "train loss:0.006101840823650876\n",
      "train loss:0.0005741520761388415\n",
      "train loss:0.00857586571915165\n",
      "train loss:0.008412343181971378\n",
      "train loss:0.0034771105579019346\n",
      "train loss:0.013806949914448786\n",
      "train loss:0.0029047484992210924\n",
      "train loss:0.0040399860252873536\n",
      "train loss:0.004827283654379467\n",
      "train loss:0.0047678933332872975\n",
      "train loss:0.004039050794283169\n",
      "train loss:0.0025031352360989035\n",
      "train loss:0.0017373906210233659\n",
      "train loss:0.01231874699357748\n",
      "train loss:0.0030756098045740298\n",
      "train loss:0.0014887265095906118\n",
      "train loss:0.003177672192782387\n",
      "train loss:0.0022150783981465536\n",
      "train loss:0.008405701691540913\n",
      "train loss:0.002219878641510761\n",
      "train loss:0.007224061664288997\n",
      "train loss:0.003935405089673551\n",
      "train loss:0.035875101272643616\n",
      "train loss:0.017727466696563377\n",
      "train loss:0.00807613746483995\n",
      "train loss:0.006453155708438589\n",
      "train loss:0.0022212407261516832\n",
      "train loss:0.00426747166576718\n",
      "train loss:0.005537411145725647\n",
      "train loss:0.010177921627257412\n",
      "train loss:0.004719318000221046\n",
      "train loss:0.042026113150143055\n",
      "train loss:0.0003754738520368556\n",
      "train loss:0.01624411273957654\n",
      "train loss:0.002509317620753029\n",
      "train loss:0.0029900220234155626\n",
      "train loss:0.003306606110698178\n",
      "train loss:0.002171270285550127\n",
      "train loss:0.0014111195920180977\n",
      "train loss:0.015389671266639043\n",
      "train loss:0.003501877504368224\n",
      "train loss:0.012657791745284381\n",
      "train loss:0.03677442542205928\n",
      "train loss:0.006509628642661497\n",
      "train loss:0.011961739350599392\n",
      "train loss:0.002597762004600311\n",
      "train loss:0.006671380798404431\n",
      "train loss:0.0028249551166702105\n",
      "train loss:0.0021708844862137217\n",
      "train loss:0.005209681324896519\n",
      "train loss:0.008945528272274116\n",
      "train loss:0.0026516421481506736\n",
      "train loss:0.0007268243104871382\n",
      "train loss:0.033046717324377195\n",
      "train loss:0.0039843084946152895\n",
      "train loss:0.011644339913080922\n",
      "train loss:0.005643637846255498\n",
      "train loss:0.0018412079407832758\n",
      "train loss:0.0020664144966957925\n",
      "train loss:0.026740737064120133\n",
      "train loss:0.0010074426633436939\n",
      "train loss:0.002403180747177885\n",
      "train loss:0.0008265439689089956\n",
      "train loss:0.000739268666538184\n",
      "train loss:0.005063665386146498\n",
      "train loss:0.002621482548745851\n",
      "train loss:0.0008682571234505778\n",
      "train loss:0.011316096348067788\n",
      "train loss:0.010670404112944397\n",
      "train loss:0.003478070597464489\n",
      "train loss:0.013761912263053034\n",
      "train loss:0.0187361265471545\n",
      "train loss:0.00315308261458404\n",
      "train loss:0.003134123347558584\n",
      "train loss:0.0017425414090987737\n",
      "train loss:0.005550448400996719\n",
      "train loss:0.001735068905456092\n",
      "train loss:0.05524064555959282\n",
      "train loss:0.0001952508596670398\n",
      "train loss:0.0038765326041816078\n",
      "train loss:0.002179015039635504\n",
      "train loss:0.00756948628123939\n",
      "train loss:0.0017900323877549959\n",
      "train loss:0.0004955898432472602\n",
      "train loss:0.0033314346778711705\n",
      "train loss:0.0028010231958844963\n",
      "train loss:0.0039585326637779404\n",
      "train loss:0.0014558896366892548\n",
      "train loss:0.00236208439895612\n",
      "train loss:0.0017191692857254593\n",
      "train loss:0.00408836594064757\n",
      "train loss:0.005565068668133099\n",
      "train loss:0.02223452614264315\n",
      "train loss:0.022845092069491386\n",
      "train loss:0.010333938011861941\n",
      "train loss:0.0008456191007358544\n",
      "train loss:0.001968384279927071\n",
      "train loss:0.0006126058075880369\n",
      "train loss:0.010021865558457443\n",
      "train loss:0.007036642058222078\n",
      "train loss:0.0028343903150788705\n",
      "train loss:0.00488033280994172\n",
      "train loss:0.008416045855555599\n",
      "train loss:0.0059434110722745015\n",
      "train loss:0.01021905906393235\n",
      "train loss:0.004766898585664439\n",
      "train loss:0.002331936809809061\n",
      "train loss:0.0030915456125537094\n",
      "train loss:0.003520945897040765\n",
      "train loss:0.012628808327769437\n",
      "train loss:0.0054993300606481395\n",
      "train loss:0.008420913351148349\n",
      "train loss:0.0023535503124872043\n",
      "train loss:0.036725011042804984\n",
      "train loss:0.013101466539775373\n",
      "train loss:0.025053885198155535\n",
      "train loss:0.006338348760473459\n",
      "train loss:0.0028861370619887106\n",
      "train loss:0.006892548030169553\n",
      "train loss:0.0065458243401414415\n",
      "train loss:0.0558800384160053\n",
      "train loss:0.004187926933719494\n",
      "train loss:0.01421465844013186\n",
      "train loss:0.011194429096617503\n",
      "train loss:0.009120644355602097\n",
      "train loss:0.008879036945239333\n",
      "train loss:0.0027152840021248516\n",
      "train loss:0.015179712533129816\n",
      "train loss:0.019992651707176973\n",
      "train loss:0.004436683130361021\n",
      "train loss:0.011339080806204254\n",
      "train loss:0.004865177555747711\n",
      "train loss:0.0013367455917039964\n",
      "train loss:0.005666066474854038\n",
      "train loss:0.0026636014617608824\n",
      "train loss:0.0011723079724517205\n",
      "train loss:0.004771056370742515\n",
      "train loss:0.008631986602188137\n",
      "train loss:0.01163023138987456\n",
      "train loss:0.010122557376742995\n",
      "train loss:0.00709225329479239\n",
      "train loss:0.0008894336695940485\n",
      "train loss:0.004575798744739787\n",
      "train loss:0.03168386284954945\n",
      "train loss:0.008279235863252353\n",
      "train loss:0.012048278415554647\n",
      "train loss:0.04580026103456311\n",
      "train loss:0.0051620811311362145\n",
      "train loss:0.01847426397080874\n",
      "train loss:0.005790194471537247\n",
      "train loss:0.019774788646756622\n",
      "train loss:0.005904794337038428\n",
      "train loss:0.004440477957315694\n",
      "train loss:0.00224904794992394\n",
      "train loss:0.006343797457744778\n",
      "train loss:0.0024191593584127176\n",
      "train loss:0.00618882735491442\n",
      "train loss:0.011481085305872597\n",
      "train loss:0.0050489693437252596\n",
      "train loss:0.0011906751943753725\n",
      "train loss:0.002890954921317898\n",
      "train loss:0.01134372665993906\n",
      "train loss:0.003209641214141121\n",
      "=== epoch:11, train acc:0.992, test acc:0.989 ===\n",
      "train loss:0.02458724774780612\n",
      "train loss:0.01441910279620177\n",
      "train loss:0.003907478206531428\n",
      "train loss:0.0027212966191144045\n",
      "train loss:0.0010082240094672296\n",
      "train loss:0.03767287717788846\n",
      "train loss:0.00438079757292869\n",
      "train loss:0.07914310399095786\n",
      "train loss:0.0032429204070096303\n",
      "train loss:0.011545027696478232\n",
      "train loss:0.012632721371242191\n",
      "train loss:0.006196024924210285\n",
      "train loss:0.006945328100431065\n",
      "train loss:0.006546999070046086\n",
      "train loss:0.01265347641920626\n",
      "train loss:0.012343434376192307\n",
      "train loss:0.0022959417309479646\n",
      "train loss:0.0016872276290468198\n",
      "train loss:0.0068822138062050444\n",
      "train loss:0.019467399957534947\n",
      "train loss:0.009299855960359286\n",
      "train loss:0.009223850479775732\n",
      "train loss:0.001748682656177372\n",
      "train loss:0.0006671725906560942\n",
      "train loss:0.008836701759024282\n",
      "train loss:0.014220956846003673\n",
      "train loss:0.0066651171980530634\n",
      "train loss:0.011072825053205537\n",
      "train loss:0.0021690413678240716\n",
      "train loss:0.005864234375678786\n",
      "train loss:0.0018906259738454682\n",
      "train loss:0.0027401035448050125\n",
      "train loss:0.006012063088249575\n",
      "train loss:0.003307348072880244\n",
      "train loss:0.004912618121876947\n",
      "train loss:0.002428721034557291\n",
      "train loss:0.01061705803550799\n",
      "train loss:0.00046926037215923056\n",
      "train loss:0.00102984549619875\n",
      "train loss:0.0026515486428861485\n",
      "train loss:0.017203380890618503\n",
      "train loss:0.01497124790675972\n",
      "train loss:0.007760922842334842\n",
      "train loss:0.004916199030073969\n",
      "train loss:0.0005731360552812242\n",
      "train loss:0.006195283735727059\n",
      "train loss:0.010805992254441187\n",
      "train loss:0.005612328316140515\n",
      "train loss:0.0016118505416095551\n",
      "train loss:0.001616936486509843\n",
      "train loss:0.02541179061667166\n",
      "train loss:0.002214083992361225\n",
      "train loss:0.0018853915817346092\n",
      "train loss:0.005926465755889697\n",
      "train loss:0.0007960314769976877\n",
      "train loss:0.0005473916020661151\n",
      "train loss:0.004886336871280441\n",
      "train loss:0.003863791442536872\n",
      "train loss:0.012156466570525652\n",
      "train loss:0.0029008174794385995\n",
      "train loss:0.0010868691996426942\n",
      "train loss:0.0030153133009235295\n",
      "train loss:0.003699534467221563\n",
      "train loss:0.008493855085440764\n",
      "train loss:0.045188489006398935\n",
      "train loss:0.018608182469701032\n",
      "train loss:0.000888778100354877\n",
      "train loss:0.04652030072845943\n",
      "train loss:0.0010411613450178514\n",
      "train loss:0.009391892786337888\n",
      "train loss:0.01108155347446537\n",
      "train loss:0.010425187369221666\n",
      "train loss:0.009676210868777176\n",
      "train loss:0.007474057227728264\n",
      "train loss:0.002434181396770643\n",
      "train loss:0.005998574960016838\n",
      "train loss:0.007718042887251367\n",
      "train loss:0.00876646228753742\n",
      "train loss:0.0026182208058749584\n",
      "train loss:0.03258573612300995\n",
      "train loss:0.030515499622075216\n",
      "train loss:0.01072428224130948\n",
      "train loss:0.0023708333380956835\n",
      "train loss:0.0027680932574202467\n",
      "train loss:0.006564708007747564\n",
      "train loss:0.008087173230217888\n",
      "train loss:0.0004289524612451274\n",
      "train loss:0.008694473564272635\n",
      "train loss:0.0031448984965137703\n",
      "train loss:0.014081524314532802\n",
      "train loss:0.001201247100802278\n",
      "train loss:0.008655961237487894\n",
      "train loss:0.011005695525605423\n",
      "train loss:0.021984647132320477\n",
      "train loss:0.0076795056469990556\n",
      "train loss:0.0013860366940897262\n",
      "train loss:0.002610876301571163\n",
      "train loss:0.0005868070061696906\n",
      "train loss:0.00651160579382462\n",
      "train loss:0.0095514287011256\n",
      "train loss:0.006294937840245577\n",
      "train loss:0.010426391508502745\n",
      "train loss:0.0012690846428209815\n",
      "train loss:0.001867997666407189\n",
      "train loss:0.0035480615445642365\n",
      "train loss:0.00649886244793632\n",
      "train loss:0.00983547410446601\n",
      "train loss:0.0027040386095953405\n",
      "train loss:0.009242508065759852\n",
      "train loss:0.0006379165138889822\n",
      "train loss:0.003712142779596625\n",
      "train loss:0.017293379768590317\n",
      "train loss:0.034289608858098786\n",
      "train loss:0.015474092950039096\n",
      "train loss:0.006253867846254304\n",
      "train loss:0.11436199517465095\n",
      "train loss:0.01654476528030867\n",
      "train loss:0.0022368538127332514\n",
      "train loss:0.019783297826744727\n",
      "train loss:0.007443508451139994\n",
      "train loss:0.0018630721521186355\n",
      "train loss:0.0019720466670833116\n",
      "train loss:0.009186216203838188\n",
      "train loss:0.020066077827618933\n",
      "train loss:0.003967957292324198\n",
      "train loss:0.014719215915171873\n",
      "train loss:0.002402736387972896\n",
      "train loss:0.0014611567620070496\n",
      "train loss:0.002729433169516034\n",
      "train loss:0.0032391890106227505\n",
      "train loss:0.006186988973241425\n",
      "train loss:0.0025321138930559446\n",
      "train loss:0.0016029451232586467\n",
      "train loss:0.0027541762692973003\n",
      "train loss:0.006778667610281256\n",
      "train loss:0.01656965651817974\n",
      "train loss:0.0054235960539951895\n",
      "train loss:0.009093539388619681\n",
      "train loss:0.017230933912869884\n",
      "train loss:0.018498165064909537\n",
      "train loss:0.014792700332982845\n",
      "train loss:0.0069729886881232\n",
      "train loss:0.000656836269508448\n",
      "train loss:0.010230364654335666\n",
      "train loss:0.005123502178149204\n",
      "train loss:0.013342819895474263\n",
      "train loss:0.002796664895047275\n",
      "train loss:0.004392529404890537\n",
      "train loss:0.0022145300432780592\n",
      "train loss:0.021574269648559054\n",
      "train loss:0.009227772515323435\n",
      "train loss:0.001676043658762293\n",
      "train loss:0.0015747988539356627\n",
      "train loss:0.004066496526868432\n",
      "train loss:0.003131593906183559\n",
      "train loss:0.001611875613794151\n",
      "train loss:0.003467415684000184\n",
      "train loss:0.006507010730924955\n",
      "train loss:0.007080659501969081\n",
      "train loss:0.0015217243872445824\n",
      "train loss:0.011109155126880795\n",
      "train loss:0.0031336490948352287\n",
      "train loss:0.006018111904981809\n",
      "train loss:0.004850049222017643\n",
      "train loss:0.00039224336514865135\n",
      "train loss:0.01236249713258266\n",
      "train loss:0.0028127393488759926\n",
      "train loss:0.0035465828311385473\n",
      "train loss:0.016473500758369456\n",
      "train loss:0.004406547340593923\n",
      "train loss:0.002949961001745518\n",
      "train loss:0.002464806239105498\n",
      "train loss:0.0008783282429730655\n",
      "train loss:0.06821835414345614\n",
      "train loss:0.003571113398083928\n",
      "train loss:0.001957648238351133\n",
      "train loss:0.001600684975564649\n",
      "train loss:0.006910562855006267\n",
      "train loss:0.016358013130814263\n",
      "train loss:0.007037355127601551\n",
      "train loss:0.006366554524882825\n",
      "train loss:0.006038435920225992\n",
      "train loss:0.0026101408595183956\n",
      "train loss:0.0092829028206258\n",
      "train loss:0.0039563382680883104\n",
      "train loss:0.010498165123645096\n",
      "train loss:0.0071745434683598034\n",
      "train loss:0.004803130600079232\n",
      "train loss:0.03032918708955517\n",
      "train loss:0.0006776779741020033\n",
      "train loss:0.0010846582897220964\n",
      "train loss:0.002115122761613868\n",
      "train loss:0.007270730276629216\n",
      "train loss:0.002981645473055397\n",
      "train loss:0.0029528186542509723\n",
      "train loss:0.0027712682730224062\n",
      "train loss:0.006828359702097803\n",
      "train loss:0.0015487452781484566\n",
      "train loss:0.0030896427930091103\n",
      "train loss:0.0004391678034736896\n",
      "train loss:0.018494882700623726\n",
      "train loss:0.022324856283230336\n",
      "train loss:0.010331768214126201\n",
      "train loss:0.006399062623032723\n",
      "train loss:0.002713199333304669\n",
      "train loss:0.0173431919347256\n",
      "train loss:0.0009227434648241759\n",
      "train loss:0.0008527757426333393\n",
      "train loss:0.002411068460514687\n",
      "train loss:0.00035862243769164677\n",
      "train loss:0.01698764295430447\n",
      "train loss:0.0007912694801377914\n",
      "train loss:0.013690827309400872\n",
      "train loss:0.002683984006607176\n",
      "train loss:0.003291720640472034\n",
      "train loss:0.003734301378841509\n",
      "train loss:0.009485968710759424\n",
      "train loss:0.0011079621087385111\n",
      "train loss:0.007187921844304049\n",
      "train loss:0.0011867731592370514\n",
      "train loss:0.00772904432773734\n",
      "train loss:0.0059943380044681725\n",
      "train loss:0.001373515877194991\n",
      "train loss:0.00394937679598622\n",
      "train loss:0.0004908350545237007\n",
      "train loss:0.0008738293330975966\n",
      "train loss:0.004087132595778847\n",
      "train loss:0.0025707295512711944\n",
      "train loss:0.010284337469661859\n",
      "train loss:0.0030558225988710458\n",
      "train loss:0.0011004410635002014\n",
      "train loss:0.021729182486633317\n",
      "train loss:0.01839784104872428\n",
      "train loss:0.0034924693889653974\n",
      "train loss:0.030251173831092278\n",
      "train loss:0.003833146584641553\n",
      "train loss:0.0012521276754739095\n",
      "train loss:0.015560035227548317\n",
      "train loss:0.014953495035681864\n",
      "train loss:0.022485062537699673\n",
      "train loss:0.00987729353608432\n",
      "train loss:0.005232016806238261\n",
      "train loss:0.0036912084619624952\n",
      "train loss:0.0039845597168384\n",
      "train loss:0.00446276411086283\n",
      "train loss:0.0036212966224414105\n",
      "train loss:0.0030284343407703997\n",
      "train loss:0.001591592215658205\n",
      "train loss:0.0051225981800033845\n",
      "train loss:0.004483948871706705\n",
      "train loss:0.003042243197926705\n",
      "train loss:0.01609172528433009\n",
      "train loss:0.0053002939761132364\n",
      "train loss:0.0059976452667231065\n",
      "train loss:0.010407401262157985\n",
      "train loss:0.006635219034342494\n",
      "train loss:0.003156670284562682\n",
      "train loss:0.011646077814845337\n",
      "train loss:0.012439019607929149\n",
      "train loss:0.0014230221194764696\n",
      "train loss:0.004256489298358009\n",
      "train loss:0.1262193474980262\n",
      "train loss:0.005389293047226853\n",
      "train loss:0.0025114911227024483\n",
      "train loss:0.03004131639247901\n",
      "train loss:0.0034950832162741253\n",
      "train loss:0.0008210376270117171\n",
      "train loss:0.06250926782467299\n",
      "train loss:0.002012063073330856\n",
      "train loss:0.0030804714847576897\n",
      "train loss:0.006895077491170457\n",
      "train loss:0.005602991024043119\n",
      "train loss:0.0026012644659639816\n",
      "train loss:0.02770442173796749\n",
      "train loss:0.0006186870169997239\n",
      "train loss:0.007381603920583427\n",
      "train loss:0.0019208060832019492\n",
      "train loss:0.003421696373416223\n",
      "train loss:0.008534944697788595\n",
      "train loss:0.004807303114140012\n",
      "train loss:0.004385289212808988\n",
      "train loss:0.0008852942606786218\n",
      "train loss:0.002186134205529944\n",
      "train loss:0.006541204092751029\n",
      "train loss:0.0037264916305650743\n",
      "train loss:0.012702646990341005\n",
      "train loss:0.008797549754485655\n",
      "train loss:0.0012012912190223824\n",
      "train loss:0.0016065411711271254\n",
      "train loss:0.0021559655961902184\n",
      "train loss:0.004126091585741116\n",
      "train loss:0.0037576548365507944\n",
      "train loss:0.0034767833442380857\n",
      "train loss:0.002379596398278983\n",
      "train loss:0.01356008361684647\n",
      "train loss:0.008198975101440093\n",
      "train loss:0.0024041548515359775\n",
      "train loss:0.00599241030040704\n",
      "train loss:0.006366323962044689\n",
      "train loss:0.0025834500651776356\n",
      "train loss:0.07357310066687157\n",
      "train loss:0.0009003938473845191\n",
      "train loss:0.0006964097838725874\n",
      "train loss:0.0039106949386035535\n",
      "train loss:0.0033579161992461286\n",
      "train loss:0.004825100402511641\n",
      "train loss:0.0028085703101571463\n",
      "train loss:0.0008706901017952194\n",
      "train loss:0.007290522958868554\n",
      "train loss:0.022957836200360546\n",
      "train loss:0.0018539133415959187\n",
      "train loss:0.005743762894862097\n",
      "train loss:0.0029900179627655593\n",
      "train loss:0.005474893401988689\n",
      "train loss:0.003635672567152476\n",
      "train loss:0.003663554247456089\n",
      "train loss:0.002203042066622846\n",
      "train loss:0.011605657926441746\n",
      "train loss:0.005576439410796973\n",
      "train loss:0.007037507132295071\n",
      "train loss:0.007159084153588585\n",
      "train loss:0.005829420417363914\n",
      "train loss:0.003118203091516188\n",
      "train loss:0.0006456667192816231\n",
      "train loss:0.01519602569498715\n",
      "train loss:0.003156893894467278\n",
      "train loss:0.006421449466301294\n",
      "train loss:0.010502595770743486\n",
      "train loss:0.005402619879020109\n",
      "train loss:0.028638748877187755\n",
      "train loss:0.030025725459842056\n",
      "train loss:0.0016908504560693427\n",
      "train loss:0.0012563769219585705\n",
      "train loss:0.009412600482636575\n",
      "train loss:0.021908028907642364\n",
      "train loss:0.010873390332637187\n",
      "train loss:0.010057113179994652\n",
      "train loss:0.011987585280895554\n",
      "train loss:0.0008905551054363016\n",
      "train loss:0.05027846030462788\n",
      "train loss:0.0037897310898103304\n",
      "train loss:0.004062611941594321\n",
      "train loss:0.0008319083763342372\n",
      "train loss:0.003570931786872897\n",
      "train loss:0.008426194920120363\n",
      "train loss:0.04522654300136066\n",
      "train loss:0.00265455071389271\n",
      "train loss:0.004429740669486461\n",
      "train loss:0.0033233467891567005\n",
      "train loss:0.007980087337543223\n",
      "train loss:0.001486010801128213\n",
      "train loss:0.005626800269500717\n",
      "train loss:0.0025257062280584497\n",
      "train loss:0.0032919916259730115\n",
      "train loss:0.03287172113768766\n",
      "train loss:0.0017136800213177472\n",
      "train loss:0.0012595669644945961\n",
      "train loss:0.035405124413363145\n",
      "train loss:0.002158294139832648\n",
      "train loss:0.023065642822641914\n",
      "train loss:0.007656155935994321\n",
      "train loss:0.007137651998925831\n",
      "train loss:0.02227012503327011\n",
      "train loss:0.010860745922823333\n",
      "train loss:0.005798053101596504\n",
      "train loss:0.0014882760742253509\n",
      "train loss:0.034551442005549896\n",
      "train loss:0.006144902208395571\n",
      "train loss:0.0009597642733223715\n",
      "train loss:0.0029782689281550386\n",
      "train loss:0.0018875837879975186\n",
      "train loss:0.010259464434274035\n",
      "train loss:0.0016567113732601846\n",
      "train loss:0.001019039190654088\n",
      "train loss:0.004096889402629264\n",
      "train loss:0.011186004940341785\n",
      "train loss:0.009321746099471628\n",
      "train loss:0.002007756260680773\n",
      "train loss:0.0030013939461017297\n",
      "train loss:0.015440434106462881\n",
      "train loss:0.001179330203983278\n",
      "train loss:0.0016542048399562975\n",
      "train loss:0.01048507192973397\n",
      "train loss:0.010759088700543797\n",
      "train loss:0.0010737772066953283\n",
      "train loss:0.006115479429177834\n",
      "train loss:0.0073527706697502394\n",
      "train loss:0.12194313068827006\n",
      "train loss:0.011860945359555284\n",
      "train loss:0.004315145956092625\n",
      "train loss:0.008497212627097194\n",
      "train loss:0.008314680058819798\n",
      "train loss:0.00480527838255244\n",
      "train loss:0.009814576004774695\n",
      "train loss:0.048823500988457766\n",
      "train loss:0.02585383011253301\n",
      "train loss:0.0010962781309969288\n",
      "train loss:0.004052213210969023\n",
      "train loss:0.0013519386129333393\n",
      "train loss:0.005174288651058682\n",
      "train loss:0.022491993918879873\n",
      "train loss:0.002720682000737407\n",
      "train loss:0.0085919455485979\n",
      "train loss:0.009449598153916916\n",
      "train loss:0.005357980571382457\n",
      "train loss:0.00575138256562412\n",
      "train loss:0.004509182489896762\n",
      "train loss:0.05141862865346646\n",
      "train loss:0.0006330653482589363\n",
      "train loss:0.0017850845146281397\n",
      "train loss:0.0044950672000545824\n",
      "train loss:0.009434552279133356\n",
      "train loss:0.00776151241265205\n",
      "train loss:0.004898706937321733\n",
      "train loss:0.01162774190053653\n",
      "train loss:0.013987043506065612\n",
      "train loss:0.012210341415010333\n",
      "train loss:0.007073878173182949\n",
      "train loss:0.006971620512985034\n",
      "train loss:0.007044245525437725\n",
      "train loss:0.0018719664105212833\n",
      "train loss:0.0042628927639156875\n",
      "train loss:0.02149771836806215\n",
      "train loss:0.002842002205999286\n",
      "train loss:0.009934949668160518\n",
      "train loss:0.005409461106375642\n",
      "train loss:0.012434183310477884\n",
      "train loss:0.04148379823559587\n",
      "train loss:0.00206623828193187\n",
      "train loss:0.0034528139434166407\n",
      "train loss:0.003628708601467969\n",
      "train loss:0.012543585765195936\n",
      "train loss:0.0010482654314354011\n",
      "train loss:0.001953061046448177\n",
      "train loss:0.0008480063977589664\n",
      "train loss:0.028055626921630834\n",
      "train loss:0.0059228645654838185\n",
      "train loss:0.0033515214872733095\n",
      "train loss:0.009340501298937041\n",
      "train loss:0.0007816914649745068\n",
      "train loss:0.005931005505393671\n",
      "train loss:0.05054517927051387\n",
      "train loss:0.005145239974998305\n",
      "train loss:0.014606313665825607\n",
      "train loss:0.0005842543663037291\n",
      "train loss:0.002048053663286251\n",
      "train loss:0.0005895336741844916\n",
      "train loss:0.01859011812983776\n",
      "train loss:0.004929901729425815\n",
      "train loss:0.00024072377700386016\n",
      "train loss:0.004144542424903156\n",
      "train loss:0.005994874241394083\n",
      "train loss:0.0055359695497854714\n",
      "train loss:0.014934844610205882\n",
      "train loss:0.006590279449183155\n",
      "train loss:0.002345544611541835\n",
      "train loss:0.01949957267087858\n",
      "train loss:0.003931144205122021\n",
      "train loss:0.002234026991749423\n",
      "train loss:0.008878355792975006\n",
      "train loss:0.0010237400621472804\n",
      "train loss:0.002072144372302478\n",
      "train loss:0.007490839163955725\n",
      "train loss:0.0035776964966119447\n",
      "train loss:0.00040164087922622\n",
      "train loss:0.0018715444017143798\n",
      "train loss:0.0009684028682579933\n",
      "train loss:0.0055019740061773735\n",
      "train loss:0.0010776936287416872\n",
      "train loss:0.001064692204347275\n",
      "train loss:0.008293648798860503\n",
      "train loss:0.000824048927640488\n",
      "train loss:0.012022104473900808\n",
      "train loss:0.001512342138249415\n",
      "train loss:0.0604696109700347\n",
      "train loss:0.0014192371428833268\n",
      "train loss:0.000898980946120915\n",
      "train loss:0.0009373456070104816\n",
      "train loss:0.006882784846791484\n",
      "train loss:0.006320793465927906\n",
      "train loss:0.006837910942210034\n",
      "train loss:0.0014576608113851708\n",
      "train loss:0.0017581839841549812\n",
      "train loss:0.004747883087456221\n",
      "train loss:0.009102798871352404\n",
      "train loss:0.0008584821950286936\n",
      "train loss:0.0016572903830991937\n",
      "train loss:0.0022709623657491502\n",
      "train loss:0.006711407421859879\n",
      "train loss:0.0007740445444600581\n",
      "train loss:0.011986704814378593\n",
      "train loss:0.0013004237524333914\n",
      "train loss:0.0022738280504391232\n",
      "train loss:0.001680943436995251\n",
      "train loss:0.00874837776215798\n",
      "train loss:0.0023934224009079536\n",
      "train loss:0.015561736008002093\n",
      "train loss:0.0028553998757027453\n",
      "train loss:0.005960044028917556\n",
      "train loss:0.001408978385735178\n",
      "train loss:0.010594150484461528\n",
      "train loss:0.0005683884010964612\n",
      "train loss:0.008642290817505087\n",
      "train loss:0.0017198416710086347\n",
      "train loss:0.0026148344850102697\n",
      "train loss:0.0032501557535860354\n",
      "train loss:0.041094688335421826\n",
      "train loss:0.00430131863820434\n",
      "train loss:0.001024185742748587\n",
      "train loss:0.004783382030829605\n",
      "train loss:0.005986407148805817\n",
      "train loss:0.007150970657148928\n",
      "train loss:0.002567984244209773\n",
      "train loss:0.004888640638962803\n",
      "train loss:0.0030227165366141975\n",
      "train loss:0.0075136291790163685\n",
      "train loss:0.0024222502638818325\n",
      "train loss:0.011479449848304282\n",
      "train loss:0.0007694306322915872\n",
      "train loss:0.0020172736790034403\n",
      "train loss:0.0003449763269951176\n",
      "train loss:0.11896598947901867\n",
      "train loss:0.0009667925671818522\n",
      "train loss:0.004808772428395728\n",
      "train loss:0.001937342249248189\n",
      "train loss:0.001695857403344108\n",
      "train loss:0.0018629235602340918\n",
      "train loss:0.0010613804708593556\n",
      "train loss:0.003999793170751976\n",
      "train loss:0.021185862732244654\n",
      "train loss:0.005384434651352414\n",
      "train loss:0.004585185650153358\n",
      "train loss:0.0034407731907761217\n",
      "train loss:0.0011493181524079529\n",
      "train loss:0.0005499347040209008\n",
      "train loss:0.003884922546412184\n",
      "train loss:0.0029313452075374357\n",
      "train loss:0.006511756271801702\n",
      "train loss:0.004106184994466175\n",
      "train loss:0.008690367391585335\n",
      "train loss:0.0018975097973705684\n",
      "train loss:0.025215000078198893\n",
      "train loss:0.0009980933903288105\n",
      "train loss:0.03401549122061706\n",
      "train loss:0.001301532353041021\n",
      "train loss:0.007356896684660874\n",
      "train loss:0.0012273995687521193\n",
      "train loss:0.02783210757710065\n",
      "train loss:0.06633350113337619\n",
      "train loss:0.006273141398934262\n",
      "train loss:0.001388288679280421\n",
      "train loss:0.005998120255438373\n",
      "train loss:0.004180551278663814\n",
      "train loss:0.0050025241627365425\n",
      "train loss:0.0042173090130855325\n",
      "train loss:0.003531922564554008\n",
      "train loss:0.004333845972295635\n",
      "train loss:0.0028881631857502967\n",
      "train loss:0.007455966593368802\n",
      "train loss:0.004928442489471696\n",
      "train loss:0.0020759371553344826\n",
      "train loss:0.001987500478613623\n",
      "train loss:0.0028873248436506694\n",
      "train loss:0.0022656486505739423\n",
      "train loss:0.002338672445606205\n",
      "train loss:0.01904834106514197\n",
      "train loss:0.007837078980233485\n",
      "train loss:0.007462672631463945\n",
      "train loss:0.002857043564641124\n",
      "train loss:0.013010001520124206\n",
      "train loss:0.0022509161098081213\n",
      "train loss:0.005518476425941951\n",
      "train loss:0.005556781667895961\n",
      "train loss:0.0019561690475266478\n",
      "train loss:0.005786767326668683\n",
      "train loss:0.003528212357068465\n",
      "train loss:0.0006885348791854378\n",
      "train loss:0.00199449865956357\n",
      "train loss:0.00883014320860216\n",
      "train loss:0.012276256037114193\n",
      "train loss:0.005718829100766059\n",
      "train loss:0.07535154845536332\n",
      "train loss:0.0005398995081354459\n",
      "train loss:0.0006885891598336083\n",
      "train loss:0.0077944329824058\n",
      "train loss:0.004955710568357326\n",
      "train loss:0.006851960074502953\n",
      "train loss:0.0006658609345133562\n",
      "train loss:0.001317148617322174\n",
      "train loss:0.008810628337382663\n",
      "train loss:0.0024646323202286956\n",
      "train loss:0.006054273003740514\n",
      "train loss:0.01772588124534527\n",
      "train loss:0.01334269450341399\n",
      "train loss:0.009349838449976961\n",
      "train loss:0.105289593536926\n",
      "train loss:0.011265516364536822\n",
      "train loss:0.005250501174169238\n",
      "train loss:0.0038427924753720553\n",
      "train loss:0.004145668273223702\n",
      "=== epoch:12, train acc:0.997, test acc:0.991 ===\n",
      "train loss:0.004692611998127476\n",
      "train loss:0.005284698988579844\n",
      "train loss:0.0033069231423002625\n",
      "train loss:0.0016275380992673736\n",
      "train loss:0.006738584035223026\n",
      "train loss:0.00072607640585994\n",
      "train loss:0.0016168842268516662\n",
      "train loss:0.014968990191129884\n",
      "train loss:0.0014800650204559974\n",
      "train loss:0.0012829017684601717\n",
      "train loss:0.0009145781596708191\n",
      "train loss:0.03614778521862759\n",
      "train loss:0.018898118051440833\n",
      "train loss:0.0014611040588188096\n",
      "train loss:0.0009963460104089835\n",
      "train loss:0.02386911538032512\n",
      "train loss:0.011791456885581643\n",
      "train loss:0.003378119620004782\n",
      "train loss:0.007224477560406935\n",
      "train loss:0.06716529133857177\n",
      "train loss:0.018156284910491035\n",
      "train loss:0.021656068533161738\n",
      "train loss:0.0030736852491720585\n",
      "train loss:0.005615275979237975\n",
      "train loss:0.00803722191732434\n",
      "train loss:0.0304696336395087\n",
      "train loss:0.002345067447581725\n",
      "train loss:0.001376701082010457\n",
      "train loss:0.07409738211281278\n",
      "train loss:0.0012554643719690844\n",
      "train loss:0.00539253457184203\n",
      "train loss:0.005999218301507617\n",
      "train loss:0.010595150140429064\n",
      "train loss:0.004900936836415813\n",
      "train loss:0.007489038484666811\n",
      "train loss:0.06291501039552781\n",
      "train loss:0.0021032275347055026\n",
      "train loss:0.002728992486426679\n",
      "train loss:0.0016811267188567645\n",
      "train loss:0.0067998104180310315\n",
      "train loss:0.003147499521419207\n",
      "train loss:0.0062240397347643975\n",
      "train loss:0.004587080387385414\n",
      "train loss:0.0031728488157933003\n",
      "train loss:0.003607911095362984\n",
      "train loss:0.001965348508119026\n",
      "train loss:0.003731181696665864\n",
      "train loss:0.0020441898198919365\n",
      "train loss:0.001384600741521466\n",
      "train loss:0.0009006896803728196\n",
      "train loss:0.0023271439074350263\n",
      "train loss:0.0042543388899980855\n",
      "train loss:0.006877683867112929\n",
      "train loss:0.0014897851133989493\n",
      "train loss:0.0005969764394863958\n",
      "train loss:0.004099817146105285\n",
      "train loss:0.0009084233876353568\n",
      "train loss:0.021633764239479755\n",
      "train loss:0.008232653556175688\n",
      "train loss:0.0007039362400035455\n",
      "train loss:0.001549282686307036\n",
      "train loss:0.0019072557715005631\n",
      "train loss:0.002137860568440218\n",
      "train loss:0.002222990481798304\n",
      "train loss:0.0007573107713638738\n",
      "train loss:0.013266766413913517\n",
      "train loss:0.002295258217413837\n",
      "train loss:0.004938686422029537\n",
      "train loss:0.00990836902128155\n",
      "train loss:0.005096336114592886\n",
      "train loss:0.007701491774038917\n",
      "train loss:0.007945422308010071\n",
      "train loss:0.002095204133442505\n",
      "train loss:0.004763224171977956\n",
      "train loss:0.0008049841152340102\n",
      "train loss:0.0028397105705891784\n",
      "train loss:0.0010905040945339583\n",
      "train loss:0.0026050954331160382\n",
      "train loss:0.0042834900226446804\n",
      "train loss:0.049076840572144044\n",
      "train loss:0.003931904806041222\n",
      "train loss:0.0008926177531235047\n",
      "train loss:0.003500858281262658\n",
      "train loss:0.0016834776631967285\n",
      "train loss:0.003720544131358234\n",
      "train loss:0.0043074439785603085\n",
      "train loss:0.0062954653921000366\n",
      "train loss:0.006777477235868806\n",
      "train loss:0.0017238378936420512\n",
      "train loss:0.0035370843982455136\n",
      "train loss:0.0012484726644184576\n",
      "train loss:0.009489326669974844\n",
      "train loss:0.0021977169995716908\n",
      "train loss:0.05238184148257436\n",
      "train loss:0.0091064214190026\n",
      "train loss:0.0011272162024293297\n",
      "train loss:0.008706731055907111\n",
      "train loss:0.007319520132906452\n",
      "train loss:0.009053763443529669\n",
      "train loss:0.006428152260695364\n",
      "train loss:0.0003329071384982541\n",
      "train loss:0.002596165826215997\n",
      "train loss:0.019294050495268732\n",
      "train loss:0.004785521902358301\n",
      "train loss:0.000837528879845466\n",
      "train loss:0.0035417156872565954\n",
      "train loss:0.0021505871006633932\n",
      "train loss:0.0028339788556288542\n",
      "train loss:0.0005233242038462618\n",
      "train loss:0.0017934316005379718\n",
      "train loss:0.009596906178399428\n",
      "train loss:0.0031858096818526776\n",
      "train loss:0.010099456818873467\n",
      "train loss:0.0018385295589008416\n",
      "train loss:0.012918018985220412\n",
      "train loss:0.00319506750099382\n",
      "train loss:0.006292483537714937\n",
      "train loss:0.011894732356257624\n",
      "train loss:0.0009114701113170498\n",
      "train loss:0.0007291210389566705\n",
      "train loss:0.022411805768505055\n",
      "train loss:0.0033411781190708823\n",
      "train loss:0.011932599584782681\n",
      "train loss:0.03249613894817852\n",
      "train loss:0.0024815115871824455\n",
      "train loss:0.0035411822288701766\n",
      "train loss:0.014906917378746849\n",
      "train loss:0.0015223452996966256\n",
      "train loss:0.0009878185510504291\n",
      "train loss:0.0033347446406815596\n",
      "train loss:0.0012656816430412076\n",
      "train loss:0.0036725066329776805\n",
      "train loss:0.002092488740410332\n",
      "train loss:0.0017701327948454967\n",
      "train loss:0.0024154567380439834\n",
      "train loss:0.011072639453995352\n",
      "train loss:0.00819089439963834\n",
      "train loss:0.006173739774644728\n",
      "train loss:0.03400850068013777\n",
      "train loss:0.003009857583634356\n",
      "train loss:0.0018482364237791323\n",
      "train loss:0.0014983041622282027\n",
      "train loss:0.012272071613273457\n",
      "train loss:0.0005234262253407518\n",
      "train loss:0.00583243520974288\n",
      "train loss:0.0014211106152787864\n",
      "train loss:0.0008116363027929533\n",
      "train loss:0.04695183912875639\n",
      "train loss:0.004825272777899547\n",
      "train loss:0.002329187265585863\n",
      "train loss:0.0031051126921851\n",
      "train loss:0.005465354189006542\n",
      "train loss:0.0011133395357732568\n",
      "train loss:0.0019096259454873885\n",
      "train loss:0.009470430080073608\n",
      "train loss:0.0026760753104059475\n",
      "train loss:0.007561173432345437\n",
      "train loss:0.0046544472074198295\n",
      "train loss:0.00721387020503064\n",
      "train loss:0.0006177787926168594\n",
      "train loss:0.020741348220212483\n",
      "train loss:0.0027649325246703587\n",
      "train loss:0.004847302854489593\n",
      "train loss:0.022640630873853203\n",
      "train loss:0.0008206444728154992\n",
      "train loss:0.0049869500820923516\n",
      "train loss:0.0030111159780379705\n",
      "train loss:0.0004972624615563124\n",
      "train loss:0.0005938538138125625\n",
      "train loss:0.00014045423617505424\n",
      "train loss:0.0031153445167726424\n",
      "train loss:0.017731234863130604\n",
      "train loss:0.0009501803683760578\n",
      "train loss:0.0045870919339343\n",
      "train loss:0.0036843026092444834\n",
      "train loss:0.006243031070671664\n",
      "train loss:0.0010670069934746304\n",
      "train loss:0.0031917801822143417\n",
      "train loss:0.001494091944483734\n",
      "train loss:0.006466060554119818\n",
      "train loss:0.0029681406923607935\n",
      "train loss:0.0002704975128635956\n",
      "train loss:0.005530103196568109\n",
      "train loss:0.0019252345268399643\n",
      "train loss:0.004227631903452351\n",
      "train loss:0.002330844153741821\n",
      "train loss:0.016311256230507422\n",
      "train loss:0.0007641745254584476\n",
      "train loss:0.06240559049472801\n",
      "train loss:0.0012918933629743326\n",
      "train loss:0.0024370143495252156\n",
      "train loss:0.00178590004661291\n",
      "train loss:0.0030112122517210516\n",
      "train loss:0.003145848327175876\n",
      "train loss:0.009331504424363821\n",
      "train loss:0.018552868923307507\n",
      "train loss:0.005656177283529329\n",
      "train loss:0.008334275201789903\n",
      "train loss:0.001288537020112685\n",
      "train loss:0.0040586187480834415\n",
      "train loss:0.004062106130163763\n",
      "train loss:0.001746669550278257\n",
      "train loss:0.01147153388013724\n",
      "train loss:0.010861963453097798\n",
      "train loss:0.005368167512888516\n",
      "train loss:0.006410413466646459\n",
      "train loss:0.0191812525061534\n",
      "train loss:0.005498792223543813\n",
      "train loss:0.004361671370534448\n",
      "train loss:0.0009036409161915246\n",
      "train loss:0.0013921047972886358\n",
      "train loss:0.01359680550570679\n",
      "train loss:0.0034478206739464584\n",
      "train loss:0.0015329795401715083\n",
      "train loss:0.004529629913965239\n",
      "train loss:0.0012971420704530096\n",
      "train loss:0.0031880976245778196\n",
      "train loss:0.003004283538797595\n",
      "train loss:0.022565686671733875\n",
      "train loss:0.002643863280130879\n",
      "train loss:0.006849095001817891\n",
      "train loss:0.009642166970167896\n",
      "train loss:0.0010682532419740102\n",
      "train loss:0.011563937774039272\n",
      "train loss:0.0008005665529856449\n",
      "train loss:0.011955011886940148\n",
      "train loss:0.001315614036229538\n",
      "train loss:0.0008789248481886813\n",
      "train loss:0.00482599423602397\n",
      "train loss:0.0006104275809464225\n",
      "train loss:0.0033681696756219597\n",
      "train loss:0.0008471584070154765\n",
      "train loss:0.0011312050736064514\n",
      "train loss:0.032243935034694735\n",
      "train loss:0.02986101315849313\n",
      "train loss:0.0015607683565472617\n",
      "train loss:0.00034187546252019874\n",
      "train loss:0.0019204282749399517\n",
      "train loss:0.00143868791965995\n",
      "train loss:0.0017333319956620461\n",
      "train loss:0.02278633829815595\n",
      "train loss:0.007372892769306253\n",
      "train loss:0.003688463412862249\n",
      "train loss:0.0005650973332818187\n",
      "train loss:0.0008824868030234374\n",
      "train loss:0.004795502871980563\n",
      "train loss:0.001001531678920695\n",
      "train loss:0.0004487400415437596\n",
      "train loss:0.014319510369302364\n",
      "train loss:0.012304699060729533\n",
      "train loss:0.002759441860046698\n",
      "train loss:0.0041652144592544\n",
      "train loss:0.007736682265658047\n",
      "train loss:0.000996360813344099\n",
      "train loss:0.0006347176290507965\n",
      "train loss:0.0020127588416862688\n",
      "train loss:0.0009655639787374216\n",
      "train loss:0.0025725604460715163\n",
      "train loss:0.0026424445890229752\n",
      "train loss:0.010162345495802185\n",
      "train loss:0.0007595236782792538\n",
      "train loss:0.0031977057573003994\n",
      "train loss:0.0011564310056499027\n",
      "train loss:0.003421006264338689\n",
      "train loss:0.002321234918966347\n",
      "train loss:0.0021328815625307656\n",
      "train loss:0.0034414055527179238\n",
      "train loss:0.00483731772813672\n",
      "train loss:0.003793276616638873\n",
      "train loss:0.0004370807755158333\n",
      "train loss:0.004378441891349488\n",
      "train loss:0.0011706133232098322\n",
      "train loss:0.013206293001490323\n",
      "train loss:0.0016113305696808238\n",
      "train loss:0.10429008784500729\n",
      "train loss:0.026627380924701592\n",
      "train loss:0.0017561482043307035\n",
      "train loss:0.001078770842618485\n",
      "train loss:0.0076670563213630675\n",
      "train loss:0.003413847324650503\n",
      "train loss:0.007921636499290926\n",
      "train loss:0.0009221511724067711\n",
      "train loss:0.0017251004052251048\n",
      "train loss:0.006541460436481231\n",
      "train loss:0.004009243317254874\n",
      "train loss:0.004557818778027808\n",
      "train loss:0.004859950029671005\n",
      "train loss:0.0027271663497320147\n",
      "train loss:0.014064860871665277\n",
      "train loss:0.009191297036519263\n",
      "train loss:0.0033041514460869716\n",
      "train loss:0.0017952812451138866\n",
      "train loss:0.018797832441889352\n",
      "train loss:0.012254644575745963\n",
      "train loss:0.004179906277897123\n",
      "train loss:0.00017887390859774383\n",
      "train loss:0.02012167705717722\n",
      "train loss:0.003589741343445524\n",
      "train loss:0.0034294018358813592\n",
      "train loss:0.002279933001254396\n",
      "train loss:0.002401645664066315\n",
      "train loss:0.006561219745102483\n",
      "train loss:0.013480537917687187\n",
      "train loss:0.002098798062221459\n",
      "train loss:0.0011616536751998712\n",
      "train loss:0.0075148369018628825\n",
      "train loss:0.012357469816074334\n",
      "train loss:0.0004190412278681241\n",
      "train loss:0.008289395105650401\n",
      "train loss:0.0036303901986563976\n",
      "train loss:0.012953719864012524\n",
      "train loss:0.004329742519145829\n",
      "train loss:0.003975747547840298\n",
      "train loss:0.005702162029687292\n",
      "train loss:0.0005603055760451552\n",
      "train loss:0.0005464452320639401\n",
      "train loss:0.005955730830287156\n",
      "train loss:0.005849855788778604\n",
      "train loss:0.006272000070795245\n",
      "train loss:0.01100740509482381\n",
      "train loss:0.008275990492399026\n",
      "train loss:0.004311179217703998\n",
      "train loss:0.004022353201770137\n",
      "train loss:0.017730616908686714\n",
      "train loss:0.001219285241238247\n",
      "train loss:0.0011012144170069343\n",
      "train loss:0.008075091523735584\n",
      "train loss:0.0008763953899744812\n",
      "train loss:0.002219723289076488\n",
      "train loss:0.009255218955154023\n",
      "train loss:0.005847957116541935\n",
      "train loss:0.0012465302886520997\n",
      "train loss:0.0025996863694670597\n",
      "train loss:0.0009631632945182732\n",
      "train loss:0.00770983253414054\n",
      "train loss:0.0022963711768259946\n",
      "train loss:0.03610623635868538\n",
      "train loss:0.0011298833883161418\n",
      "train loss:0.001561010464425435\n",
      "train loss:0.0026886161697202465\n",
      "train loss:0.008052620091048786\n",
      "train loss:0.012787941423172865\n",
      "train loss:0.0017276638526420264\n",
      "train loss:0.0004965317718292538\n",
      "train loss:0.0008048428275985062\n",
      "train loss:0.0018659261812796122\n",
      "train loss:0.04445912289778872\n",
      "train loss:0.001988366203197406\n",
      "train loss:0.00305455590553152\n",
      "train loss:0.005020044206719479\n",
      "train loss:0.006433270202634216\n",
      "train loss:0.005021480318629114\n",
      "train loss:0.0118323640612658\n",
      "train loss:5.075724491153388e-05\n",
      "train loss:0.00015198788631678442\n",
      "train loss:0.008178824791372137\n",
      "train loss:0.007241630909584276\n",
      "train loss:0.0031079323218067677\n",
      "train loss:0.0006269682526308101\n",
      "train loss:0.0024669370494838196\n",
      "train loss:0.002381149718507997\n",
      "train loss:0.001523238191322034\n",
      "train loss:0.005817931682705129\n",
      "train loss:0.0032101010113630615\n",
      "train loss:0.005476473341182247\n",
      "train loss:0.0024580074011821317\n",
      "train loss:0.00432816686720991\n",
      "train loss:0.006514783884401825\n",
      "train loss:0.00045077536457956895\n",
      "train loss:0.002985661186265914\n",
      "train loss:0.002385105443413836\n",
      "train loss:0.0017220570142136068\n",
      "train loss:0.008816956799998422\n",
      "train loss:0.0007045604970696646\n",
      "train loss:0.004476803343136574\n",
      "train loss:0.0006463110666230173\n",
      "train loss:0.0038136203131088186\n",
      "train loss:0.0012533430185222235\n",
      "train loss:0.003090853351535311\n",
      "train loss:0.003434742356359646\n",
      "train loss:0.0005697339914302582\n",
      "train loss:0.0004943437364494028\n",
      "train loss:0.0008048611474424609\n",
      "train loss:0.0008329270864974665\n",
      "train loss:0.0032035261055018117\n",
      "train loss:0.031126167088148603\n",
      "train loss:0.00897517034772021\n",
      "train loss:0.0020973442149808596\n",
      "train loss:0.008901755933999458\n",
      "train loss:0.0006589806597846872\n",
      "train loss:0.008134171358579386\n",
      "train loss:0.00209601869727326\n",
      "train loss:0.0026812944773452222\n",
      "train loss:0.0031070907930031543\n",
      "train loss:0.002901109402849451\n",
      "train loss:0.007012884746075013\n",
      "train loss:0.0049201138795665475\n",
      "train loss:0.02069601356405892\n",
      "train loss:0.0008124323606692424\n",
      "train loss:0.0008083369627300766\n",
      "train loss:0.0033019225593456446\n",
      "train loss:0.0004940814476246734\n",
      "train loss:0.0004980440607439334\n",
      "train loss:0.007393323146831097\n",
      "train loss:0.011022913611431397\n",
      "train loss:0.00218130716938113\n",
      "train loss:0.03736481796610216\n",
      "train loss:0.006898477889512081\n",
      "train loss:0.00025650602871438155\n",
      "train loss:0.00029229667213465137\n",
      "train loss:0.0026482934264730447\n",
      "train loss:0.009980272007151963\n",
      "train loss:0.0005461202651552437\n",
      "train loss:0.0014412748463562065\n",
      "train loss:0.005605264561029669\n",
      "train loss:0.0006151350567995311\n",
      "train loss:0.0011904414219285385\n",
      "train loss:0.023409293017828035\n",
      "train loss:0.015251184078633231\n",
      "train loss:0.009524370068263914\n",
      "train loss:0.001674325939651572\n",
      "train loss:0.0014335136075727247\n",
      "train loss:0.021252716981267156\n",
      "train loss:0.0016271058645653618\n",
      "train loss:0.0004184114287078678\n",
      "train loss:0.0008255104038314934\n",
      "train loss:0.017008955556666337\n",
      "train loss:0.003066469733700634\n",
      "train loss:0.002568138408299676\n",
      "train loss:0.004129024762037467\n",
      "train loss:0.0028134757552510745\n",
      "train loss:0.0038182994064496364\n",
      "train loss:0.001364446898408834\n",
      "train loss:0.0038027005757523343\n",
      "train loss:0.005444668527022468\n",
      "train loss:0.001697526381857832\n",
      "train loss:0.0037064373576639596\n",
      "train loss:0.000648799295682427\n",
      "train loss:0.008689268264197329\n",
      "train loss:0.001619860201100512\n",
      "train loss:0.005729508028970122\n",
      "train loss:0.0053348216966171815\n",
      "train loss:0.0002523314486210345\n",
      "train loss:0.0010167810073479953\n",
      "train loss:0.0008061529211979107\n",
      "train loss:0.00016972344288950788\n",
      "train loss:0.01806726985379715\n",
      "train loss:0.006210029558293828\n",
      "train loss:0.005401596004546087\n",
      "train loss:0.009715443811599313\n",
      "train loss:0.007053044413264499\n",
      "train loss:0.0005426762281014216\n",
      "train loss:0.005477763561001221\n",
      "train loss:0.0011252177523683102\n",
      "train loss:0.001688642597635724\n",
      "train loss:0.0021659770058110213\n",
      "train loss:0.004951612625235172\n",
      "train loss:0.05154120238541675\n",
      "train loss:0.0017826260256256729\n",
      "train loss:0.0042588048664561375\n",
      "train loss:0.0168835737479875\n",
      "train loss:0.006128245579134609\n",
      "train loss:0.0016962776522228698\n",
      "train loss:0.029108615759900997\n",
      "train loss:0.004521479885378234\n",
      "train loss:0.004139308327034535\n",
      "train loss:0.0009936232166457954\n",
      "train loss:0.00043177040400979366\n",
      "train loss:0.005297890278241002\n",
      "train loss:0.0006821594680529461\n",
      "train loss:0.000499102266171441\n",
      "train loss:0.0034916615996616607\n",
      "train loss:0.005450574083695989\n",
      "train loss:0.0038619548381246937\n",
      "train loss:0.004001511902390912\n",
      "train loss:0.006656303985035519\n",
      "train loss:0.003632304357258379\n",
      "train loss:0.0007091637127234565\n",
      "train loss:0.0017491452823100743\n",
      "train loss:0.006456747455184487\n",
      "train loss:0.016536241163910684\n",
      "train loss:0.005457307917109362\n",
      "train loss:0.0020791761210029146\n",
      "train loss:0.002039506591523214\n",
      "train loss:0.0008098073251133111\n",
      "train loss:0.025827263253508564\n",
      "train loss:0.0029413460631368383\n",
      "train loss:0.0031077849555304123\n",
      "train loss:0.0018682266495064807\n",
      "train loss:0.005199110989415461\n",
      "train loss:0.0008921974670845615\n",
      "train loss:0.007010257793285679\n",
      "train loss:0.004413289403240323\n",
      "train loss:0.02865556476843882\n",
      "train loss:0.004179184369852228\n",
      "train loss:0.00343784493005083\n",
      "train loss:0.004927754386325232\n",
      "train loss:0.0030588354012921963\n",
      "train loss:0.03765578699337353\n",
      "train loss:0.002901605466275026\n",
      "train loss:0.00014758028627377782\n",
      "train loss:0.005024937342473409\n",
      "train loss:0.0008321148502642254\n",
      "train loss:0.0007611125021912541\n",
      "train loss:0.016271955201016174\n",
      "train loss:0.0017536788393725682\n",
      "train loss:0.006494270196092642\n",
      "train loss:0.002819713983687436\n",
      "train loss:0.011757128743572744\n",
      "train loss:0.006277097778534618\n",
      "train loss:0.0008585363642250911\n",
      "train loss:0.0004864143808704549\n",
      "train loss:0.002588631126266065\n",
      "train loss:0.0316805975889791\n",
      "train loss:0.0017912470465943396\n",
      "train loss:0.004313563394135211\n",
      "train loss:0.0022313851360660484\n",
      "train loss:0.005219611455265001\n",
      "train loss:0.0004957488340468835\n",
      "train loss:0.0004988028469417625\n",
      "train loss:0.002393807821776367\n",
      "train loss:0.003164411085913661\n",
      "train loss:0.0022289629651818543\n",
      "train loss:0.0020015955184523706\n",
      "train loss:0.002486816517729048\n",
      "train loss:0.0005063779982381531\n",
      "train loss:0.0006380967828814683\n",
      "train loss:0.0034869038088415046\n",
      "train loss:0.005151387839363301\n",
      "train loss:0.00031730643460098384\n",
      "train loss:0.0013659612958865095\n",
      "train loss:0.0011883917736491743\n",
      "train loss:0.0034624018442159315\n",
      "train loss:0.012146232885665409\n",
      "train loss:0.003407380944105756\n",
      "train loss:0.01720256671819853\n",
      "train loss:0.06878183146315035\n",
      "train loss:0.001196885027668562\n",
      "train loss:0.013149311810292599\n",
      "train loss:0.007646235731818608\n",
      "train loss:0.0005273217935108453\n",
      "train loss:0.07540249664019848\n",
      "train loss:0.0008634280055841642\n",
      "train loss:0.004240068984187387\n",
      "train loss:0.003165962526090651\n",
      "train loss:0.01546034646584773\n",
      "train loss:0.0021596624212411194\n",
      "train loss:0.005000201470851502\n",
      "train loss:0.0036848666186545514\n",
      "train loss:0.0013339578887774865\n",
      "train loss:0.000740248054286516\n",
      "train loss:0.005315058452230506\n",
      "train loss:0.0011891627532655768\n",
      "train loss:0.0006948915039922536\n",
      "train loss:0.0009044981648847742\n",
      "train loss:0.0008331594268885745\n",
      "train loss:0.004477299947479954\n",
      "train loss:0.002746219105439462\n",
      "train loss:0.0032621800392081267\n",
      "train loss:0.006866967858416989\n",
      "train loss:0.0008411206480202582\n",
      "train loss:0.011946805787121683\n",
      "train loss:0.004017203337370655\n",
      "train loss:0.002511206286638388\n",
      "train loss:0.001466187936690837\n",
      "train loss:0.0026787043089146105\n",
      "train loss:0.0012011835234654975\n",
      "train loss:0.0012858571743707\n",
      "train loss:0.00741416158939132\n",
      "train loss:0.007268663628605565\n",
      "train loss:0.054862453089085585\n",
      "train loss:0.002611268733983575\n",
      "train loss:0.00369972967493107\n",
      "train loss:0.007692460618116031\n",
      "train loss:0.0016538402865839549\n",
      "train loss:0.001846427128504622\n",
      "train loss:0.005780783598664775\n",
      "train loss:0.005209357512384145\n",
      "train loss:0.0025637352218001873\n",
      "train loss:0.020358848736662466\n",
      "train loss:0.008836914932774977\n",
      "train loss:0.0061212650244503695\n",
      "train loss:0.0023202908325117666\n",
      "train loss:0.018273936191785304\n",
      "train loss:0.005890953819841983\n",
      "train loss:0.007967826763860202\n",
      "train loss:0.0009599953335670155\n",
      "train loss:0.00598616321039358\n",
      "train loss:0.0018222040955301322\n",
      "train loss:0.013939810622160815\n",
      "train loss:0.015879435007037358\n",
      "train loss:0.06729067354858573\n",
      "train loss:0.0015933202454610875\n",
      "train loss:0.003910552512913375\n",
      "train loss:0.022266579644191754\n",
      "train loss:0.0009670141186659423\n",
      "train loss:0.0017780197424181288\n",
      "train loss:0.0065653832091337894\n",
      "train loss:0.0039488662773050544\n",
      "train loss:0.007390561342656704\n",
      "=== epoch:13, train acc:0.997, test acc:0.99 ===\n",
      "train loss:0.015257526130852218\n",
      "train loss:0.010844804317976216\n",
      "train loss:0.002934735331091459\n",
      "train loss:0.0051507031583055965\n",
      "train loss:0.011022316667672657\n",
      "train loss:0.00037572150012312377\n",
      "train loss:0.009297830792106946\n",
      "train loss:0.0011732385445569341\n",
      "train loss:0.00028285638377064867\n",
      "train loss:0.008610706470457563\n",
      "train loss:0.002257674260777851\n",
      "train loss:0.001741603504111263\n",
      "train loss:0.003143658829924456\n",
      "train loss:0.005910819183491486\n",
      "train loss:0.0008615197961742215\n",
      "train loss:0.0025898265443848665\n",
      "train loss:0.0024975166113266694\n",
      "train loss:0.0002338174434069026\n",
      "train loss:0.0011837799796471373\n",
      "train loss:0.000851435119097501\n",
      "train loss:0.0021977621428466766\n",
      "train loss:0.000996863477770749\n",
      "train loss:0.0037806922246587118\n",
      "train loss:0.018777815351953903\n",
      "train loss:0.01585290594803393\n",
      "train loss:0.0035068804018334337\n",
      "train loss:0.0017739798084416634\n",
      "train loss:0.0006244645937489187\n",
      "train loss:0.0027917175290486825\n",
      "train loss:0.0011970407061940617\n",
      "train loss:0.001201996213892309\n",
      "train loss:0.019001444483418152\n",
      "train loss:0.0005886333886637011\n",
      "train loss:0.0015030632303496575\n",
      "train loss:0.0018249477697713336\n",
      "train loss:0.009351695097502036\n",
      "train loss:0.005048919244065048\n",
      "train loss:0.0013645994334026957\n",
      "train loss:0.0026131085915676194\n",
      "train loss:0.0019902870549482485\n",
      "train loss:0.00447660393243336\n",
      "train loss:0.002130079197837706\n",
      "train loss:0.0021215030677625354\n",
      "train loss:0.0017539808958329352\n",
      "train loss:0.002013795889847228\n",
      "train loss:0.00294428292940907\n",
      "train loss:0.006511895081395195\n",
      "train loss:0.0032923496999722984\n",
      "train loss:0.0008406669228763898\n",
      "train loss:0.0009229032469419471\n",
      "train loss:0.004991872811421051\n",
      "train loss:0.009277290131632447\n",
      "train loss:0.011238580206592998\n",
      "train loss:0.0032440027705004527\n",
      "train loss:0.004344339645911283\n",
      "train loss:0.004183971613037403\n",
      "train loss:0.010433095067558951\n",
      "train loss:0.003926839623686308\n",
      "train loss:0.001974203683583995\n",
      "train loss:0.004076266097051051\n",
      "train loss:0.003234461971545405\n",
      "train loss:0.007025277613212287\n",
      "train loss:0.001452837211251927\n",
      "train loss:0.00024227139561062576\n",
      "train loss:0.0003107420423554184\n",
      "train loss:0.032930920870976856\n",
      "train loss:0.001505042062204797\n",
      "train loss:0.0008225763104177382\n",
      "train loss:0.0008115672893008805\n",
      "train loss:0.0005816643250219401\n",
      "train loss:0.02276991289801035\n",
      "train loss:0.004639474206747543\n",
      "train loss:0.0021694224602952644\n",
      "train loss:0.001792869544328804\n",
      "train loss:0.0008356903925487137\n",
      "train loss:0.003865171358920733\n",
      "train loss:0.0018141441495442415\n",
      "train loss:0.02837562966918561\n",
      "train loss:0.0015038568957080327\n",
      "train loss:0.0009935636790885318\n",
      "train loss:0.0003713251490308062\n",
      "train loss:0.0008679095987293066\n",
      "train loss:0.0021110839983623513\n",
      "train loss:0.0073273923234721434\n",
      "train loss:0.004773885834420687\n",
      "train loss:0.002877443708237769\n",
      "train loss:0.007053714236835305\n",
      "train loss:0.0031113215930674426\n",
      "train loss:0.006444909457629171\n",
      "train loss:0.0016269175964692217\n",
      "train loss:0.003927591907405864\n",
      "train loss:0.008833113814598465\n",
      "train loss:0.0009929981347471353\n",
      "train loss:0.004781023502262296\n",
      "train loss:0.007013438624525105\n",
      "train loss:0.0002388549454233805\n",
      "train loss:0.004009678030437878\n",
      "train loss:0.0030087027268239142\n",
      "train loss:0.0035393449259734293\n",
      "train loss:0.0033994509243085998\n",
      "train loss:0.0027526957083127764\n",
      "train loss:0.048253562398682434\n",
      "train loss:0.0006383827997145623\n",
      "train loss:0.0038195761994473856\n",
      "train loss:0.0015092375796621129\n",
      "train loss:0.020055410390679998\n",
      "train loss:0.004520098045659007\n",
      "train loss:0.002154319842909515\n",
      "train loss:0.0014777430895164744\n",
      "train loss:0.004024459675450867\n",
      "train loss:0.0017095075372421677\n",
      "train loss:0.0017661659075837949\n",
      "train loss:0.00528818382012099\n",
      "train loss:0.0010576503746945868\n",
      "train loss:0.0003519281877833357\n",
      "train loss:0.0017075063440452102\n",
      "train loss:0.004624133543080834\n",
      "train loss:0.0022523301191434966\n",
      "train loss:0.0023026239721972673\n",
      "train loss:0.005541020064715271\n",
      "train loss:0.00468349644666436\n",
      "train loss:0.006301422897015055\n",
      "train loss:0.0014421366876518826\n",
      "train loss:0.0013343613442676186\n",
      "train loss:0.0003609493245549078\n",
      "train loss:0.00032791345832058644\n",
      "train loss:0.00701667638077044\n",
      "train loss:0.002104638789024934\n",
      "train loss:0.012360758073375505\n",
      "train loss:0.0014384496135144854\n",
      "train loss:0.0030526704365210038\n",
      "train loss:0.0009811881412663218\n",
      "train loss:0.0006141889598536603\n",
      "train loss:0.0029477022464232823\n",
      "train loss:0.004065543154715139\n",
      "train loss:0.0010644380192093355\n",
      "train loss:0.002838616708120477\n",
      "train loss:0.0014069022188780908\n",
      "train loss:0.00043148842688907585\n",
      "train loss:0.000470974256200197\n",
      "train loss:0.0015221821061284482\n",
      "train loss:0.0008543649960293481\n",
      "train loss:0.0015117889008370974\n",
      "train loss:0.002151033013804976\n",
      "train loss:0.0002911183669219004\n",
      "train loss:0.013689347046942323\n",
      "train loss:0.0012902395188440583\n",
      "train loss:0.0032755838785046383\n",
      "train loss:0.0012611650852903875\n",
      "train loss:0.003927660482208019\n",
      "train loss:0.0003657951494530047\n",
      "train loss:0.003550713670267811\n",
      "train loss:0.00424217373449149\n",
      "train loss:0.0007649364954824263\n",
      "train loss:0.0010166612205236838\n",
      "train loss:0.0002322453605811687\n",
      "train loss:0.0007776052804184644\n",
      "train loss:0.0005066688996909917\n",
      "train loss:0.002171592966082449\n",
      "train loss:0.004125771429101402\n",
      "train loss:0.0045120128144917155\n",
      "train loss:0.0017048193420131212\n",
      "train loss:0.0006554915447621219\n",
      "train loss:0.0008417345641922893\n",
      "train loss:0.0009143395594246037\n",
      "train loss:0.0017088879895218385\n",
      "train loss:0.004543112425889806\n",
      "train loss:0.0003345535643009102\n",
      "train loss:0.006916164050407967\n",
      "train loss:0.0001562118319282051\n",
      "train loss:0.00033425917490770903\n",
      "train loss:0.001467988678158355\n",
      "train loss:0.0006448737816760321\n",
      "train loss:0.0022741035694503788\n",
      "train loss:0.0007358445837724931\n",
      "train loss:0.0004425900853657047\n",
      "train loss:0.003943553687720799\n",
      "train loss:0.00023640569814552677\n",
      "train loss:0.0009215550378743766\n",
      "train loss:0.0011582037518613547\n",
      "train loss:0.0014259065079629538\n",
      "train loss:0.003222388689128927\n",
      "train loss:0.001151764773605952\n",
      "train loss:0.0038200312795150355\n",
      "train loss:0.0003390902048890393\n",
      "train loss:0.0005103216113580744\n",
      "train loss:0.003728993722935899\n",
      "train loss:0.00320652784447275\n",
      "train loss:0.0012666917719105942\n",
      "train loss:0.0011559662625381215\n",
      "train loss:0.0012676863936875872\n",
      "train loss:0.0016190912633188073\n",
      "train loss:0.0005689770359512558\n",
      "train loss:0.008701931855435165\n",
      "train loss:0.005767290442811783\n",
      "train loss:0.0011424974936756927\n",
      "train loss:0.0014607190321880687\n",
      "train loss:0.00047498944910439537\n",
      "train loss:0.0058169119734517985\n",
      "train loss:0.004207668957969952\n",
      "train loss:0.0015504206055780927\n",
      "train loss:0.0024320993131462547\n",
      "train loss:0.0008598264208357268\n",
      "train loss:0.0021807905834233714\n",
      "train loss:0.0011329143970917718\n",
      "train loss:0.0005014654660032372\n",
      "train loss:0.006180042234505807\n",
      "train loss:0.003428605098097521\n",
      "train loss:0.0012143007283432255\n",
      "train loss:8.109540228910521e-05\n",
      "train loss:0.003654221619173505\n",
      "train loss:0.0003290898890735926\n",
      "train loss:0.0006881227885807735\n",
      "train loss:0.05993877579922236\n",
      "train loss:0.0024031702274213544\n",
      "train loss:0.002308228508757659\n",
      "train loss:0.00035762604494173414\n",
      "train loss:0.0020734525802211146\n",
      "train loss:0.0035012877293781543\n",
      "train loss:0.0021835712016812824\n",
      "train loss:0.0032029150653940463\n",
      "train loss:0.002031303611752991\n",
      "train loss:0.0016540849327531355\n",
      "train loss:0.0029860159038268136\n",
      "train loss:0.0019377862980691036\n",
      "train loss:0.0004842189616710764\n",
      "train loss:0.009005651392661082\n",
      "train loss:0.0005878454477474544\n",
      "train loss:0.0018816527302737702\n",
      "train loss:0.00329349674797772\n",
      "train loss:0.0015736470493349843\n",
      "train loss:0.0037134484914657408\n",
      "train loss:0.0017067325273319495\n",
      "train loss:0.004764643408347464\n",
      "train loss:0.0019634962661825126\n",
      "train loss:0.006262321228768008\n",
      "train loss:0.0006315910185805837\n",
      "train loss:0.0002195288774184209\n",
      "train loss:0.0021078626546465386\n",
      "train loss:0.00045510807123876805\n",
      "train loss:0.0014936721122857455\n",
      "train loss:0.007040480529447081\n",
      "train loss:0.001136116734848443\n",
      "train loss:0.001926506936383942\n",
      "train loss:0.0011161591669522721\n",
      "train loss:0.002605549261535201\n",
      "train loss:0.005111264462504143\n",
      "train loss:0.0018839703000175251\n",
      "train loss:0.002596725866624629\n",
      "train loss:0.009851563150399666\n",
      "train loss:0.0013878009384733433\n",
      "train loss:0.011027422378147913\n",
      "train loss:0.00033307763225189275\n",
      "train loss:0.0011188951769125351\n",
      "train loss:0.0034225520330741295\n",
      "train loss:0.0027733845361235126\n",
      "train loss:0.003324662310171146\n",
      "train loss:0.004717501722852109\n",
      "train loss:0.0007455777975527861\n",
      "train loss:0.0004956634766006317\n",
      "train loss:0.0017966034236905249\n",
      "train loss:0.0032693277199389325\n",
      "train loss:0.00016544509874554553\n",
      "train loss:0.0014626737878428533\n",
      "train loss:0.001416720898266988\n",
      "train loss:0.0018993949464499353\n",
      "train loss:0.002298408091465266\n",
      "train loss:0.0010035457852506787\n",
      "train loss:0.029531920587972896\n",
      "train loss:0.0008747031599743147\n",
      "train loss:0.0017051328569038563\n",
      "train loss:0.0001876171949424748\n",
      "train loss:0.0005647428868588605\n",
      "train loss:0.002532281168635847\n",
      "train loss:0.0007356327026478178\n",
      "train loss:0.005299438033753285\n",
      "train loss:0.008303979168636072\n",
      "train loss:0.0006593291519260691\n",
      "train loss:0.0008939595732478192\n",
      "train loss:0.0004600601516812381\n",
      "train loss:0.0026830809473708467\n",
      "train loss:0.00014745023615614185\n",
      "train loss:0.0006010199690625937\n",
      "train loss:0.002457015694427443\n",
      "train loss:0.002077221929482725\n",
      "train loss:0.0008207057112013075\n",
      "train loss:0.004477955120624174\n",
      "train loss:0.0021158746371689676\n",
      "train loss:0.0020740741803764538\n",
      "train loss:0.0007907144370773801\n",
      "train loss:0.001956496986082977\n",
      "train loss:0.005814285401677964\n",
      "train loss:0.010890990204793253\n",
      "train loss:0.0010450226643677267\n",
      "train loss:0.0003978466691821691\n",
      "train loss:0.0010785217506304782\n",
      "train loss:0.002092601915941964\n",
      "train loss:0.010193744486691213\n",
      "train loss:0.0013205674139084367\n",
      "train loss:0.0022832090002666986\n",
      "train loss:0.0038587756817519757\n",
      "train loss:0.0017557509040736564\n",
      "train loss:0.004673607004785679\n",
      "train loss:0.0025986633054251433\n",
      "train loss:0.001148486486058234\n",
      "train loss:0.001117367446857114\n",
      "train loss:0.0008262231311969167\n",
      "train loss:0.002825379666179102\n",
      "train loss:0.005092479226581969\n",
      "train loss:0.02386217440489951\n",
      "train loss:0.0024728941203120696\n",
      "train loss:0.0025565312521599087\n",
      "train loss:0.0004657941655946073\n",
      "train loss:0.0014277010893271446\n",
      "train loss:0.0015808038690867418\n",
      "train loss:0.00039441244570851704\n",
      "train loss:0.0039476304888124945\n",
      "train loss:0.0003503574928206725\n",
      "train loss:0.006042332371516871\n",
      "train loss:0.0010707277431114305\n",
      "train loss:0.0006684665415881871\n",
      "train loss:0.0009783662201775462\n",
      "train loss:0.002574838481271003\n",
      "train loss:0.00027857636151930706\n",
      "train loss:0.012885910201369356\n",
      "train loss:0.002499819400152581\n",
      "train loss:0.0012298638768475174\n",
      "train loss:0.0004507640985434428\n",
      "train loss:0.02857460136919708\n",
      "train loss:0.00030594915719152056\n",
      "train loss:0.0014730893455239002\n",
      "train loss:0.01897715779630544\n",
      "train loss:0.024878297047908327\n",
      "train loss:0.0005996266483144475\n",
      "train loss:0.0032121385277342294\n",
      "train loss:0.0004084810749403178\n",
      "train loss:0.001219498700782508\n",
      "train loss:0.005610712640220445\n",
      "train loss:0.009189854838760239\n",
      "train loss:0.011758132142585807\n",
      "train loss:0.026343744025317785\n",
      "train loss:0.009206405050298214\n",
      "train loss:0.013544808047702868\n",
      "train loss:0.0019346922066592468\n",
      "train loss:0.00025923799143114047\n",
      "train loss:0.0007648305217972208\n",
      "train loss:0.004199102195012944\n",
      "train loss:0.0006098689115338226\n",
      "train loss:0.0035068027427511083\n",
      "train loss:0.0007646023364585677\n",
      "train loss:0.001544528507042264\n",
      "train loss:0.0005274403346462311\n",
      "train loss:0.004569933959071857\n",
      "train loss:0.00356753613797884\n",
      "train loss:0.0006861747402439257\n",
      "train loss:0.0033400610438497863\n",
      "train loss:0.001099802238985525\n",
      "train loss:0.01501508335380705\n",
      "train loss:0.00555843838054875\n",
      "train loss:0.005560724870991398\n",
      "train loss:0.0011393237247309478\n",
      "train loss:0.0029778752217101286\n",
      "train loss:0.0008816054890777319\n",
      "train loss:0.00468966760892397\n",
      "train loss:0.0008087789620474684\n",
      "train loss:0.0011648455390069609\n",
      "train loss:0.0008512108913430609\n",
      "train loss:0.0005506728636519615\n",
      "train loss:0.00033730203613063266\n",
      "train loss:0.001850671015543019\n",
      "train loss:0.01033278802414497\n",
      "train loss:0.0011192357226367286\n",
      "train loss:0.0014412956885693814\n",
      "train loss:0.0041551897661157\n",
      "train loss:0.00026763954131032037\n",
      "train loss:0.0022387873086294886\n",
      "train loss:0.0025428280967939886\n",
      "train loss:0.007777093134460364\n",
      "train loss:0.004818278961165973\n",
      "train loss:0.0003210449414109537\n",
      "train loss:0.0009598610905729438\n",
      "train loss:0.007843568280053647\n",
      "train loss:0.001202019861199678\n",
      "train loss:0.004138987479415127\n",
      "train loss:0.00040905058367869847\n",
      "train loss:0.002882537280030503\n",
      "train loss:0.0009132390679256614\n",
      "train loss:0.0025999920727684447\n",
      "train loss:0.0008411668819734985\n",
      "train loss:0.009743149760701198\n",
      "train loss:0.0007557171049325912\n",
      "train loss:0.0016076421147315847\n",
      "train loss:0.0010263322532420185\n",
      "train loss:0.00308845833631998\n",
      "train loss:0.00030822284414455453\n",
      "train loss:0.0037217334929984186\n",
      "train loss:0.0008697231951834188\n",
      "train loss:0.00031783227044846325\n",
      "train loss:0.0012943360541947996\n",
      "train loss:0.0010660837036121041\n",
      "train loss:0.00235299724673732\n",
      "train loss:0.0015281382395947013\n",
      "train loss:0.0009083426037066934\n",
      "train loss:0.0008598866037992241\n",
      "train loss:0.00023111250220882363\n",
      "train loss:0.0005125208735253759\n",
      "train loss:0.004549614290643266\n",
      "train loss:0.00266840625180441\n",
      "train loss:0.0003235549482380064\n",
      "train loss:0.0013323639068105462\n",
      "train loss:0.006766182491733945\n",
      "train loss:0.0028532743154682334\n",
      "train loss:0.003061427918071431\n",
      "train loss:0.0007491436006791064\n",
      "train loss:0.004791203528047071\n",
      "train loss:0.0012307301973563457\n",
      "train loss:0.00047513508366729934\n",
      "train loss:0.001646820815185272\n",
      "train loss:0.00588242420181884\n",
      "train loss:0.0016985083936061013\n",
      "train loss:0.0002027498254317927\n",
      "train loss:0.0013540236829523026\n",
      "train loss:0.00027646798714808557\n",
      "train loss:0.003239597353526883\n",
      "train loss:0.02508088206376564\n",
      "train loss:0.001034352489561725\n",
      "train loss:0.004493395190009897\n",
      "train loss:0.0013881963377670797\n",
      "train loss:0.004070580360751703\n",
      "train loss:0.00435695676694336\n",
      "train loss:0.005417210746735124\n",
      "train loss:0.004304657531774661\n",
      "train loss:0.0031361741221293095\n",
      "train loss:0.007138274291840236\n",
      "train loss:0.0001424498295200351\n",
      "train loss:0.0004871948654403529\n",
      "train loss:0.002912362306383732\n",
      "train loss:0.0007411964331834216\n",
      "train loss:0.0008170778716461311\n",
      "train loss:8.610223103964676e-05\n",
      "train loss:0.0004563574589441833\n",
      "train loss:0.004948592169404604\n",
      "train loss:0.005902238260469796\n",
      "train loss:0.06950514877576625\n",
      "train loss:0.0010293837554515369\n",
      "train loss:0.00115477319769345\n",
      "train loss:0.0035818313394032275\n",
      "train loss:0.002339413401896527\n",
      "train loss:0.004083391612548203\n",
      "train loss:0.026659570155411476\n",
      "train loss:0.002939344365507962\n",
      "train loss:0.002725335609548441\n",
      "train loss:0.004518531161870992\n",
      "train loss:0.005582688867354917\n",
      "train loss:0.08218836627546511\n",
      "train loss:0.002485217775051509\n",
      "train loss:0.005054367704496392\n",
      "train loss:0.0033857913300101893\n",
      "train loss:0.0004865348125161345\n",
      "train loss:0.0019085238650014763\n",
      "train loss:0.0005525146756604793\n",
      "train loss:0.013017180621985005\n",
      "train loss:0.005634685030102745\n",
      "train loss:0.0016277342016971029\n",
      "train loss:0.0090098712104345\n",
      "train loss:0.009244210032988035\n",
      "train loss:0.0006780407723144562\n",
      "train loss:0.017560527703591483\n",
      "train loss:0.0005494000881143778\n",
      "train loss:0.005289048361458632\n",
      "train loss:0.0037011034407345546\n",
      "train loss:0.0008082401213752413\n",
      "train loss:0.002199963824117456\n",
      "train loss:0.005287869456468074\n",
      "train loss:0.0022103904309148993\n",
      "train loss:0.002324711625033104\n",
      "train loss:0.013497351337678936\n",
      "train loss:0.0028216849499617873\n",
      "train loss:0.001088521661841117\n",
      "train loss:0.0005511904429387921\n",
      "train loss:0.004216436481175004\n",
      "train loss:0.003313997105963033\n",
      "train loss:0.004668529079574626\n",
      "train loss:0.0006413420727212909\n",
      "train loss:0.0013210393489028042\n",
      "train loss:0.0014093066807799404\n",
      "train loss:0.008684579371467183\n",
      "train loss:0.004398378901198167\n",
      "train loss:0.002948688894817673\n",
      "train loss:0.0038630394432480125\n",
      "train loss:0.002497430248320099\n",
      "train loss:0.0035541744189304444\n",
      "train loss:0.00483219611835831\n",
      "train loss:0.0024388706589251368\n",
      "train loss:0.0004244149373966126\n",
      "train loss:0.008523185214199223\n",
      "train loss:0.0019279817523770284\n",
      "train loss:0.0038763482803842097\n",
      "train loss:0.013615351707396044\n",
      "train loss:0.004370126250506385\n",
      "train loss:0.00030424792739442216\n",
      "train loss:0.0029748982441512796\n",
      "train loss:0.0004765757565908397\n",
      "train loss:0.00359013167564613\n",
      "train loss:0.0018901052780686397\n",
      "train loss:0.0011639300581299517\n",
      "train loss:0.013590247019159694\n",
      "train loss:0.0007423490761339198\n",
      "train loss:0.001540170282393491\n",
      "train loss:0.00019359642128486732\n",
      "train loss:0.001324120920717313\n",
      "train loss:0.0045487256202587905\n",
      "train loss:0.002135471412864011\n",
      "train loss:0.003056100801733846\n",
      "train loss:0.004218878659099031\n",
      "train loss:0.0030823335890964284\n",
      "train loss:0.0009869646514354537\n",
      "train loss:0.00042921666192449347\n",
      "train loss:0.0012800334449241837\n",
      "train loss:0.0008179530020113958\n",
      "train loss:0.000729811354479277\n",
      "train loss:0.005028637319303292\n",
      "train loss:0.0012420764500799659\n",
      "train loss:0.016561646968034086\n",
      "train loss:0.0017269467381316006\n",
      "train loss:0.0008793200357449258\n",
      "train loss:0.0027686378207312855\n",
      "train loss:0.0044696139179482425\n",
      "train loss:0.007600712362092723\n",
      "train loss:0.0019393052119450623\n",
      "train loss:0.006899889202026766\n",
      "train loss:0.0015530039508957565\n",
      "train loss:0.010393973773161052\n",
      "train loss:0.0032715866223351343\n",
      "train loss:0.001217005449035588\n",
      "train loss:0.004455197418690245\n",
      "train loss:0.0016487073667842147\n",
      "train loss:0.00035268814931562387\n",
      "train loss:0.00935052168855607\n",
      "train loss:0.002635695122912901\n",
      "train loss:0.0009546070337942497\n",
      "train loss:0.004822186910899266\n",
      "train loss:0.0007586849310352585\n",
      "train loss:0.002109457448635682\n",
      "train loss:0.001143683575340577\n",
      "train loss:0.02090737835760993\n",
      "train loss:0.0006722280138642486\n",
      "train loss:0.004783098227100023\n",
      "train loss:0.015196275224734166\n",
      "train loss:0.006969933630107338\n",
      "train loss:0.0013778799578509568\n",
      "train loss:0.0025087711010978748\n",
      "train loss:0.005477360242474277\n",
      "train loss:0.00242918487577198\n",
      "train loss:0.00786293024743816\n",
      "train loss:0.0013671045690614246\n",
      "train loss:0.007899901264357027\n",
      "train loss:0.00341134447787982\n",
      "train loss:0.0011826359605298152\n",
      "train loss:0.0009748656967782058\n",
      "train loss:0.0012498864081875885\n",
      "train loss:0.0014915330646667626\n",
      "train loss:0.011855158861991977\n",
      "train loss:0.03189503236589953\n",
      "train loss:0.002951762099192565\n",
      "train loss:0.0030276465500235373\n",
      "train loss:0.009888054377867285\n",
      "train loss:0.0014199711883545235\n",
      "train loss:0.0018119895306029164\n",
      "train loss:0.00044477958817628157\n",
      "train loss:0.012666492831487687\n",
      "train loss:0.0012228329480229124\n",
      "train loss:0.002433975733013111\n",
      "train loss:0.0011082944032268216\n",
      "train loss:0.0022229268804327203\n",
      "train loss:0.0003210362221891306\n",
      "train loss:0.000494509218417116\n",
      "train loss:0.0029295136401733496\n",
      "train loss:0.0036610065816674205\n",
      "train loss:0.00046819450819919536\n",
      "train loss:0.0002365319549461839\n",
      "train loss:0.0062298958332455716\n",
      "train loss:0.006344153232400936\n",
      "train loss:0.00029376691148653387\n",
      "train loss:0.0005077744578482845\n",
      "train loss:0.0008985353306052603\n",
      "train loss:0.001206772557072978\n",
      "train loss:0.004037356425121447\n",
      "train loss:0.0026206551106535327\n",
      "train loss:0.0031469564820224122\n",
      "train loss:0.0012871955490359496\n",
      "train loss:0.003737124571596964\n",
      "train loss:0.0014262729696577494\n",
      "train loss:0.0006098053902910285\n",
      "train loss:0.0012910515512702984\n",
      "train loss:0.0011332176744931733\n",
      "train loss:0.0012000097971442995\n",
      "train loss:0.0003982226753946768\n",
      "train loss:0.0013409341706215742\n",
      "train loss:0.004484221290358419\n",
      "=== epoch:14, train acc:0.998, test acc:0.99 ===\n",
      "train loss:0.001552486300278498\n",
      "train loss:0.004065892103808386\n",
      "train loss:0.003855773626054081\n",
      "train loss:0.0011814127671144483\n",
      "train loss:0.0011262150260839315\n",
      "train loss:0.0013299823870034473\n",
      "train loss:0.006478756880433228\n",
      "train loss:0.0009768476794412\n",
      "train loss:0.00028048944586287107\n",
      "train loss:0.0008808998233097834\n",
      "train loss:0.0014974199287775775\n",
      "train loss:0.00105670441710053\n",
      "train loss:0.012402236629501084\n",
      "train loss:0.0006817982977036192\n",
      "train loss:0.0005561872120557844\n",
      "train loss:0.005195201935875191\n",
      "train loss:0.0003126200199179057\n",
      "train loss:0.004162831009319462\n",
      "train loss:0.001083308838954828\n",
      "train loss:0.0005357761579632262\n",
      "train loss:0.011721393678442653\n",
      "train loss:0.006203588059083601\n",
      "train loss:0.0018712857727535982\n",
      "train loss:0.0015147108230216344\n",
      "train loss:0.004068401576097342\n",
      "train loss:0.00175695794587021\n",
      "train loss:0.00606295917966321\n",
      "train loss:0.007004248641555613\n",
      "train loss:0.0010716838708536057\n",
      "train loss:0.0004901235170963137\n",
      "train loss:0.0018616234322900301\n",
      "train loss:0.0015081298327387432\n",
      "train loss:0.004269341542556134\n",
      "train loss:0.002387131319414781\n",
      "train loss:0.00048099080523453653\n",
      "train loss:0.00024706189256631846\n",
      "train loss:0.0006162350849563167\n",
      "train loss:0.0013442370279894544\n",
      "train loss:0.003489256716186784\n",
      "train loss:0.01460730287465288\n",
      "train loss:0.005567377941338523\n",
      "train loss:0.0005514919668795773\n",
      "train loss:0.002256396937497603\n",
      "train loss:0.0006175631289239225\n",
      "train loss:0.0023606282805749995\n",
      "train loss:0.0007926708734140581\n",
      "train loss:0.004168864149254718\n",
      "train loss:0.0019763410871052826\n",
      "train loss:0.0010946344458631554\n",
      "train loss:0.0016321726313296627\n",
      "train loss:0.0033357923570100988\n",
      "train loss:0.002066971355336742\n",
      "train loss:0.006785963936087186\n",
      "train loss:0.0046990370830513484\n",
      "train loss:0.002226282985838341\n",
      "train loss:0.001292507506039229\n",
      "train loss:0.004002773804668697\n",
      "train loss:0.003581859549776941\n",
      "train loss:0.002860989149320959\n",
      "train loss:0.0014253661990434614\n",
      "train loss:0.001172358434578879\n",
      "train loss:0.005353613192289752\n",
      "train loss:0.0005003083154149733\n",
      "train loss:0.0010506164773799514\n",
      "train loss:0.0010248865832186366\n",
      "train loss:0.00793951229393424\n",
      "train loss:0.0023343340680527618\n",
      "train loss:0.00042889109108986973\n",
      "train loss:0.00025817076656490335\n",
      "train loss:0.003136875173030944\n",
      "train loss:0.00041277427636196497\n",
      "train loss:0.010290021686179866\n",
      "train loss:6.254633679343973e-05\n",
      "train loss:0.004161603998797312\n",
      "train loss:0.0013451706207308236\n",
      "train loss:0.009125710283513312\n",
      "train loss:0.002185960030998462\n",
      "train loss:0.00015004179010427742\n",
      "train loss:0.0007916025429171818\n",
      "train loss:0.0022262021965391426\n",
      "train loss:0.006947412185720187\n",
      "train loss:0.004886873243169063\n",
      "train loss:0.0001388296755798257\n",
      "train loss:0.004640904013069339\n",
      "train loss:0.0008737019626225842\n",
      "train loss:0.014086002513502748\n",
      "train loss:0.002130558910837411\n",
      "train loss:0.006637872859051986\n",
      "train loss:0.0012522614026924217\n",
      "train loss:0.008146039293226012\n",
      "train loss:0.0005143824234057262\n",
      "train loss:0.0008959189768842023\n",
      "train loss:0.0007315789637079251\n",
      "train loss:0.0021553435844034476\n",
      "train loss:0.000586995767028281\n",
      "train loss:0.0015400968137375573\n",
      "train loss:0.004848771796788828\n",
      "train loss:0.00844853050810296\n",
      "train loss:0.00015598465888776113\n",
      "train loss:0.0011142459038565018\n",
      "train loss:0.004906072279989644\n",
      "train loss:0.006461379757597499\n",
      "train loss:0.001571059795987262\n",
      "train loss:0.001106591092188437\n",
      "train loss:0.0017405693289230418\n",
      "train loss:0.000746683250221364\n",
      "train loss:0.010949368635657115\n",
      "train loss:0.0020543788262689707\n",
      "train loss:0.007749886894834357\n",
      "train loss:0.000692122952160742\n",
      "train loss:0.0018025494458211461\n",
      "train loss:0.002026691939434843\n",
      "train loss:0.002321240807828419\n",
      "train loss:0.000892393545142159\n",
      "train loss:0.000492068025361558\n",
      "train loss:0.0021549551239154986\n",
      "train loss:0.0028410899376839697\n",
      "train loss:0.003651146566306066\n",
      "train loss:0.015955757727424406\n",
      "train loss:0.0086556683320058\n",
      "train loss:0.00047864012832225447\n",
      "train loss:0.002543372687445468\n",
      "train loss:0.0014350590569763907\n",
      "train loss:0.0017143822779608915\n",
      "train loss:0.01693243806226995\n",
      "train loss:0.007461297400692971\n",
      "train loss:0.0013846797710879116\n",
      "train loss:0.0016122623147181128\n",
      "train loss:0.0001521999671054863\n",
      "train loss:8.139099968871202e-05\n",
      "train loss:0.004387696342443355\n",
      "train loss:0.0025961385821286105\n",
      "train loss:0.0022643283780308977\n",
      "train loss:0.0008737014916469678\n",
      "train loss:0.006264462462374648\n",
      "train loss:0.0007037458013160027\n",
      "train loss:0.00024147458440911776\n",
      "train loss:0.00019365246745800025\n",
      "train loss:0.002910720280109358\n",
      "train loss:0.002479786508753094\n",
      "train loss:0.001383137332082712\n",
      "train loss:0.02100758011934526\n",
      "train loss:0.0020176241977104756\n",
      "train loss:0.0033277761644371308\n",
      "train loss:0.002436906340031365\n",
      "train loss:0.0007360068399565607\n",
      "train loss:0.0013988128638584907\n",
      "train loss:0.002998382076127614\n",
      "train loss:0.003290326972402788\n",
      "train loss:0.005203396311577806\n",
      "train loss:0.005006804567022176\n",
      "train loss:0.0007461176922978406\n",
      "train loss:0.00352818236237057\n",
      "train loss:0.0029830677926952166\n",
      "train loss:0.0007387357386805029\n",
      "train loss:0.012850194451877113\n",
      "train loss:0.0009870831485080962\n",
      "train loss:0.0035003929718486425\n",
      "train loss:0.0026625670251774858\n",
      "train loss:0.0038812845456771324\n",
      "train loss:0.00014164672521960574\n",
      "train loss:0.0008975675102049869\n",
      "train loss:0.0003781087798753819\n",
      "train loss:0.0019267070728547673\n",
      "train loss:0.002966696308673379\n",
      "train loss:0.0010282740935471121\n",
      "train loss:0.0007819410698779027\n",
      "train loss:0.0003593783877156642\n",
      "train loss:0.00207643157894811\n",
      "train loss:0.001210410114581393\n",
      "train loss:0.004631510183062442\n",
      "train loss:0.020185036735804122\n",
      "train loss:0.004636030520289991\n",
      "train loss:0.0012115231352806176\n",
      "train loss:0.0026961614848014935\n",
      "train loss:0.00027017532590572075\n",
      "train loss:0.006306066997517628\n",
      "train loss:0.0016503275997664976\n",
      "train loss:0.0001410568225731818\n",
      "train loss:0.0022747271555354034\n",
      "train loss:0.0008644354532349434\n",
      "train loss:0.0007048147932780346\n",
      "train loss:0.014333311311028066\n",
      "train loss:0.004049573120546\n",
      "train loss:0.00769830635368842\n",
      "train loss:0.013938930762720281\n",
      "train loss:0.0005411342165543452\n",
      "train loss:0.003699133940613959\n",
      "train loss:0.0008868413553740152\n",
      "train loss:0.0009504865931397849\n",
      "train loss:0.08396948136167064\n",
      "train loss:0.0013521643888531518\n",
      "train loss:0.002884103345290275\n",
      "train loss:0.001467802116928556\n",
      "train loss:0.004331590926918915\n",
      "train loss:0.00011545680513386622\n",
      "train loss:0.012075305415601305\n",
      "train loss:0.002000850688595985\n",
      "train loss:0.00016307999889104377\n",
      "train loss:0.00412155239449143\n",
      "train loss:0.0062537991335055035\n",
      "train loss:0.0047963683058101884\n",
      "train loss:0.001450583839190141\n",
      "train loss:0.0037293877003379675\n",
      "train loss:0.0017596430355856646\n",
      "train loss:0.002695300911281758\n",
      "train loss:0.051275199351894514\n",
      "train loss:0.002557661963227855\n",
      "train loss:0.0008108030669451829\n",
      "train loss:0.004602852193701934\n",
      "train loss:0.0023573753850514865\n",
      "train loss:0.005911329504718243\n",
      "train loss:0.002237679164400493\n",
      "train loss:0.003692521050361999\n",
      "train loss:0.0010949920804992146\n",
      "train loss:0.006330757017778239\n",
      "train loss:0.002320483993322421\n",
      "train loss:0.0007057359540602564\n",
      "train loss:0.0006485271425620379\n",
      "train loss:0.0013775297791247668\n",
      "train loss:0.003874926263530037\n",
      "train loss:0.0031054608785119468\n",
      "train loss:0.07989903811980664\n",
      "train loss:0.007206146489926214\n",
      "train loss:0.0020694518852867527\n",
      "train loss:0.003242008237012234\n",
      "train loss:0.001165965149823179\n",
      "train loss:0.0005733068751014096\n",
      "train loss:0.002879759135212218\n",
      "train loss:0.0018578714778347757\n",
      "train loss:0.014085009755472612\n",
      "train loss:0.006419173144109625\n",
      "train loss:0.0030339741559781194\n",
      "train loss:0.001722888998808592\n",
      "train loss:0.0031668137298607683\n",
      "train loss:0.008678688439279022\n",
      "train loss:0.0027318422212742905\n",
      "train loss:0.0009487969333999358\n",
      "train loss:0.002539596047227122\n",
      "train loss:0.002885809020694992\n",
      "train loss:0.0015626028470212686\n",
      "train loss:0.001642864245133891\n",
      "train loss:0.0003960425963958387\n",
      "train loss:0.0008912164668697066\n",
      "train loss:0.00200562583524815\n",
      "train loss:0.00153499030679346\n",
      "train loss:0.00023466173001870802\n",
      "train loss:0.00022842306462016727\n",
      "train loss:0.0013007108995462895\n",
      "train loss:0.011644692677526346\n",
      "train loss:0.0006973641500923091\n",
      "train loss:0.0018752979975385257\n",
      "train loss:0.001379871946259318\n",
      "train loss:0.0005076962207533819\n",
      "train loss:0.0008783606475972067\n",
      "train loss:0.0003389918642671445\n",
      "train loss:0.003105971187640474\n",
      "train loss:0.0016398434626128627\n",
      "train loss:0.00013321428894019953\n",
      "train loss:0.0009329693402821357\n",
      "train loss:0.004515754920978318\n",
      "train loss:0.00042666716531915825\n",
      "train loss:0.001408419947205423\n",
      "train loss:0.0037447174621534703\n",
      "train loss:0.0006654907335461636\n",
      "train loss:0.0014198046962737325\n",
      "train loss:0.000903110597723942\n",
      "train loss:0.0012546952465290148\n",
      "train loss:0.0005505967675188726\n",
      "train loss:0.006664382245196218\n",
      "train loss:0.0024305579462158646\n",
      "train loss:0.00235340454419356\n",
      "train loss:0.0004589875439953176\n",
      "train loss:0.0013503161035350064\n",
      "train loss:0.007234395447603284\n",
      "train loss:0.00041589310182944984\n",
      "train loss:0.006860244040735974\n",
      "train loss:0.0008022539079755166\n",
      "train loss:0.001986749658019469\n",
      "train loss:0.004119337740600354\n",
      "train loss:0.01583011773588677\n",
      "train loss:0.00030421087713215116\n",
      "train loss:0.0020593645537279924\n",
      "train loss:0.006031701783928688\n",
      "train loss:0.00014846994167037162\n",
      "train loss:0.0007485115019486361\n",
      "train loss:0.0035017326586694623\n",
      "train loss:0.013869167285689838\n",
      "train loss:0.0011799624723509887\n",
      "train loss:0.0011243685405320798\n",
      "train loss:0.017948016896999444\n",
      "train loss:0.0005677215800346963\n",
      "train loss:0.002494509457501869\n",
      "train loss:0.009870111609988219\n",
      "train loss:0.00041540583901384244\n",
      "train loss:0.00507942903303283\n",
      "train loss:0.0009264708617780817\n",
      "train loss:0.005511766438103076\n",
      "train loss:0.001564831081535619\n",
      "train loss:0.0008028255153448255\n",
      "train loss:0.0034627293826873253\n",
      "train loss:0.0007051260580051983\n",
      "train loss:0.0008346896954054345\n",
      "train loss:0.0008382469115996518\n",
      "train loss:0.0007337877685087995\n",
      "train loss:0.0008870258360675718\n",
      "train loss:0.007326175227283349\n",
      "train loss:0.014375314345721108\n",
      "train loss:0.0004289218796053472\n",
      "train loss:0.005266732543624543\n",
      "train loss:0.00018708260054663595\n",
      "train loss:0.0008215978480498094\n",
      "train loss:0.0002473982610789061\n",
      "train loss:0.0011254546276275616\n",
      "train loss:0.00147557508796086\n",
      "train loss:0.00024041464122693046\n",
      "train loss:0.0011263130344552235\n",
      "train loss:0.004569306183241005\n",
      "train loss:0.0028260944692571495\n",
      "train loss:0.0016530683274255595\n",
      "train loss:0.003101534596311341\n",
      "train loss:0.0026190883255529426\n",
      "train loss:0.0013097762889888718\n",
      "train loss:0.0006431828107984082\n",
      "train loss:0.0007590023461300565\n",
      "train loss:0.00428021840799659\n",
      "train loss:0.005664908273297822\n",
      "train loss:0.0009887324621125901\n",
      "train loss:0.01949787722803868\n",
      "train loss:0.0030502548811509665\n",
      "train loss:0.0004425294437165003\n",
      "train loss:0.00040089431023774066\n",
      "train loss:0.0007403216811604761\n",
      "train loss:0.0018588644204166496\n",
      "train loss:0.0044346009178847165\n",
      "train loss:0.005074728468578909\n",
      "train loss:0.0005905649769646692\n",
      "train loss:0.012215367741623793\n",
      "train loss:0.0008998556286274557\n",
      "train loss:0.0021711299932308734\n",
      "train loss:0.0023002158560849364\n",
      "train loss:0.0001774741503200649\n",
      "train loss:0.003779737657971127\n",
      "train loss:0.0003850303653575812\n",
      "train loss:0.0004314914275679333\n",
      "train loss:0.00036006263214698186\n",
      "train loss:0.0008630088397550299\n",
      "train loss:0.0001995054241875044\n",
      "train loss:0.0026216053356840525\n",
      "train loss:0.0017668857244209748\n",
      "train loss:0.00016994256863961044\n",
      "train loss:0.001327330206711575\n",
      "train loss:0.0038843416140393306\n",
      "train loss:0.0016044944097544276\n",
      "train loss:0.0015007552607741229\n",
      "train loss:0.0023778010712747124\n",
      "train loss:0.0009305668742824194\n",
      "train loss:0.0027055331105327813\n",
      "train loss:0.000861548109348805\n",
      "train loss:0.0008211702154242591\n",
      "train loss:0.0006765511880193858\n",
      "train loss:0.0030164865490236153\n",
      "train loss:0.0022498430390665695\n",
      "train loss:0.0012476418732171048\n",
      "train loss:0.003834248782624055\n",
      "train loss:0.0012209038628694787\n",
      "train loss:0.006738535073834947\n",
      "train loss:0.0001145357177607429\n",
      "train loss:0.0036172595755989893\n",
      "train loss:0.0029942430658835817\n",
      "train loss:0.0002832857120675164\n",
      "train loss:0.0005045863099208243\n",
      "train loss:0.001145402473753351\n",
      "train loss:0.002470577468123694\n",
      "train loss:0.003209578849876456\n",
      "train loss:0.04415584226276268\n",
      "train loss:0.0010697352094108646\n",
      "train loss:0.004528620584113804\n",
      "train loss:0.0008698987450947236\n",
      "train loss:0.001312621998875676\n",
      "train loss:0.02122071840035067\n",
      "train loss:0.0027064625092478646\n",
      "train loss:0.0239028194523095\n",
      "train loss:0.11603915634854425\n",
      "train loss:0.0006466101495860204\n",
      "train loss:0.0005333436220072425\n",
      "train loss:0.0018372497541522894\n",
      "train loss:0.0026171572452498865\n",
      "train loss:0.004026542914792696\n",
      "train loss:0.04326125047060132\n",
      "train loss:0.008917022502906687\n",
      "train loss:0.012702724480904714\n",
      "train loss:0.0005653972887457191\n",
      "train loss:0.005098102417912384\n",
      "train loss:0.025387265663896406\n",
      "train loss:0.0057052818667622076\n",
      "train loss:0.0011239184040852208\n",
      "train loss:0.0031316525193539144\n",
      "train loss:0.013247560528516887\n",
      "train loss:0.003201754401033349\n",
      "train loss:0.00010764107662143654\n",
      "train loss:0.010645892464526664\n",
      "train loss:0.0041844833461590295\n",
      "train loss:0.010374445562065548\n",
      "train loss:0.003613150310078539\n",
      "train loss:0.008191179745147983\n",
      "train loss:0.0016961145278209693\n",
      "train loss:0.003420843284961131\n",
      "train loss:0.0013356722343145682\n",
      "train loss:0.003972324491180844\n",
      "train loss:0.008286118676661899\n",
      "train loss:0.00013219913362480274\n",
      "train loss:0.0030584734127712026\n",
      "train loss:0.013975674811375023\n",
      "train loss:0.014270883990004184\n",
      "train loss:0.018347417052084238\n",
      "train loss:0.0025763146007689204\n",
      "train loss:0.0009296001418945326\n",
      "train loss:0.0026844541589439975\n",
      "train loss:0.0020220508141832196\n",
      "train loss:0.007861089955434912\n",
      "train loss:0.017411654239490804\n",
      "train loss:0.0006755304451334034\n",
      "train loss:0.00041721581199440934\n",
      "train loss:7.139023381982986e-05\n",
      "train loss:0.006319090848348111\n",
      "train loss:0.002017731331536973\n",
      "train loss:0.003342083141429506\n",
      "train loss:0.009569574469269884\n",
      "train loss:0.0005343915048462333\n",
      "train loss:0.002392907026995182\n",
      "train loss:0.021276505729366995\n",
      "train loss:0.002324596280090457\n",
      "train loss:0.0020241284351419993\n",
      "train loss:0.0009986330328419946\n",
      "train loss:0.0015227994471135313\n",
      "train loss:0.0055220533063025535\n",
      "train loss:0.023443126094171488\n",
      "train loss:0.007744311955543175\n",
      "train loss:0.0006276645180928887\n",
      "train loss:0.00039152446013559355\n",
      "train loss:0.00018407020026683845\n",
      "train loss:0.004359898289493658\n",
      "train loss:0.002007916924080717\n",
      "train loss:0.0019226947696530383\n",
      "train loss:0.0034180882491565328\n",
      "train loss:0.00014039240821298567\n",
      "train loss:0.007208147046446809\n",
      "train loss:0.005945600697306167\n",
      "train loss:0.008015602098611104\n",
      "train loss:0.007822245073312646\n",
      "train loss:0.0017412375802339955\n",
      "train loss:0.0018650215891597832\n",
      "train loss:0.00450658151303291\n",
      "train loss:0.004181611590623268\n",
      "train loss:0.0023386628056218726\n",
      "train loss:0.00032551799050448675\n",
      "train loss:0.0012090187073250272\n",
      "train loss:0.0009685891661914272\n",
      "train loss:0.0020148662088274438\n",
      "train loss:0.004195542159710839\n",
      "train loss:0.024076997790955606\n",
      "train loss:0.0028791365225062427\n",
      "train loss:0.0008277429171202026\n",
      "train loss:0.01239184083932546\n",
      "train loss:0.0021475010079023407\n",
      "train loss:0.007078391513945952\n",
      "train loss:0.00035150382063192903\n",
      "train loss:0.0036652390896833916\n",
      "train loss:0.0011791025067830667\n",
      "train loss:0.0016666047897460259\n",
      "train loss:0.003056349235416102\n",
      "train loss:0.0015716133270670468\n",
      "train loss:0.010033734605183206\n",
      "train loss:0.002206479159624222\n",
      "train loss:0.004662909401161556\n",
      "train loss:0.0009408258441317946\n",
      "train loss:0.0019492125496451118\n",
      "train loss:0.0017040629937463388\n",
      "train loss:0.0024636560911636576\n",
      "train loss:0.001645458423814909\n",
      "train loss:0.000985532868706222\n",
      "train loss:0.002128929780283122\n",
      "train loss:0.003708186787344317\n",
      "train loss:0.0013018892914121128\n",
      "train loss:0.0013627291639774592\n",
      "train loss:0.04368541235141812\n",
      "train loss:0.0004614436598492225\n",
      "train loss:0.0014762133658441008\n",
      "train loss:0.0018008030273480608\n",
      "train loss:0.004143453712777834\n",
      "train loss:0.00242105695096869\n",
      "train loss:5.601525168450144e-05\n",
      "train loss:0.0019646620733225414\n",
      "train loss:0.003482589230049591\n",
      "train loss:0.0003232333036659266\n",
      "train loss:0.00028723422267962786\n",
      "train loss:0.0011696054584833223\n",
      "train loss:0.0012218692257543505\n",
      "train loss:0.003051991870024079\n",
      "train loss:0.0023211283453090635\n",
      "train loss:0.001185792382896101\n",
      "train loss:0.005323900697094508\n",
      "train loss:0.0018257731873835671\n",
      "train loss:0.0036142823604102727\n",
      "train loss:0.002679206398029591\n",
      "train loss:0.0009408270725900488\n",
      "train loss:0.0009872728658432603\n",
      "train loss:0.00012369666037064685\n",
      "train loss:0.0005362872470545771\n",
      "train loss:0.0024591603293854193\n",
      "train loss:0.0003035212961233561\n",
      "train loss:0.00020986441494585714\n",
      "train loss:0.0026094062118724648\n",
      "train loss:0.0014542775439300697\n",
      "train loss:0.0003800884931183608\n",
      "train loss:0.0008426359265053067\n",
      "train loss:0.0019450211092905969\n",
      "train loss:0.0016551454548502929\n",
      "train loss:0.002835845833646281\n",
      "train loss:0.0312803701496393\n",
      "train loss:0.006647177951010004\n",
      "train loss:0.00023697036580397717\n",
      "train loss:0.0015244950615100508\n",
      "train loss:0.0005221519849817667\n",
      "train loss:0.002673109776706918\n",
      "train loss:0.0011091284874377803\n",
      "train loss:0.021221667045365874\n",
      "train loss:0.009633794120352888\n",
      "train loss:0.001556617711024183\n",
      "train loss:0.0019848625018860228\n",
      "train loss:0.0013524327013829543\n",
      "train loss:0.0005540325127571285\n",
      "train loss:0.004813857714555799\n",
      "train loss:0.0016632793931685872\n",
      "train loss:0.0006751419463892275\n",
      "train loss:0.006711753094152601\n",
      "train loss:0.0004893598954767415\n",
      "train loss:0.002414491225775225\n",
      "train loss:0.0008336784863713722\n",
      "train loss:0.0008409269767633183\n",
      "train loss:0.0021154477013792\n",
      "train loss:0.0011182799911536464\n",
      "train loss:0.0021559649856554113\n",
      "train loss:0.0020645893498769767\n",
      "train loss:0.001990731355402721\n",
      "train loss:0.0006011440024649512\n",
      "train loss:0.00020989996885819866\n",
      "train loss:0.0011990477322000538\n",
      "train loss:0.0015033901440257716\n",
      "train loss:0.001883780643454709\n",
      "train loss:0.00019058710719369872\n",
      "train loss:0.0071783530595342536\n",
      "train loss:0.002658154938891591\n",
      "train loss:0.0025643424822613574\n",
      "train loss:0.006298693702970378\n",
      "train loss:0.00045111224736677625\n",
      "train loss:0.025140199656853702\n",
      "train loss:0.0021895550085040843\n",
      "train loss:0.002863967545065046\n",
      "train loss:0.0017178681264964275\n",
      "train loss:0.002309236391073571\n",
      "train loss:0.0013149715555137768\n",
      "train loss:0.0009408724423286636\n",
      "train loss:0.0027855349004947388\n",
      "train loss:0.0013034579673921634\n",
      "train loss:0.0007733947141476415\n",
      "train loss:0.0036552360550684625\n",
      "train loss:0.0005879712161454473\n",
      "train loss:0.0013194228712173595\n",
      "train loss:0.007863609527739896\n",
      "train loss:0.00563575195275366\n",
      "train loss:0.003445299973432827\n",
      "train loss:0.0025404861405643174\n",
      "train loss:0.008601252473121575\n",
      "train loss:0.0023635723658239098\n",
      "train loss:0.001023922846134279\n",
      "train loss:0.0025764371259175156\n",
      "train loss:0.009373017556671392\n",
      "train loss:0.006020673454375475\n",
      "train loss:0.0005391056607710134\n",
      "train loss:0.0008054609456078757\n",
      "train loss:0.006988056241956448\n",
      "train loss:0.00020496663064202558\n",
      "train loss:0.0024747141607339264\n",
      "train loss:0.0011247843268228004\n",
      "train loss:0.0012879375090236141\n",
      "train loss:0.0005313664364653766\n",
      "train loss:0.00035765521612140876\n",
      "train loss:0.0002960872037692639\n",
      "train loss:0.0023894757287657603\n",
      "train loss:0.0034413663446215726\n",
      "train loss:0.0015956416696805576\n",
      "train loss:0.013251271928558102\n",
      "train loss:0.0003875744774542039\n",
      "train loss:0.003071211888099853\n",
      "train loss:0.003144369030257214\n",
      "train loss:0.0030006503887043084\n",
      "train loss:0.00039489405469611034\n",
      "train loss:0.00032595104487342057\n",
      "=== epoch:15, train acc:0.992, test acc:0.988 ===\n",
      "train loss:0.00022565973031510105\n",
      "train loss:0.006818383393220298\n",
      "train loss:0.10137147331169329\n",
      "train loss:0.00023339600931645044\n",
      "train loss:0.0005851993952772014\n",
      "train loss:0.00075688259369133\n",
      "train loss:0.000211845230032282\n",
      "train loss:0.004914471840320327\n",
      "train loss:0.001971317937835488\n",
      "train loss:0.0006395984190639272\n",
      "train loss:0.002683363192794798\n",
      "train loss:0.005555127214325811\n",
      "train loss:0.009899763575942109\n",
      "train loss:0.0033273986007212263\n",
      "train loss:0.0014907282788815602\n",
      "train loss:0.0007429806607400729\n",
      "train loss:0.003644370016500029\n",
      "train loss:0.006675022896462858\n",
      "train loss:0.0008019117137100603\n",
      "train loss:0.0004587733968488951\n",
      "train loss:0.0011515615129841495\n",
      "train loss:0.004191571763792008\n",
      "train loss:0.004123750483324839\n",
      "train loss:0.0012662241849696917\n",
      "train loss:0.0026125589173660595\n",
      "train loss:0.015659832274804643\n",
      "train loss:0.006795097790249028\n",
      "train loss:0.0012845121604949242\n",
      "train loss:0.0017709826023655474\n",
      "train loss:0.006090570099256671\n",
      "train loss:0.00010309239399610848\n",
      "train loss:0.0020609350771912493\n",
      "train loss:0.0014999786206786614\n",
      "train loss:0.002366007353460838\n",
      "train loss:0.004432960081231796\n",
      "train loss:0.006929870371671142\n",
      "train loss:0.001007340838082577\n",
      "train loss:0.001831676747283532\n",
      "train loss:0.009257966432267012\n",
      "train loss:0.010539542682561536\n",
      "train loss:0.002192627154970076\n",
      "train loss:0.0018468487821643182\n",
      "train loss:0.001993448640717091\n",
      "train loss:0.005121376680421662\n",
      "train loss:0.000450397140707557\n",
      "train loss:0.0015887609713600525\n",
      "train loss:0.003143251993763024\n",
      "train loss:0.003936085030907095\n",
      "train loss:0.004099747896778299\n",
      "train loss:0.006106189991225509\n",
      "train loss:0.0018716970866398902\n",
      "train loss:0.006041347824765603\n",
      "train loss:0.00393623587827537\n",
      "train loss:0.0013673518602452886\n",
      "train loss:0.0002422142195462043\n",
      "train loss:0.00026250006971468285\n",
      "train loss:0.0001510573951905425\n",
      "train loss:0.00022697007001737154\n",
      "train loss:0.0002672113766227832\n",
      "train loss:0.00024952883068519614\n",
      "train loss:0.000964411770718379\n",
      "train loss:0.0031107370596271926\n",
      "train loss:0.004607069672053322\n",
      "train loss:0.0001690980994780315\n",
      "train loss:0.006331776291061951\n",
      "train loss:0.0004069940130995089\n",
      "train loss:0.0003702268548666299\n",
      "train loss:0.001389697595174303\n",
      "train loss:0.0003444082852196597\n",
      "train loss:0.0015174004514797617\n",
      "train loss:0.000381551420707662\n",
      "train loss:0.0012125015351951254\n",
      "train loss:0.019811426839641332\n",
      "train loss:0.0006818197926508951\n",
      "train loss:0.002587331928661869\n",
      "train loss:0.004997362534012453\n",
      "train loss:0.005634504412606342\n",
      "train loss:0.0004634295172503959\n",
      "train loss:0.0009218995927820585\n",
      "train loss:0.0060611725742243\n",
      "train loss:0.00010000035574872017\n",
      "train loss:0.0007322755300830943\n",
      "train loss:0.0022938964838357325\n",
      "train loss:0.044534768501598536\n",
      "train loss:0.0019586984585722436\n",
      "train loss:0.0013960536530766695\n",
      "train loss:0.0001734488123086435\n",
      "train loss:0.0010414853511604405\n",
      "train loss:0.0009317168236309682\n",
      "train loss:0.002020936330968517\n",
      "train loss:0.0037943871885337127\n",
      "train loss:0.0006098145845612101\n",
      "train loss:0.0009280335344660044\n",
      "train loss:0.003782961593815419\n",
      "train loss:0.0004094494809638441\n",
      "train loss:0.00023800581496962614\n",
      "train loss:0.0010953745996231969\n",
      "train loss:0.00048176088555736124\n",
      "train loss:0.002694307317486111\n",
      "train loss:0.0017584829007048595\n",
      "train loss:0.0013235448676307735\n",
      "train loss:0.0014707358822889044\n",
      "train loss:0.0011354262900879638\n",
      "train loss:0.00040370142486610314\n",
      "train loss:0.000263509522957257\n",
      "train loss:0.04072847673152452\n",
      "train loss:0.003296584962074033\n",
      "train loss:0.001248019351855354\n",
      "train loss:0.0039864224051210685\n",
      "train loss:0.0026710634893065692\n",
      "train loss:0.010686594062331104\n",
      "train loss:0.0016058371866945612\n",
      "train loss:0.0037011028556554228\n",
      "train loss:0.00013589433429498954\n",
      "train loss:0.0021596659252735542\n",
      "train loss:0.00340183611753412\n",
      "train loss:0.0006427271756736759\n",
      "train loss:0.003996886686341651\n",
      "train loss:0.005345558197825888\n",
      "train loss:0.0035207322273690263\n",
      "train loss:0.0008505409586387041\n",
      "train loss:0.000784370185759122\n",
      "train loss:0.00011341872051981726\n",
      "train loss:0.0018038660752303043\n",
      "train loss:0.0025743195259610475\n",
      "train loss:0.0014273297174354105\n",
      "train loss:0.0069337349346335056\n",
      "train loss:0.00025201488362723546\n",
      "train loss:0.0036858988584806108\n",
      "train loss:0.0007313179164914909\n",
      "train loss:0.001768280081519632\n",
      "train loss:0.0004392083484448064\n",
      "train loss:0.004064086109801041\n",
      "train loss:0.0015495426149820203\n",
      "train loss:0.0012690915417535396\n",
      "train loss:0.005302503277903648\n",
      "train loss:0.0018175393767230793\n",
      "train loss:0.0009623408463840139\n",
      "train loss:0.0015496394170521682\n",
      "train loss:0.003202088782602906\n",
      "train loss:0.004626908431210113\n",
      "train loss:0.0011710458478951837\n",
      "train loss:0.004780149500717018\n",
      "train loss:0.001990330208700985\n",
      "train loss:0.004074679640903115\n",
      "train loss:0.0009289327668029017\n",
      "train loss:0.008105057196574377\n",
      "train loss:0.0027827533476696004\n",
      "train loss:0.0014473049909578845\n",
      "train loss:0.004529892661724346\n",
      "train loss:0.0027937598114593535\n",
      "train loss:0.01254399542772235\n",
      "train loss:0.0023829386714264516\n",
      "train loss:0.000991244453455129\n",
      "train loss:0.00015750692906099512\n",
      "train loss:0.00012243777674649854\n",
      "train loss:0.005507589846992464\n",
      "train loss:0.0019833604975038927\n",
      "train loss:0.00998104885914273\n",
      "train loss:0.0015067782048920125\n",
      "train loss:0.0010606271874630106\n",
      "train loss:0.000570112391952521\n",
      "train loss:0.001982722544786535\n",
      "train loss:0.008915690104823888\n",
      "train loss:0.0023736463464127167\n",
      "train loss:0.002832330240709776\n",
      "train loss:0.01672816762867078\n",
      "train loss:0.0004185152971685903\n",
      "train loss:0.007662944714977075\n",
      "train loss:0.0016715915912698298\n",
      "train loss:0.0026346902259102244\n",
      "train loss:0.0005858842519666646\n",
      "train loss:0.0017440748206733517\n",
      "train loss:0.001119993941168765\n",
      "train loss:0.0013269193974585955\n",
      "train loss:0.004019213654915599\n",
      "train loss:0.0009642997232442187\n",
      "train loss:0.001098446505334406\n",
      "train loss:0.009777075371346242\n",
      "train loss:0.005029283048893657\n",
      "train loss:0.003574212524340606\n",
      "train loss:0.001906154993333801\n",
      "train loss:0.004598567725309059\n",
      "train loss:0.0004611268331821281\n",
      "train loss:0.00048755916423760674\n",
      "train loss:0.003886597864031517\n",
      "train loss:0.0043027629719234765\n",
      "train loss:0.0031631971925112834\n",
      "train loss:0.0024200035044080123\n",
      "train loss:0.00043375242766068245\n",
      "train loss:0.002932690729353169\n",
      "train loss:0.012327424558375955\n",
      "train loss:0.0010248820986731712\n",
      "train loss:0.0006603935192231087\n",
      "train loss:0.005052004898482518\n",
      "train loss:0.005735587877480457\n",
      "train loss:0.0019682524816981967\n",
      "train loss:0.0022272816692007424\n",
      "train loss:0.0012034496400755352\n",
      "train loss:0.002383179166800857\n",
      "train loss:0.0032800803606408495\n",
      "train loss:0.0019783415960705365\n",
      "train loss:0.004356021702039055\n",
      "train loss:0.013785118137026526\n",
      "train loss:0.0015812978143067745\n",
      "train loss:0.0013623703250111117\n",
      "train loss:0.002002001997114241\n",
      "train loss:0.0005983889041064032\n",
      "train loss:0.009724180529395669\n",
      "train loss:0.0002884263927074247\n",
      "train loss:0.0010983972127204436\n",
      "train loss:0.00047598579028429043\n",
      "train loss:0.000210390184262425\n",
      "train loss:0.0007253118775200788\n",
      "train loss:0.0005103905679510295\n",
      "train loss:0.0001982067813602737\n",
      "train loss:0.005144994181694971\n",
      "train loss:0.009847868428616492\n",
      "train loss:0.0014362829809894818\n",
      "train loss:0.00021219322657462268\n",
      "train loss:0.00013278644497816637\n",
      "train loss:0.0007598154555755042\n",
      "train loss:0.004424481273180331\n",
      "train loss:0.0011020080810039382\n",
      "train loss:0.0023916904441506656\n",
      "train loss:0.0006225407920984851\n",
      "train loss:0.0025060578455940617\n",
      "train loss:0.0015123453302871668\n",
      "train loss:0.0028398687980825325\n",
      "train loss:0.002573891620815699\n",
      "train loss:0.002947405613645966\n",
      "train loss:0.0006516683525256944\n",
      "train loss:0.009861369865901517\n",
      "train loss:0.0018318213044274995\n",
      "train loss:0.0005871658064478661\n",
      "train loss:0.012461967120482843\n",
      "train loss:0.0012149641918053232\n",
      "train loss:0.0008676555458331732\n",
      "train loss:0.0003752944821270546\n",
      "train loss:0.0006773320156184255\n",
      "train loss:0.0026533281686421765\n",
      "train loss:0.0007160234027322391\n",
      "train loss:0.001333483234364645\n",
      "train loss:0.0011044442064406849\n",
      "train loss:0.0032169561113845314\n",
      "train loss:0.0038490455093743133\n",
      "train loss:0.0011150780042250572\n",
      "train loss:0.0013817991480886377\n",
      "train loss:0.0002760813894279602\n",
      "train loss:0.0020647481462947497\n",
      "train loss:0.01178439933437824\n",
      "train loss:0.0010635033644738738\n",
      "train loss:0.00875779263119074\n",
      "train loss:0.0002105380076477134\n",
      "train loss:0.006060956852170343\n",
      "train loss:0.0019659774665659775\n",
      "train loss:0.0003318391705918995\n",
      "train loss:0.0019500522034617096\n",
      "train loss:0.0011729109918290261\n",
      "train loss:0.008776170263822767\n",
      "train loss:0.00023547610967551352\n",
      "train loss:0.004072740052888099\n",
      "train loss:0.0004971023393293565\n",
      "train loss:0.0007502554213424914\n",
      "train loss:0.0011511948420290371\n",
      "train loss:0.0005328215737198033\n",
      "train loss:0.002286537831821754\n",
      "train loss:0.0037657496586854266\n",
      "train loss:0.0008656618695759386\n",
      "train loss:0.0015127390130221208\n",
      "train loss:0.002132385357305368\n",
      "train loss:0.0006200243505872049\n",
      "train loss:0.0006414824991182704\n",
      "train loss:0.0006143786874955822\n",
      "train loss:0.0006328016567668412\n",
      "train loss:0.0009778708184864447\n",
      "train loss:0.019382312212804193\n",
      "train loss:0.007982883832438739\n",
      "train loss:0.000620892255445727\n",
      "train loss:0.0018098244372576017\n",
      "train loss:0.0009798555383438606\n",
      "train loss:0.0066155295229771306\n",
      "train loss:0.0006263304704051101\n",
      "train loss:0.0010520800558707327\n",
      "train loss:0.004268125266447198\n",
      "train loss:0.006145108538726181\n",
      "train loss:0.006407183416121299\n",
      "train loss:0.0004561212848466764\n",
      "train loss:0.004757980521983478\n",
      "train loss:0.0005166258796860535\n",
      "train loss:0.005355097274719162\n",
      "train loss:0.0004274135475419156\n",
      "train loss:0.0014073099948983417\n",
      "train loss:0.0007639821089328486\n",
      "train loss:0.0039150087182891185\n",
      "train loss:0.0009677704195907776\n",
      "train loss:0.009945634866187771\n",
      "train loss:0.0009734490823040185\n",
      "train loss:0.0005214654142714709\n",
      "train loss:0.007254214479643358\n",
      "train loss:0.002571382194329454\n",
      "train loss:0.0007142501519178092\n",
      "train loss:0.006299952269234622\n",
      "train loss:0.002908037818615758\n",
      "train loss:0.0030114618549605017\n",
      "train loss:0.0013522149224834872\n",
      "train loss:0.00019012608824645297\n",
      "train loss:0.002497564061102634\n",
      "train loss:0.0013786725428250293\n",
      "train loss:0.0025599193956407852\n",
      "train loss:0.0017852341455178208\n",
      "train loss:0.0016685451135741982\n",
      "train loss:0.03147805504128453\n",
      "train loss:0.006058749447330957\n",
      "train loss:0.00043653507723171136\n",
      "train loss:8.354137361979568e-05\n",
      "train loss:0.012360165397696816\n",
      "train loss:0.0003771052455398778\n",
      "train loss:0.002742968927897255\n",
      "train loss:0.0015866730227254563\n",
      "train loss:0.0020258446090720443\n",
      "train loss:0.0030343349227192657\n",
      "train loss:0.0010677481002947125\n",
      "train loss:0.001832449068457494\n",
      "train loss:0.0020282022266002466\n",
      "train loss:0.003257802845408085\n",
      "train loss:0.0015456025531202608\n",
      "train loss:0.0004933625565229236\n",
      "train loss:0.0027857145727236275\n",
      "train loss:0.0022251309671984395\n",
      "train loss:0.000763528726483634\n",
      "train loss:0.0008424030432251716\n",
      "train loss:0.001470269661532424\n",
      "train loss:0.0021182563019091277\n",
      "train loss:0.0006277434098863374\n",
      "train loss:0.0006713027286439943\n",
      "train loss:0.00043731420882532596\n",
      "train loss:0.0025156327352620408\n",
      "train loss:0.0026678171665306238\n",
      "train loss:0.00019743750700776668\n",
      "train loss:0.0007496923089374374\n",
      "train loss:0.0014023133229505102\n",
      "train loss:0.0007950127113837248\n",
      "train loss:0.0010161153526119155\n",
      "train loss:0.00027061438215271395\n",
      "train loss:0.0006094095348523769\n",
      "train loss:0.0008984791217481971\n",
      "train loss:0.00817728772845085\n",
      "train loss:0.00012252305690096311\n",
      "train loss:0.0002357422768042046\n",
      "train loss:0.0011202053387205763\n",
      "train loss:9.748119954639712e-05\n",
      "train loss:0.00042850861363405836\n",
      "train loss:0.0011427424956666715\n",
      "train loss:0.0011391806324034096\n",
      "train loss:0.00013674385026471802\n",
      "train loss:0.001626352847987506\n",
      "train loss:0.004255564292360733\n",
      "train loss:0.001935337840488937\n",
      "train loss:0.0040097657594017865\n",
      "train loss:0.0027244004805230216\n",
      "train loss:0.002093009843329821\n",
      "train loss:0.0015047650408427727\n",
      "train loss:0.0004330575659814025\n",
      "train loss:0.0009744238069466372\n",
      "train loss:0.00015080810565596927\n",
      "train loss:0.0008752262518527174\n",
      "train loss:0.00040197155440160215\n",
      "train loss:0.0009089159969318895\n",
      "train loss:0.00046110121140418496\n",
      "train loss:0.0014560194060190734\n",
      "train loss:0.002807716980158688\n",
      "train loss:0.0003465137689407668\n",
      "train loss:0.00979782204385041\n",
      "train loss:0.002639851503945977\n",
      "train loss:3.5288991642801e-05\n",
      "train loss:0.0009157442567416205\n",
      "train loss:0.00017134117202425797\n",
      "train loss:0.0005187277829267113\n",
      "train loss:0.0003218100832034082\n",
      "train loss:0.0033083562294644684\n",
      "train loss:0.000330214661158082\n",
      "train loss:0.0031567984279744403\n",
      "train loss:0.0046772654636088925\n",
      "train loss:0.0028591437598542257\n",
      "train loss:0.004157581509696054\n",
      "train loss:0.0017718986644296886\n",
      "train loss:0.0016168934118232178\n",
      "train loss:0.0012760687063849382\n",
      "train loss:0.002453687440524101\n",
      "train loss:0.0008525933650142155\n",
      "train loss:0.0024750930383669587\n",
      "train loss:0.0007614510358319279\n",
      "train loss:0.001007907500914527\n",
      "train loss:0.0009488409452374977\n",
      "train loss:0.00018380277620392676\n",
      "train loss:0.0006510122815122445\n",
      "train loss:0.0002466183558117096\n",
      "train loss:0.0005751642890500469\n",
      "train loss:0.00022131125307918678\n",
      "train loss:0.0002690018401755055\n",
      "train loss:0.0002401434035018183\n",
      "train loss:0.0005112010727503404\n",
      "train loss:0.0002309849689720263\n",
      "train loss:0.0010082188597726285\n",
      "train loss:0.0014976120896812103\n",
      "train loss:0.00146079115717183\n",
      "train loss:8.818339389215238e-05\n",
      "train loss:0.0008730981464680005\n",
      "train loss:0.0001514503242357368\n",
      "train loss:0.0023419035825019106\n",
      "train loss:0.00012294078215490376\n",
      "train loss:0.0017202799622022188\n",
      "train loss:0.0018500786666559533\n",
      "train loss:0.00023108651860742597\n",
      "train loss:0.0001702146286126142\n",
      "train loss:0.0019651525419618152\n",
      "train loss:0.002514447791427442\n",
      "train loss:0.0026499102280517026\n",
      "train loss:0.009222493891811324\n",
      "train loss:0.006360897777943992\n",
      "train loss:0.0003639626760188091\n",
      "train loss:0.003956000401354822\n",
      "train loss:0.00031200966036838414\n",
      "train loss:0.0006915753667289021\n",
      "train loss:0.0024123745609783203\n",
      "train loss:0.0005405350414700925\n",
      "train loss:0.0005499961258240504\n",
      "train loss:0.0004443406632164855\n",
      "train loss:0.001262109900970737\n",
      "train loss:0.0005141743861969472\n",
      "train loss:0.0017467625584682667\n",
      "train loss:0.0006126740418081008\n",
      "train loss:0.0035166254276823073\n",
      "train loss:0.00017092766355493336\n",
      "train loss:0.014832558214476736\n",
      "train loss:0.0005538582116344324\n",
      "train loss:0.00045669713697288594\n",
      "train loss:0.0018310978334209302\n",
      "train loss:0.0005667324121369953\n",
      "train loss:0.00010035821033260183\n",
      "train loss:0.000728364407135507\n",
      "train loss:0.0034454678265160143\n",
      "train loss:0.006517274981744583\n",
      "train loss:0.010601828784986922\n",
      "train loss:0.006445140463460301\n",
      "train loss:0.0018588920627121519\n",
      "train loss:0.0007606241863335573\n",
      "train loss:0.0007168723267469547\n",
      "train loss:0.0008095086608921361\n",
      "train loss:0.005513609699545246\n",
      "train loss:0.001027606077898348\n",
      "train loss:0.0004547611376927859\n",
      "train loss:0.0027773371064332797\n",
      "train loss:0.001174722611601444\n",
      "train loss:0.01028883501368543\n",
      "train loss:0.0024683803410239825\n",
      "train loss:0.008618386228259335\n",
      "train loss:0.0026547926476688504\n",
      "train loss:0.015471198434712953\n",
      "train loss:0.0006361571355101623\n",
      "train loss:0.0009582982393696468\n",
      "train loss:0.004189313905790289\n",
      "train loss:9.943295236928498e-05\n",
      "train loss:0.0007159572857874995\n",
      "train loss:0.003856126616223528\n",
      "train loss:0.006714219670727376\n",
      "train loss:0.0005923736048432745\n",
      "train loss:0.001698619725736733\n",
      "train loss:0.002051557795630282\n",
      "train loss:0.0009633722726875242\n",
      "train loss:0.0017304814418854567\n",
      "train loss:0.0027533157255301716\n",
      "train loss:0.00037408789236845555\n",
      "train loss:0.0004292556984607464\n",
      "train loss:0.001101618063607221\n",
      "train loss:0.0009249050119712497\n",
      "train loss:0.00301187408169003\n",
      "train loss:0.002564489834972443\n",
      "train loss:0.0034283721970614638\n",
      "train loss:0.002069223855107789\n",
      "train loss:0.0015611691695225215\n",
      "train loss:0.0007866500996578618\n",
      "train loss:0.00869543929305149\n",
      "train loss:0.0007866811763750988\n",
      "train loss:0.0007383421887146532\n",
      "train loss:0.0002474644760409525\n",
      "train loss:0.00092620807367872\n",
      "train loss:0.0011152712188782778\n",
      "train loss:0.042917858418001574\n",
      "train loss:0.000638411389227359\n",
      "train loss:0.0006942912721203647\n",
      "train loss:0.0024714564600847983\n",
      "train loss:0.002136487313436693\n",
      "train loss:0.0037720420134131037\n",
      "train loss:0.011179977022598318\n",
      "train loss:0.0005694320715813211\n",
      "train loss:0.0013814756909755288\n",
      "train loss:0.0004028443630461392\n",
      "train loss:0.0035514200008717072\n",
      "train loss:0.00028611441704376076\n",
      "train loss:0.00017461689269009236\n",
      "train loss:0.0048582604594284585\n",
      "train loss:0.002918563131368685\n",
      "train loss:0.0004751470255979577\n",
      "train loss:0.00040636201056043\n",
      "train loss:0.004797968478214054\n",
      "train loss:0.000331380840322527\n",
      "train loss:0.001606418474002956\n",
      "train loss:0.0014977419719706777\n",
      "train loss:0.002083772251111797\n",
      "train loss:0.007818568900439991\n",
      "train loss:0.00241792256660136\n",
      "train loss:0.004214899817407763\n",
      "train loss:0.00011551137215598795\n",
      "train loss:0.00029675811496263126\n",
      "train loss:9.582922430379832e-05\n",
      "train loss:0.01225910074281516\n",
      "train loss:0.0001873268421202926\n",
      "train loss:0.006300181797098026\n",
      "train loss:0.009565902085231582\n",
      "train loss:0.05492560831162995\n",
      "train loss:0.0029759880827281825\n",
      "train loss:0.0024871973363067724\n",
      "train loss:0.014876377161248766\n",
      "train loss:0.003763548172672152\n",
      "train loss:0.029250713480251954\n",
      "train loss:0.00022351362624958282\n",
      "train loss:0.005081624031999329\n",
      "train loss:0.0002698549800268427\n",
      "train loss:0.00043337966326089874\n",
      "train loss:0.018796007530741742\n",
      "train loss:0.000970957795257354\n",
      "train loss:8.950775361945388e-05\n",
      "train loss:0.00514451657712355\n",
      "train loss:0.0009967837955165652\n",
      "train loss:0.010137648927412314\n",
      "train loss:0.0010935068176149004\n",
      "train loss:0.002543537525942423\n",
      "train loss:0.0030145302620082836\n",
      "train loss:0.03794797448058009\n",
      "train loss:0.00037105333678912403\n",
      "train loss:0.006853070857403832\n",
      "train loss:0.0008018601755120341\n",
      "train loss:0.005308922791895252\n",
      "train loss:0.000255472932602469\n",
      "train loss:0.0021662604840531384\n",
      "train loss:0.005477880920314545\n",
      "train loss:0.0006623350882960155\n",
      "train loss:0.00041443424892953246\n",
      "train loss:0.0022029444075264727\n",
      "train loss:0.00046193238196912573\n",
      "train loss:0.0014372557727124755\n",
      "train loss:0.0029228457070663723\n",
      "train loss:0.0005620027570649718\n",
      "train loss:0.0031235512992812482\n",
      "train loss:0.011311427288337235\n",
      "train loss:0.004188096301190641\n",
      "train loss:0.006379992374331675\n",
      "train loss:0.006996058308046465\n",
      "train loss:0.0014042260110786891\n",
      "train loss:3.806451459943799e-05\n",
      "train loss:0.008894420243604744\n",
      "train loss:0.02549169660883439\n",
      "train loss:0.014624505205002126\n",
      "train loss:0.0006312506651249229\n",
      "train loss:0.003060742478517042\n",
      "train loss:0.0009705129865379477\n",
      "train loss:0.0004939152087473473\n",
      "train loss:0.0049172674007679105\n",
      "train loss:0.008242241473777643\n",
      "train loss:0.03921875764672694\n",
      "train loss:0.011452724192260653\n",
      "train loss:0.0025050635580624193\n",
      "train loss:0.0020699541549485927\n",
      "train loss:0.002239413494693841\n",
      "train loss:0.008001290149782589\n",
      "train loss:0.014158007128555505\n",
      "train loss:0.008939076665889814\n",
      "train loss:0.00023202717852796587\n",
      "train loss:0.0002323281818474249\n",
      "train loss:0.003182470405345266\n",
      "train loss:0.001008361252396839\n",
      "train loss:0.0017022162812819705\n",
      "train loss:0.0006512095366972949\n",
      "train loss:0.0025417275083243324\n",
      "train loss:0.037316454808384074\n",
      "train loss:0.001611305380073065\n",
      "train loss:0.005515479760767238\n",
      "train loss:0.0006793948321364245\n",
      "train loss:9.361340997309214e-05\n",
      "train loss:0.0010952709986113193\n",
      "train loss:0.008603922162422879\n",
      "train loss:0.0016109390558879386\n",
      "train loss:0.0005825390698606056\n",
      "train loss:0.0031854666835844647\n",
      "train loss:0.0008155289733925871\n",
      "train loss:0.0011337713284012342\n",
      "train loss:0.0361836567144756\n",
      "train loss:0.0012886133693864618\n",
      "=== epoch:16, train acc:0.998, test acc:0.99 ===\n",
      "train loss:0.0026044475430492937\n",
      "train loss:0.00013372166437679756\n",
      "train loss:0.0013257511315271256\n",
      "train loss:0.0016219743638151418\n",
      "train loss:0.0014555520964548898\n",
      "train loss:0.009403311824316125\n",
      "train loss:0.003489339290428239\n",
      "train loss:0.004791397293965627\n",
      "train loss:0.0044811999611311\n",
      "train loss:0.0025565005200131065\n",
      "train loss:0.0010226658076473343\n",
      "train loss:0.0009550150026623476\n",
      "train loss:0.004716661230738391\n",
      "train loss:0.00020939249649561863\n",
      "train loss:0.04201105307132659\n",
      "train loss:0.003276222790618903\n",
      "train loss:0.00013092463831443832\n",
      "train loss:0.0005813477532075277\n",
      "train loss:0.004983027943468041\n",
      "train loss:0.008949281785107408\n",
      "train loss:0.0010327913749985866\n",
      "train loss:0.002962114936313271\n",
      "train loss:0.0004065442618566033\n",
      "train loss:0.005418688439308417\n",
      "train loss:0.002926075347102979\n",
      "train loss:0.005628721613897707\n",
      "train loss:0.0029677397509037208\n",
      "train loss:0.0018855788903813953\n",
      "train loss:0.0022980765447421932\n",
      "train loss:0.002944170805607694\n",
      "train loss:0.0006246806465542126\n",
      "train loss:0.003780731834240047\n",
      "train loss:0.013543389758783218\n",
      "train loss:0.005584596631486837\n",
      "train loss:0.03298588049367847\n",
      "train loss:0.000420836219087504\n",
      "train loss:0.00019665230854796242\n",
      "train loss:0.0026385781174140003\n",
      "train loss:0.01042120374006583\n",
      "train loss:0.012147733716629909\n",
      "train loss:0.0029808907771149418\n",
      "train loss:0.01368424753252403\n",
      "train loss:0.004017162615467795\n",
      "train loss:0.0013084443189490189\n",
      "train loss:0.0037387040913129605\n",
      "train loss:0.001949634578980469\n",
      "train loss:0.003690371691155625\n",
      "train loss:0.0028802818716555318\n",
      "train loss:0.0019854888781912668\n",
      "train loss:0.024452994608535516\n",
      "train loss:0.009503097776496394\n",
      "train loss:0.0012643875019554608\n",
      "train loss:0.011771450956050176\n",
      "train loss:0.0011077346081463586\n",
      "train loss:0.0031130023005459554\n",
      "train loss:0.002328586815749679\n",
      "train loss:0.0013727780222801253\n",
      "train loss:0.002080226700212475\n",
      "train loss:0.024226693256302063\n",
      "train loss:0.0021456874527992923\n",
      "train loss:0.0025980743390588423\n",
      "train loss:0.003632109336963964\n",
      "train loss:0.005076192906075919\n",
      "train loss:0.0021523804378176916\n",
      "train loss:0.000874092870824027\n",
      "train loss:0.00875045152916086\n",
      "train loss:0.005378262873770091\n",
      "train loss:0.031037888961540694\n",
      "train loss:0.0034211594594760275\n",
      "train loss:0.010106837541501192\n",
      "train loss:0.0004664284261460857\n",
      "train loss:0.008326100580128152\n",
      "train loss:0.0037417001637941806\n",
      "train loss:0.0010119424387468642\n",
      "train loss:0.015527725874224735\n",
      "train loss:0.003880406573561661\n",
      "train loss:0.00016293766264369462\n",
      "train loss:0.01054325248730405\n",
      "train loss:0.0034861335800238195\n",
      "train loss:8.52851079891594e-05\n",
      "train loss:0.0024425337755536987\n",
      "train loss:0.006126382769840625\n",
      "train loss:0.00833787440245617\n",
      "train loss:0.005696733131048067\n",
      "train loss:0.0032890138617880068\n",
      "train loss:0.005343392153668636\n",
      "train loss:0.006962476280119074\n",
      "train loss:0.004046168121854793\n",
      "train loss:0.000357134633544311\n",
      "train loss:0.0024279033614052056\n",
      "train loss:0.010602501463561998\n",
      "train loss:0.0009071286079624477\n",
      "train loss:0.0008881255424613751\n",
      "train loss:0.02452721331045737\n",
      "train loss:0.04899736178907745\n",
      "train loss:0.0008992037932637365\n",
      "train loss:0.006263427669156436\n",
      "train loss:0.0063720520642806325\n",
      "train loss:0.00030498198569318296\n",
      "train loss:0.0029297841518870498\n",
      "train loss:0.0028492261603410072\n",
      "train loss:0.00014405966621738636\n",
      "train loss:0.0037608006218469154\n",
      "train loss:0.0007366323283572681\n",
      "train loss:0.0022298121174694815\n",
      "train loss:9.397626684001007e-05\n",
      "train loss:0.0034129009513242997\n",
      "train loss:0.010750086443522934\n",
      "train loss:0.002049711016816462\n",
      "train loss:0.0005498396422717706\n",
      "train loss:0.0005083163057615999\n",
      "train loss:0.003493327502226132\n",
      "train loss:0.0006429074264216248\n",
      "train loss:0.008083918097881542\n",
      "train loss:0.0068211584333720465\n",
      "train loss:0.004181491696159582\n",
      "train loss:0.00023300460199678842\n",
      "train loss:0.0097093387218354\n",
      "train loss:0.002575377524599241\n",
      "train loss:0.003953622632665405\n",
      "train loss:0.004868662875107614\n",
      "train loss:0.0015236590288878627\n",
      "train loss:0.0009677232491238628\n",
      "train loss:0.0062137909478074006\n",
      "train loss:0.0042079494095923695\n",
      "train loss:0.0002158054320707963\n",
      "train loss:0.00510502390492273\n",
      "train loss:0.0002400020873436255\n",
      "train loss:0.0019710843459188497\n",
      "train loss:0.004085669194618338\n",
      "train loss:0.001117513454825083\n",
      "train loss:0.010088318030712402\n",
      "train loss:0.002286008618079296\n",
      "train loss:0.0005891524328142402\n",
      "train loss:0.00019554049018801034\n",
      "train loss:0.0035122980508305703\n",
      "train loss:0.0017323882488952252\n",
      "train loss:0.0006985738117925995\n",
      "train loss:0.002741789685740141\n",
      "train loss:0.003817043833464746\n",
      "train loss:0.0010786002485696196\n",
      "train loss:0.00030140479528701996\n",
      "train loss:0.0019053963971660112\n",
      "train loss:0.001961902060473345\n",
      "train loss:0.005662529255859215\n",
      "train loss:0.000652286756022288\n",
      "train loss:0.0061256784515441864\n",
      "train loss:0.0028060089393611414\n",
      "train loss:0.0017343883567899035\n",
      "train loss:0.0010103101845449101\n",
      "train loss:0.0016433019722953384\n",
      "train loss:0.006782453704899937\n",
      "train loss:0.0006566843123768305\n",
      "train loss:0.001047586164529351\n",
      "train loss:0.0049729406440227625\n",
      "train loss:0.00290139161059101\n",
      "train loss:0.0030665940482480507\n",
      "train loss:0.00473480289420892\n",
      "train loss:0.0005340407711064623\n",
      "train loss:0.004893372034819031\n",
      "train loss:0.00020831018832853353\n",
      "train loss:0.000129773988675007\n",
      "train loss:0.00042071300305424676\n",
      "train loss:0.0017533180474532623\n",
      "train loss:0.0029192221416309326\n",
      "train loss:0.0009028271361813462\n",
      "train loss:0.01959362545149889\n",
      "train loss:0.0006585929371748354\n",
      "train loss:0.001980807443605544\n",
      "train loss:0.0019061267664741226\n",
      "train loss:0.019062622227591405\n",
      "train loss:0.0069238389615245855\n",
      "train loss:0.0014378429325970607\n",
      "train loss:0.0012058355437112667\n",
      "train loss:0.011346551178445423\n",
      "train loss:0.00031160745085638677\n",
      "train loss:0.0002112076901251064\n",
      "train loss:0.003512072716566502\n",
      "train loss:0.0020603590572573728\n",
      "train loss:0.004837395659067698\n",
      "train loss:0.00034500824590076823\n",
      "train loss:0.0016280251999872385\n",
      "train loss:0.0028789811306441098\n",
      "train loss:0.0013518312720060227\n",
      "train loss:0.0017522735192962138\n",
      "train loss:0.007763600060757579\n",
      "train loss:0.0013146313033371743\n",
      "train loss:0.002485252993723649\n",
      "train loss:0.000508378571470318\n",
      "train loss:0.006895080204841748\n",
      "train loss:0.004066457970560085\n",
      "train loss:0.001970840071164297\n",
      "train loss:0.0012415456544081428\n",
      "train loss:0.001645030832595725\n",
      "train loss:0.0009455756379449831\n",
      "train loss:0.011098589416646458\n",
      "train loss:0.0007950417746020213\n",
      "train loss:0.0044714733356637\n",
      "train loss:0.004036202928750673\n",
      "train loss:0.004933152941493686\n",
      "train loss:0.003926473814819518\n",
      "train loss:0.000750537986309607\n",
      "train loss:0.0032476368983997144\n",
      "train loss:0.0022940438449080597\n",
      "train loss:0.004930446201341424\n",
      "train loss:0.0013333892177123314\n",
      "train loss:0.0016324514635287638\n",
      "train loss:0.0005723352407188379\n",
      "train loss:0.0005669907091316822\n",
      "train loss:0.00014436886678218652\n",
      "train loss:0.0026031258489531283\n",
      "train loss:0.0019287233831576823\n",
      "train loss:0.0010266420088225637\n",
      "train loss:0.005683996560559707\n",
      "train loss:0.023916254777602165\n",
      "train loss:0.0006090057826571381\n",
      "train loss:0.0013830128949473483\n",
      "train loss:0.002965092945947119\n",
      "train loss:0.00036706162454262455\n",
      "train loss:0.0008923933646340658\n",
      "train loss:0.00356043345042789\n",
      "train loss:0.010231536499543331\n",
      "train loss:0.0013461120287889417\n",
      "train loss:0.0003563121679597056\n",
      "train loss:0.00266260859182762\n",
      "train loss:0.0007867276425590212\n",
      "train loss:0.0030941662794386786\n",
      "train loss:0.0009432084633921754\n",
      "train loss:0.0005145963004669636\n",
      "train loss:0.0012665696731340404\n",
      "train loss:0.002291945335463927\n",
      "train loss:0.005256371082276343\n",
      "train loss:0.0027437431046330087\n",
      "train loss:0.00029139785727020533\n",
      "train loss:0.0033784123518526554\n",
      "train loss:0.0010659026488591165\n",
      "train loss:0.007074304115742947\n",
      "train loss:0.0026793213428973183\n",
      "train loss:0.000512252982150095\n",
      "train loss:0.0005803072793029258\n",
      "train loss:0.003040517365189956\n",
      "train loss:0.0013259515792291227\n",
      "train loss:0.0033248247668960828\n",
      "train loss:0.0013006678392385534\n",
      "train loss:0.001396720647143902\n",
      "train loss:0.002216312215187761\n",
      "train loss:0.006401583710461925\n",
      "train loss:0.0002643632644588403\n",
      "train loss:0.0005873563200234352\n",
      "train loss:0.0029807585567602074\n",
      "train loss:0.0034475675247789034\n",
      "train loss:0.003288988429782068\n",
      "train loss:0.0002575050151421439\n",
      "train loss:0.0026679776007122683\n",
      "train loss:0.0006414738848447029\n",
      "train loss:0.00059726364569415\n",
      "train loss:0.003028893949264268\n",
      "train loss:0.0004008833467355759\n",
      "train loss:0.002646476157988982\n",
      "train loss:0.0002982676910186532\n",
      "train loss:0.0017689804277452362\n",
      "train loss:0.0001135393432516961\n",
      "train loss:0.0011860496753907247\n",
      "train loss:0.0026596627515024685\n",
      "train loss:0.0016991668983831274\n",
      "train loss:0.0010348294338464869\n",
      "train loss:0.001128854848553181\n",
      "train loss:0.002901716279561643\n",
      "train loss:0.0020143788497120215\n",
      "train loss:0.0024202888846808243\n",
      "train loss:0.003674253289747998\n",
      "train loss:0.00038728857059545013\n",
      "train loss:0.03565382051055334\n",
      "train loss:0.0016298335907766273\n",
      "train loss:0.00010771084420248011\n",
      "train loss:0.003606376069085704\n",
      "train loss:0.00261870759662407\n",
      "train loss:0.006730053007925718\n",
      "train loss:0.0012451452310710339\n",
      "train loss:0.0019046991788190834\n",
      "train loss:0.006028440236700018\n",
      "train loss:0.0006891016866850566\n",
      "train loss:0.0021682201300542133\n",
      "train loss:0.0003500979486688884\n",
      "train loss:0.002379936517011259\n",
      "train loss:0.0002504707589744421\n",
      "train loss:0.001658048616548925\n",
      "train loss:0.0008760571779590078\n",
      "train loss:0.00017410774006745914\n",
      "train loss:0.006565866009925297\n",
      "train loss:0.0007914341329045621\n",
      "train loss:0.006153158712269687\n",
      "train loss:0.002229175544228756\n",
      "train loss:0.0018227212590570508\n",
      "train loss:0.0007301275397589721\n",
      "train loss:0.0018018907908499476\n",
      "train loss:0.0003411606679851817\n",
      "train loss:6.63667314165785e-05\n",
      "train loss:0.0019310507581549326\n",
      "train loss:0.00042136059800186224\n",
      "train loss:0.00045941392467695213\n",
      "train loss:0.0006365919870250361\n",
      "train loss:0.002500703270360005\n",
      "train loss:0.00010951416782271663\n",
      "train loss:0.0003138480120437942\n",
      "train loss:0.0008447410379426368\n",
      "train loss:0.0003935466161685558\n",
      "train loss:0.001107324660561089\n",
      "train loss:0.00018569332300682822\n",
      "train loss:0.0002594275906924018\n",
      "train loss:0.007039917424368217\n",
      "train loss:0.0013476593019575733\n",
      "train loss:0.0055827302708884976\n",
      "train loss:0.00011709549714294582\n",
      "train loss:0.00651562793952831\n",
      "train loss:0.0011508737576531852\n",
      "train loss:0.008120346717345869\n",
      "train loss:0.00042384743321145795\n",
      "train loss:0.00014786629986154266\n",
      "train loss:0.0008848130578424083\n",
      "train loss:0.00037195615058312377\n",
      "train loss:0.0004657584810715112\n",
      "train loss:0.00157428983610901\n",
      "train loss:0.0009439043684004094\n",
      "train loss:0.004716875715193621\n",
      "train loss:0.004047536294433483\n",
      "train loss:0.004762457158777953\n",
      "train loss:0.0006568668123651101\n",
      "train loss:0.0003111877466071343\n",
      "train loss:0.0024238390605375738\n",
      "train loss:0.004602687258757562\n",
      "train loss:0.0002905131446247718\n",
      "train loss:0.0024543546019677974\n",
      "train loss:0.013033024563826929\n",
      "train loss:0.0018962214820841309\n",
      "train loss:3.553196057824906e-05\n",
      "train loss:0.00014631646671189156\n",
      "train loss:0.004293177631880339\n",
      "train loss:0.0011429148678444455\n",
      "train loss:6.257554890456158e-05\n",
      "train loss:0.0021574271809518585\n",
      "train loss:0.0021638698532934174\n",
      "train loss:0.00014605161733472714\n",
      "train loss:0.001977979032537011\n",
      "train loss:0.0008776689842362176\n",
      "train loss:0.0026043100489657072\n",
      "train loss:0.00473197687977144\n",
      "train loss:0.002201999798651526\n",
      "train loss:0.00035082954073501995\n",
      "train loss:0.0035827453598090047\n",
      "train loss:0.0024837536716397304\n",
      "train loss:0.0020676369773752127\n",
      "train loss:0.0033352804305858096\n",
      "train loss:0.0009682571957329419\n",
      "train loss:0.000368127825654605\n",
      "train loss:0.0028853100889502316\n",
      "train loss:0.0010070178785465383\n",
      "train loss:0.0021116539939149788\n",
      "train loss:0.005214661916192089\n",
      "train loss:0.0021263896020257624\n",
      "train loss:0.0008350152949623203\n",
      "train loss:0.0024327326469817073\n",
      "train loss:0.00021424388500970994\n",
      "train loss:0.0018829229425665972\n",
      "train loss:0.0009324455906681335\n",
      "train loss:0.00185185147860525\n",
      "train loss:0.003194071231006742\n",
      "train loss:0.0025804458485086117\n",
      "train loss:0.0008468354646621933\n",
      "train loss:0.0014430116835513435\n",
      "train loss:0.0020002691821564577\n",
      "train loss:0.0005969322450455338\n",
      "train loss:0.005434820085410524\n",
      "train loss:0.0016131094699408776\n",
      "train loss:5.964451223697928e-05\n",
      "train loss:0.0005348858107258183\n",
      "train loss:0.001733118686603266\n",
      "train loss:0.0005660598059055543\n",
      "train loss:0.00041207530326245847\n",
      "train loss:0.0005013097239421925\n",
      "train loss:0.0012458109778232312\n",
      "train loss:0.0010427880523072633\n",
      "train loss:6.663495124865668e-05\n",
      "train loss:0.001074976127984635\n",
      "train loss:0.001374997350790255\n",
      "train loss:0.0007904377705578165\n",
      "train loss:0.002004156929058282\n",
      "train loss:0.00018009370410201683\n",
      "train loss:0.0003958343385053423\n",
      "train loss:0.0007775634099142231\n",
      "train loss:0.0031676485085083204\n",
      "train loss:0.0017074932394794086\n",
      "train loss:0.0010265475122422914\n",
      "train loss:0.00028818358610641434\n",
      "train loss:0.0005029389647186242\n",
      "train loss:0.0008854279441179308\n",
      "train loss:0.0006068078034310956\n",
      "train loss:0.00181776827498009\n",
      "train loss:0.00032433236219890844\n",
      "train loss:0.00023025083113472784\n",
      "train loss:0.0012263432382092088\n",
      "train loss:0.0007323928484301286\n",
      "train loss:0.0010762622545048952\n",
      "train loss:0.0013697775743054582\n",
      "train loss:0.0006207256220068113\n",
      "train loss:0.0026436370130614884\n",
      "train loss:0.0005142116273941693\n",
      "train loss:0.00045677026589009966\n",
      "train loss:0.004160938445834667\n",
      "train loss:0.004859679658040504\n",
      "train loss:0.001261287128909227\n",
      "train loss:0.010597877727599575\n",
      "train loss:0.0006999579717792474\n",
      "train loss:0.0023217431684094013\n",
      "train loss:0.004812139961340559\n",
      "train loss:0.001271433826291766\n",
      "train loss:0.001525500684600411\n",
      "train loss:0.0014339803829108513\n",
      "train loss:0.00029359454540285444\n",
      "train loss:3.838355781348971e-05\n",
      "train loss:0.001731872095822758\n",
      "train loss:0.0019761740911876263\n",
      "train loss:0.0008803170423574438\n",
      "train loss:0.015569056432700377\n",
      "train loss:0.003177766758140769\n",
      "train loss:8.855861661312722e-05\n",
      "train loss:0.0011776151348211932\n",
      "train loss:2.4712159170572857e-05\n",
      "train loss:0.00011492729514161325\n",
      "train loss:0.000318159682493869\n",
      "train loss:0.0019316303626087316\n",
      "train loss:0.0006842550337000559\n",
      "train loss:0.00062602802067307\n",
      "train loss:0.0077373384262155245\n",
      "train loss:0.005061492804537813\n",
      "train loss:0.0002630885156191272\n",
      "train loss:0.00012957857621333045\n",
      "train loss:0.0019149193239176613\n",
      "train loss:0.004018464598363383\n",
      "train loss:0.0002408497669046781\n",
      "train loss:0.11250936727923685\n",
      "train loss:0.0021726734296311804\n",
      "train loss:0.001051079519044088\n",
      "train loss:0.004156184098568013\n",
      "train loss:0.0035004371012507846\n",
      "train loss:0.004484909649062703\n",
      "train loss:0.0009463742878752392\n",
      "train loss:0.003224966420556411\n",
      "train loss:0.0022576907298006363\n",
      "train loss:0.0016877701306963527\n",
      "train loss:0.0001635773016951912\n",
      "train loss:0.0002108560314501157\n",
      "train loss:0.0002627780533229933\n",
      "train loss:0.003332108438693168\n",
      "train loss:0.0010405715843401228\n",
      "train loss:0.0034241338214559707\n",
      "train loss:0.0015250273686561006\n",
      "train loss:0.0038433429565924247\n",
      "train loss:0.0009531385467514587\n",
      "train loss:0.0011900831387280885\n",
      "train loss:0.0042671241350919166\n",
      "train loss:0.0009537779250613251\n",
      "train loss:0.0014938038126961495\n",
      "train loss:0.00013217932808064526\n",
      "train loss:0.0012770026275517\n",
      "train loss:0.002876903178901301\n",
      "train loss:0.0025185931413011444\n",
      "train loss:0.00660473979903518\n",
      "train loss:0.0031313708877764783\n",
      "train loss:0.00029889629939533897\n",
      "train loss:0.0018236083839973313\n",
      "train loss:0.0003928058075714821\n",
      "train loss:0.0004673974968111925\n",
      "train loss:0.0002090634262610235\n",
      "train loss:0.02126986312832976\n",
      "train loss:0.00013967563178916696\n",
      "train loss:0.014755621806165228\n",
      "train loss:0.004766658986023956\n",
      "train loss:0.0004420058633218919\n",
      "train loss:0.00013002439178581398\n",
      "train loss:0.00010231166782387474\n",
      "train loss:0.00095877773157782\n",
      "train loss:0.0019849977428541485\n",
      "train loss:0.0008382200062594082\n",
      "train loss:0.012297437588520886\n",
      "train loss:0.004079126174991418\n",
      "train loss:0.0015578717874507432\n",
      "train loss:0.0030624249505224067\n",
      "train loss:0.0018466620292476412\n",
      "train loss:0.014112230071729149\n",
      "train loss:0.000449473663805234\n",
      "train loss:0.0006651584839821779\n",
      "train loss:0.00017431078645854703\n",
      "train loss:0.0024353182532829655\n",
      "train loss:0.0007143208981814088\n",
      "train loss:0.002719733796013536\n",
      "train loss:0.0009237395910997513\n",
      "train loss:0.0015209562852146884\n",
      "train loss:0.0013241800948340023\n",
      "train loss:0.0021773541021240742\n",
      "train loss:0.0017190035219636617\n",
      "train loss:0.0052956225347859905\n",
      "train loss:0.09793189778703645\n",
      "train loss:0.0021284777312744075\n",
      "train loss:0.003446530439966492\n",
      "train loss:0.0005968193467909657\n",
      "train loss:7.34277909947967e-05\n",
      "train loss:0.00023948619754445455\n",
      "train loss:0.0021745443897095667\n",
      "train loss:0.0010289440187483865\n",
      "train loss:0.0010779962521974766\n",
      "train loss:0.0020509490701329258\n",
      "train loss:0.0012017300541578735\n",
      "train loss:0.0017421998526475325\n",
      "train loss:0.0008253099634980742\n",
      "train loss:0.00022045605977355487\n",
      "train loss:0.0021689708722099615\n",
      "train loss:0.003971857390627972\n",
      "train loss:0.0015668768203801527\n",
      "train loss:0.0008312477810202076\n",
      "train loss:6.048524291977659e-05\n",
      "train loss:8.28179078698615e-05\n",
      "train loss:0.0033146581826118786\n",
      "train loss:0.002346717975717995\n",
      "train loss:0.0012634258157299349\n",
      "train loss:0.0008173324167578469\n",
      "train loss:0.0015493876117264188\n",
      "train loss:0.0003509193627860943\n",
      "train loss:0.001141922430535347\n",
      "train loss:0.0002241784075857458\n",
      "train loss:0.0008028718004525684\n",
      "train loss:0.0007967962865903234\n",
      "train loss:0.010957571396683212\n",
      "train loss:0.0022722315322110526\n",
      "train loss:0.00013073855267797395\n",
      "train loss:0.00010429752083987849\n",
      "train loss:0.0019016110029472122\n",
      "train loss:8.234780280635041e-05\n",
      "train loss:0.0005536950143647723\n",
      "train loss:0.00023892282713494417\n",
      "train loss:0.0009285063267685289\n",
      "train loss:0.0008657619534772491\n",
      "train loss:0.00044097772914360146\n",
      "train loss:0.0005227116239655621\n",
      "train loss:0.006492743192726\n",
      "train loss:0.0006351344548710546\n",
      "train loss:0.00033869321388542916\n",
      "train loss:0.00015748692096691778\n",
      "train loss:0.0028866704885070716\n",
      "train loss:0.0006604523274452851\n",
      "train loss:0.0048485836209386105\n",
      "train loss:0.00013381728193959447\n",
      "train loss:0.005764200435926134\n",
      "train loss:0.0010465444345894464\n",
      "train loss:0.0005423610462768023\n",
      "train loss:0.0019604749144029664\n",
      "train loss:0.0020469125787557856\n",
      "train loss:0.002950753438571499\n",
      "train loss:0.0041210274838639985\n",
      "train loss:0.0005304417528877902\n",
      "train loss:0.0030261367914193858\n",
      "train loss:0.0020711384425209003\n",
      "train loss:0.00259763504666249\n",
      "train loss:0.00033892503375286884\n",
      "train loss:0.0011029945329144994\n",
      "train loss:0.0006990752823026642\n",
      "train loss:0.001971921820767449\n",
      "train loss:0.0003395614433709841\n",
      "train loss:0.00027476142995524057\n",
      "train loss:0.005779291864134584\n",
      "train loss:0.0005446768616948538\n",
      "train loss:0.00034840266793391075\n",
      "train loss:0.0012250506384111851\n",
      "train loss:0.002629103908701582\n",
      "train loss:0.0015566540037917828\n",
      "train loss:0.0009020930112418687\n",
      "train loss:0.0003519915001348403\n",
      "train loss:0.0009953662023994355\n",
      "train loss:0.0004467441352340816\n",
      "train loss:0.010143190446975894\n",
      "train loss:0.0019168145788022017\n",
      "train loss:0.0021903802145542823\n",
      "train loss:0.0023886673630218224\n",
      "train loss:0.011295520928519778\n",
      "train loss:0.0033677591073801288\n",
      "train loss:0.0004899108540061002\n",
      "train loss:0.00043166003810642757\n",
      "train loss:0.0006782550364353971\n",
      "train loss:0.012600100323631553\n",
      "train loss:0.0017761568765949616\n",
      "train loss:0.0025254555098908117\n",
      "train loss:0.0018687638186571382\n",
      "train loss:0.0025315605242491796\n",
      "train loss:0.0011562697473615194\n",
      "train loss:0.0006168424879778723\n",
      "train loss:0.0006701775048268416\n",
      "train loss:0.0018523598252303882\n",
      "train loss:0.002092722995140716\n",
      "train loss:0.005747785910829172\n",
      "train loss:0.0008806624217756932\n",
      "=== epoch:17, train acc:1.0, test acc:0.993 ===\n",
      "train loss:0.0060298372135259995\n",
      "train loss:0.0026134227931624205\n",
      "train loss:0.004808497303162428\n",
      "train loss:0.0005539758796106937\n",
      "train loss:0.0003300508374802223\n",
      "train loss:0.0029822452698888635\n",
      "train loss:0.002172124867232783\n",
      "train loss:0.0013339762944233593\n",
      "train loss:0.0003455045302066139\n",
      "train loss:0.0004595517021506055\n",
      "train loss:0.00024621338675275483\n",
      "train loss:0.0024812787047636237\n",
      "train loss:0.0031647127877027785\n",
      "train loss:0.00045214781551944914\n",
      "train loss:0.0019070260022171026\n",
      "train loss:0.00150058453768644\n",
      "train loss:0.0025235961498252333\n",
      "train loss:0.0013482570294687346\n",
      "train loss:0.002079983687608807\n",
      "train loss:0.0008110324807855279\n",
      "train loss:0.0022563388975438328\n",
      "train loss:0.001153993994460742\n",
      "train loss:0.0007639263816866671\n",
      "train loss:0.0018989874386965977\n",
      "train loss:5.7352690927451255e-05\n",
      "train loss:0.00132759379485295\n",
      "train loss:0.0008089418346956401\n",
      "train loss:0.0016071108408591108\n",
      "train loss:0.00971760703646075\n",
      "train loss:7.192498002457763e-05\n",
      "train loss:0.0014692439978178124\n",
      "train loss:0.0026044135353806342\n",
      "train loss:0.000762633783316638\n",
      "train loss:0.002630944102976344\n",
      "train loss:0.0004666103175570173\n",
      "train loss:0.04727660068057563\n",
      "train loss:0.000230530943299505\n",
      "train loss:0.0033170945106136985\n",
      "train loss:0.0005333729460312525\n",
      "train loss:0.002404133938643538\n",
      "train loss:0.00043046105789502735\n",
      "train loss:0.0016849050696740875\n",
      "train loss:0.002232337526567407\n",
      "train loss:0.003103670652152609\n",
      "train loss:0.0002718427969819211\n",
      "train loss:0.002263496832887641\n",
      "train loss:0.00021414791108756597\n",
      "train loss:0.0008113841070148046\n",
      "train loss:0.0016473506927426203\n",
      "train loss:0.003028042469825084\n",
      "train loss:0.0028367522438534844\n",
      "train loss:0.002026057658466039\n",
      "train loss:0.0017636927088374018\n",
      "train loss:0.00017180710695658048\n",
      "train loss:0.007416424155829084\n",
      "train loss:0.0007438970688082385\n",
      "train loss:0.00035958007457665005\n",
      "train loss:0.0013448527920968132\n",
      "train loss:0.0012450175560352005\n",
      "train loss:0.00012941903613769966\n",
      "train loss:0.0007350598801648778\n",
      "train loss:0.00218078908238214\n",
      "train loss:0.0010096019344124178\n",
      "train loss:0.0026538557156258204\n",
      "train loss:4.5049750669447116e-05\n",
      "train loss:0.000535135772091\n",
      "train loss:0.00020622115785708415\n",
      "train loss:0.0011643059161115313\n",
      "train loss:0.001870339666498441\n",
      "train loss:0.001274514453003289\n",
      "train loss:0.002282494258456676\n",
      "train loss:0.0007241185578534749\n",
      "train loss:0.0009774076028205298\n",
      "train loss:0.001299704112441732\n",
      "train loss:0.0005367915134890907\n",
      "train loss:0.0002565356875629934\n",
      "train loss:0.00010830703782110248\n",
      "train loss:0.00016155808024256467\n",
      "train loss:0.00042998564784848815\n",
      "train loss:0.0002546822913769073\n",
      "train loss:0.00033197891121388963\n",
      "train loss:0.003573018392192072\n",
      "train loss:0.0005393896583561281\n",
      "train loss:0.00040277792094358024\n",
      "train loss:6.332788376608738e-05\n",
      "train loss:0.002812962897264774\n",
      "train loss:0.0006989861561807851\n",
      "train loss:0.00012615504577496856\n",
      "train loss:0.002853281514254598\n",
      "train loss:0.0029394632290486427\n",
      "train loss:0.000372972630003838\n",
      "train loss:0.0008407242290637794\n",
      "train loss:0.0003643196876313939\n",
      "train loss:7.328683290310395e-05\n",
      "train loss:0.0016587099240037639\n",
      "train loss:0.002412757726719607\n",
      "train loss:0.0015633232447816994\n",
      "train loss:0.0010151322885023134\n",
      "train loss:0.0007012957280240612\n",
      "train loss:0.011395309994978169\n",
      "train loss:0.006780483724221687\n",
      "train loss:0.0006785792733429638\n",
      "train loss:0.0033295720907340785\n",
      "train loss:0.0006571752830025107\n",
      "train loss:0.001413203963714286\n",
      "train loss:0.00032468897557782063\n",
      "train loss:0.0014362496218797518\n",
      "train loss:0.00031065008605247037\n",
      "train loss:0.0016091891088833659\n",
      "train loss:0.0018181665650696143\n",
      "train loss:0.0005758134329851226\n",
      "train loss:0.000617628491721463\n",
      "train loss:0.0007291952628644742\n",
      "train loss:0.0009670252536117876\n",
      "train loss:0.004328312234789731\n",
      "train loss:0.004469745829000472\n",
      "train loss:0.00012918268856969536\n",
      "train loss:0.0008602028172782311\n",
      "train loss:0.0050968503686603\n",
      "train loss:0.0012987160697517622\n",
      "train loss:0.0003583477437468275\n",
      "train loss:0.007172978454866149\n",
      "train loss:0.0006401411585899462\n",
      "train loss:0.001477552331710896\n",
      "train loss:0.000766014775227329\n",
      "train loss:0.0006143066243810343\n",
      "train loss:0.0009353257880892876\n",
      "train loss:0.00018035176868209653\n",
      "train loss:0.00953929850573347\n",
      "train loss:0.0030465267382701017\n",
      "train loss:8.94410776694686e-05\n",
      "train loss:0.00015602203537486096\n",
      "train loss:0.00383443948385891\n",
      "train loss:0.025502342917232572\n",
      "train loss:0.002041433203263037\n",
      "train loss:0.00561413410611473\n",
      "train loss:0.0009480763781410065\n",
      "train loss:0.0009384504970594382\n",
      "train loss:0.0005241870694038943\n",
      "train loss:0.0062861501208679674\n",
      "train loss:0.005308890433827035\n",
      "train loss:0.0016744153484980456\n",
      "train loss:0.0008966249281829232\n",
      "train loss:0.0006882415445518649\n",
      "train loss:0.007558343598934265\n",
      "train loss:0.0009200093100166679\n",
      "train loss:0.0026501222159159427\n",
      "train loss:0.00026764104261737127\n",
      "train loss:0.007083083249671475\n",
      "train loss:0.003969303856184138\n",
      "train loss:0.000510770838873291\n",
      "train loss:0.0004895230105069187\n",
      "train loss:0.0004740884930370673\n",
      "train loss:0.00029743481137262665\n",
      "train loss:0.00044514583747363225\n",
      "train loss:0.003937018225130522\n",
      "train loss:0.0009193463068247887\n",
      "train loss:0.00039042188643210617\n",
      "train loss:0.005192358541397522\n",
      "train loss:0.0012892464389050152\n",
      "train loss:0.022983554762962544\n",
      "train loss:0.005503314622834091\n",
      "train loss:0.0013797403770841688\n",
      "train loss:0.0005638820815793435\n",
      "train loss:0.0006871119413924779\n",
      "train loss:0.0001872174033329467\n",
      "train loss:0.0009394596115327624\n",
      "train loss:0.001241363357401077\n",
      "train loss:0.00021792792898945554\n",
      "train loss:0.0029101764834466013\n",
      "train loss:0.0036403536235134143\n",
      "train loss:0.007106909306921121\n",
      "train loss:0.00019257486038049863\n",
      "train loss:0.0004897597588431824\n",
      "train loss:0.0004972245159230571\n",
      "train loss:0.0074511332091001855\n",
      "train loss:0.005424749947097778\n",
      "train loss:0.0018756248616816408\n",
      "train loss:0.0004042052668907084\n",
      "train loss:0.00019029505972928306\n",
      "train loss:0.0007727761644366353\n",
      "train loss:0.004494038396095463\n",
      "train loss:0.0004692282288443288\n",
      "train loss:0.0014941224921635188\n",
      "train loss:0.00442180140726196\n",
      "train loss:0.00022269758669061387\n",
      "train loss:0.0034703575986508627\n",
      "train loss:0.0040221330842576545\n",
      "train loss:0.0007869919582186685\n",
      "train loss:0.00021914974410262587\n",
      "train loss:0.0009680923357646654\n",
      "train loss:0.0003478883972550285\n",
      "train loss:0.003936220724418397\n",
      "train loss:0.0012744051440054622\n",
      "train loss:8.211672190347746e-05\n",
      "train loss:0.0036390905189886713\n",
      "train loss:0.0005791131292878977\n",
      "train loss:0.002040307515015366\n",
      "train loss:0.0005505483311727489\n",
      "train loss:0.0016539187804964586\n",
      "train loss:0.004305885490623053\n",
      "train loss:7.684273212859998e-05\n",
      "train loss:0.0016498537228069746\n",
      "train loss:0.0018335667154593816\n",
      "train loss:0.0017514223539946971\n",
      "train loss:0.002412587056685759\n",
      "train loss:7.420155003148465e-05\n",
      "train loss:8.174484889299992e-05\n",
      "train loss:0.0015290948934190678\n",
      "train loss:6.333035399063764e-05\n",
      "train loss:0.0012701494259126185\n",
      "train loss:7.349296341173187e-05\n",
      "train loss:0.0024395668542542956\n",
      "train loss:0.00033045807042097255\n",
      "train loss:0.0010240940136203565\n",
      "train loss:0.00048069371206467857\n",
      "train loss:0.002362977611093371\n",
      "train loss:0.001692496628940811\n",
      "train loss:0.0010497125158995652\n",
      "train loss:0.0003666629995504897\n",
      "train loss:0.0006376962827964279\n",
      "train loss:0.00037347910484219425\n",
      "train loss:0.0011982284764164906\n",
      "train loss:0.0019962677894674328\n",
      "train loss:0.0014298026896967992\n",
      "train loss:0.0003015298581168152\n",
      "train loss:9.828687851283222e-05\n",
      "train loss:0.00014168015747684644\n",
      "train loss:0.0005733244221625646\n",
      "train loss:0.0020266461522543268\n",
      "train loss:7.048947496326004e-05\n",
      "train loss:0.00035961288955712917\n",
      "train loss:0.011803624058090198\n",
      "train loss:0.0012499837757686829\n",
      "train loss:0.004499789800628402\n",
      "train loss:0.0005637508724494203\n",
      "train loss:0.001275518671887867\n",
      "train loss:0.001421174670461301\n",
      "train loss:0.00017334098124725559\n",
      "train loss:0.018559942696332814\n",
      "train loss:0.0020566849478915435\n",
      "train loss:0.0005570668661617867\n",
      "train loss:0.006752535788108347\n",
      "train loss:0.0004144058727390086\n",
      "train loss:0.0012144026673136994\n",
      "train loss:0.007197503695672134\n",
      "train loss:0.0003547100113637728\n",
      "train loss:0.0018779095053036402\n",
      "train loss:0.0027211704573183782\n",
      "train loss:0.03919922630029285\n",
      "train loss:8.51582999549723e-05\n",
      "train loss:0.0008461586212077744\n",
      "train loss:0.0012906770215127218\n",
      "train loss:0.000167952788351928\n",
      "train loss:0.00041865540129739645\n",
      "train loss:0.000665917986219243\n",
      "train loss:0.0008315795820752534\n",
      "train loss:0.0015455889071163062\n",
      "train loss:0.008969281964360023\n",
      "train loss:0.00011186828347364519\n",
      "train loss:0.0001905969778639838\n",
      "train loss:0.001609412482857829\n",
      "train loss:0.00025227175210516193\n",
      "train loss:0.00425239889346322\n",
      "train loss:0.003239987330346688\n",
      "train loss:0.003559170704626075\n",
      "train loss:0.0013145983560086036\n",
      "train loss:0.01038040759713078\n",
      "train loss:0.002286929462206073\n",
      "train loss:9.346969855080849e-05\n",
      "train loss:0.0009335700317503855\n",
      "train loss:0.003979219940120491\n",
      "train loss:0.00878664189025291\n",
      "train loss:0.0010370844810956776\n",
      "train loss:0.000867675854095066\n",
      "train loss:0.0017969093529417324\n",
      "train loss:0.0025222816649098055\n",
      "train loss:0.0010396811067299354\n",
      "train loss:0.0024682339806916826\n",
      "train loss:0.000783541652636719\n",
      "train loss:0.00047737746210835963\n",
      "train loss:0.0003695723041637515\n",
      "train loss:0.0023454840240654347\n",
      "train loss:0.009915256313768238\n",
      "train loss:0.0015634636581082942\n",
      "train loss:0.0008297821130043187\n",
      "train loss:0.03532190107440874\n",
      "train loss:0.0007593483665313136\n",
      "train loss:0.005623670427307442\n",
      "train loss:0.00184157434121205\n",
      "train loss:0.0025802546977186504\n",
      "train loss:0.013408730020660757\n",
      "train loss:0.0015073984324496708\n",
      "train loss:0.0009112316863085208\n",
      "train loss:0.003430780193206753\n",
      "train loss:0.003021699252052519\n",
      "train loss:0.006658588678875963\n",
      "train loss:0.00036211155683177495\n",
      "train loss:0.0018477643563388811\n",
      "train loss:0.0019326913346614696\n",
      "train loss:0.002163868471193874\n",
      "train loss:0.010875304445568064\n",
      "train loss:0.004390468593237076\n",
      "train loss:0.001663131712880595\n",
      "train loss:0.0014791949960114678\n",
      "train loss:0.006302069006877641\n",
      "train loss:0.00013868328598753166\n",
      "train loss:0.0016804092411743022\n",
      "train loss:0.00033243925017381685\n",
      "train loss:0.0014154751320857983\n",
      "train loss:0.006250528265853008\n",
      "train loss:0.009329676845873179\n",
      "train loss:0.0015823558139579244\n",
      "train loss:8.968193110890978e-05\n",
      "train loss:0.00023825775352510437\n",
      "train loss:0.007562512736628245\n",
      "train loss:0.0003496329649339356\n",
      "train loss:0.0020676617262325456\n",
      "train loss:0.0007682020681310327\n",
      "train loss:0.0004912510227868267\n",
      "train loss:0.004671246338435062\n",
      "train loss:0.0029455108679973456\n",
      "train loss:0.00018687007133952026\n",
      "train loss:0.0066740941159936775\n",
      "train loss:0.0014918896934348238\n",
      "train loss:0.0004267429918097672\n",
      "train loss:0.0013061105607697248\n",
      "train loss:0.0035881536252147807\n",
      "train loss:0.006821908571591471\n",
      "train loss:0.0005730304282639776\n",
      "train loss:0.024424406436269874\n",
      "train loss:0.0007899761983503195\n",
      "train loss:0.0005917190390573071\n",
      "train loss:0.002388764408732428\n",
      "train loss:0.005654232623701252\n",
      "train loss:0.0005538847707828667\n",
      "train loss:0.0025057634696901672\n",
      "train loss:0.002792887197019545\n",
      "train loss:0.00012314037186677903\n",
      "train loss:0.0030949613358876005\n",
      "train loss:0.0009519021471402654\n",
      "train loss:0.005073268916159469\n",
      "train loss:0.0034779968019763765\n",
      "train loss:0.0037896725838095745\n",
      "train loss:0.00012231161304933455\n",
      "train loss:0.0010931300005716784\n",
      "train loss:0.0016876739560858836\n",
      "train loss:0.0017115546009430563\n",
      "train loss:0.003965647885279481\n",
      "train loss:0.005124044350511373\n",
      "train loss:0.0017255480054113631\n",
      "train loss:0.004559870917861443\n",
      "train loss:0.002786196570435636\n",
      "train loss:0.0016254150904289413\n",
      "train loss:0.0005107799790067294\n",
      "train loss:0.004824734883533084\n",
      "train loss:0.0009170605481139786\n",
      "train loss:0.0009508273190796996\n",
      "train loss:0.0032040023906611498\n",
      "train loss:0.00011553798154535747\n",
      "train loss:0.0013246515606154777\n",
      "train loss:0.0007012810651994202\n",
      "train loss:0.002384058915362484\n",
      "train loss:0.0016686010996033534\n",
      "train loss:0.0015461352220510496\n",
      "train loss:0.0004605171208783144\n",
      "train loss:0.0016843183882846488\n",
      "train loss:0.003716102868226058\n",
      "train loss:0.0006206564687415455\n",
      "train loss:0.0018714723656998204\n",
      "train loss:0.0005337413388170454\n",
      "train loss:0.004860147811821523\n",
      "train loss:0.0008692990128828758\n",
      "train loss:0.000589051560396688\n",
      "train loss:0.0016076980014062857\n",
      "train loss:0.0036197484771767984\n",
      "train loss:0.0024453692914875574\n",
      "train loss:0.0009416159448046882\n",
      "train loss:0.0027381303212744507\n",
      "train loss:0.00017209395533170592\n",
      "train loss:0.0007824359345056881\n",
      "train loss:0.0020268666711270355\n",
      "train loss:0.00019288330345227712\n",
      "train loss:0.001207680941906314\n",
      "train loss:0.001339384425282597\n",
      "train loss:0.0008266052243726461\n",
      "train loss:3.9520978514324365e-05\n",
      "train loss:0.0013130443347200592\n",
      "train loss:0.0027950946234047203\n",
      "train loss:4.0418359280666e-05\n",
      "train loss:0.003959432613339922\n",
      "train loss:0.0004765462384403194\n",
      "train loss:0.002234439282528064\n",
      "train loss:0.0018845385196651961\n",
      "train loss:0.012700825547375888\n",
      "train loss:0.0018051421405671103\n",
      "train loss:0.0013545154656378394\n",
      "train loss:6.535810998473767e-05\n",
      "train loss:0.00018067327025756064\n",
      "train loss:0.0007750556192971043\n",
      "train loss:0.0004836568588116044\n",
      "train loss:0.00042748413197278486\n",
      "train loss:0.0021319893870239202\n",
      "train loss:0.0003207602250452776\n",
      "train loss:0.0003555717966517221\n",
      "train loss:0.001652926508580659\n",
      "train loss:0.00030992636853433367\n",
      "train loss:0.0008829478747480871\n",
      "train loss:0.004160773951822515\n",
      "train loss:0.0007936233552439569\n",
      "train loss:0.0006073968966832787\n",
      "train loss:0.00017768033893130443\n",
      "train loss:6.600980940593342e-05\n",
      "train loss:0.0014110548257460916\n",
      "train loss:0.00032839581410675856\n",
      "train loss:0.00018891153217289917\n",
      "train loss:0.0004786311196261613\n",
      "train loss:0.0027811890608856974\n",
      "train loss:0.0012843995768192051\n",
      "train loss:0.0013344148645468273\n",
      "train loss:0.0005115838008913116\n",
      "train loss:4.3008907701790426e-05\n",
      "train loss:0.00037322152871074453\n",
      "train loss:0.0020447649056830938\n",
      "train loss:0.0006635414787310265\n",
      "train loss:0.002095000435303738\n",
      "train loss:0.0051707123667331135\n",
      "train loss:3.1653949914421106e-05\n",
      "train loss:9.213561254705778e-05\n",
      "train loss:0.0006012384412831277\n",
      "train loss:0.0004220613088382364\n",
      "train loss:0.0006001245052153076\n",
      "train loss:0.0003870403740586063\n",
      "train loss:0.000998004021669737\n",
      "train loss:0.002923850509498402\n",
      "train loss:0.00010896461247865271\n",
      "train loss:0.0001222426768994876\n",
      "train loss:0.00024311003222073622\n",
      "train loss:0.006584529773027644\n",
      "train loss:0.0009481088423426602\n",
      "train loss:0.00032170334643773625\n",
      "train loss:0.0014522049955266049\n",
      "train loss:4.710136165209661e-05\n",
      "train loss:0.00020914621497491095\n",
      "train loss:0.0008113553820258842\n",
      "train loss:0.0008088886557021119\n",
      "train loss:0.00015145959915779903\n",
      "train loss:0.0011961433379226259\n",
      "train loss:0.00032401418046334383\n",
      "train loss:0.00016156423568682978\n",
      "train loss:0.022051794514931316\n",
      "train loss:0.0001253039715870924\n",
      "train loss:0.00019848792921348216\n",
      "train loss:0.0011397830220618917\n",
      "train loss:0.0008235869996744729\n",
      "train loss:0.002067274926288961\n",
      "train loss:0.00585561696837888\n",
      "train loss:0.002976644198823973\n",
      "train loss:0.003156520973903686\n",
      "train loss:0.00012828298618133878\n",
      "train loss:0.0022291408482437353\n",
      "train loss:0.0017428980821686852\n",
      "train loss:0.0002241903547578801\n",
      "train loss:0.002457207387628864\n",
      "train loss:0.00033352434952323026\n",
      "train loss:0.005563192213791761\n",
      "train loss:0.0038561065662044026\n",
      "train loss:0.003966849914126418\n",
      "train loss:0.0011180399406993389\n",
      "train loss:0.0001802613189293325\n",
      "train loss:0.002801602913796112\n",
      "train loss:0.0011046903415848006\n",
      "train loss:0.0015094269296036652\n",
      "train loss:0.0013714651166109606\n",
      "train loss:0.00018531535858070728\n",
      "train loss:0.003455713891241711\n",
      "train loss:3.6260168590844534e-05\n",
      "train loss:0.00041020362453390803\n",
      "train loss:0.03984884781998598\n",
      "train loss:0.0008279415782917664\n",
      "train loss:0.001889409611789093\n",
      "train loss:0.0005761677607189336\n",
      "train loss:0.00045347849778531546\n",
      "train loss:0.001016102328237469\n",
      "train loss:0.004704960566909311\n",
      "train loss:0.0020358274050956146\n",
      "train loss:0.001494923750230297\n",
      "train loss:0.0007900457948650277\n",
      "train loss:0.0020503041496642742\n",
      "train loss:0.009241743857689631\n",
      "train loss:0.000884013113190286\n",
      "train loss:0.01026104466322352\n",
      "train loss:0.00024979774713291164\n",
      "train loss:0.0009099830691231979\n",
      "train loss:0.00037506557006216767\n",
      "train loss:0.0023921839619271113\n",
      "train loss:0.0010480831803828042\n",
      "train loss:0.0014819513418976927\n",
      "train loss:0.0029047762720364424\n",
      "train loss:0.0014194443689897222\n",
      "train loss:0.0007613553124999943\n",
      "train loss:0.008292556399540603\n",
      "train loss:0.0005486782035972621\n",
      "train loss:8.133887069548965e-05\n",
      "train loss:0.0007370399785496791\n",
      "train loss:6.60095035115758e-05\n",
      "train loss:6.09752342920437e-05\n",
      "train loss:0.0013533946498884399\n",
      "train loss:0.0035503369918996235\n",
      "train loss:0.002901057818140434\n",
      "train loss:0.0005037921219193043\n",
      "train loss:0.00022835035600310297\n",
      "train loss:0.0002622536324377864\n",
      "train loss:0.004583646237259032\n",
      "train loss:0.000514481440012282\n",
      "train loss:0.0012276484000259573\n",
      "train loss:0.0010922017645721635\n",
      "train loss:0.0025933472160884936\n",
      "train loss:0.0031684012345010787\n",
      "train loss:0.0016664597068697135\n",
      "train loss:0.0005627947381592469\n",
      "train loss:0.006491052724915244\n",
      "train loss:3.497717052361054e-05\n",
      "train loss:0.004195495259777225\n",
      "train loss:0.0025992185374467736\n",
      "train loss:0.00020271019369746848\n",
      "train loss:0.00028838795817269497\n",
      "train loss:0.0009559187843570084\n",
      "train loss:0.014668221451836954\n",
      "train loss:4.676261043623008e-05\n",
      "train loss:0.0008809282540880442\n",
      "train loss:0.002039933991021172\n",
      "train loss:0.001345797088654429\n",
      "train loss:0.0002978227573253989\n",
      "train loss:0.0015322468942901466\n",
      "train loss:0.02181893628431708\n",
      "train loss:0.002659286369112791\n",
      "train loss:0.00031730561773728595\n",
      "train loss:0.0012763714705358593\n",
      "train loss:0.002983987416438243\n",
      "train loss:0.0005847416425178125\n",
      "train loss:0.00015370075549991325\n",
      "train loss:0.0035171593701035946\n",
      "train loss:0.0028485319730083324\n",
      "train loss:0.002572928139356297\n",
      "train loss:0.000541754860131113\n",
      "train loss:0.0007661878638070671\n",
      "train loss:0.0003222489267098124\n",
      "train loss:0.0013173909997977941\n",
      "train loss:0.001233500436755327\n",
      "train loss:0.0009327942090597236\n",
      "train loss:0.0015955166269915107\n",
      "train loss:0.0003812165626758151\n",
      "train loss:9.460814054949545e-05\n",
      "train loss:0.00011604311130442691\n",
      "train loss:0.0006101868639985747\n",
      "train loss:0.00026717273579521494\n",
      "train loss:0.0017430291301209263\n",
      "train loss:0.003202239065997775\n",
      "train loss:0.0001535805896146371\n",
      "train loss:0.002734107071065738\n",
      "train loss:0.0021606004718933637\n",
      "train loss:0.0006744634017100197\n",
      "train loss:0.001942762900049668\n",
      "train loss:0.0012085588736325704\n",
      "train loss:3.775709433375269e-06\n",
      "train loss:0.0006893953910808927\n",
      "train loss:0.0003111991243764014\n",
      "train loss:0.0018821506981807035\n",
      "train loss:0.00023889597931599227\n",
      "train loss:0.00507269499766047\n",
      "train loss:0.00021849727874984827\n",
      "train loss:0.005359749629473025\n",
      "train loss:0.0018800852256634984\n",
      "train loss:0.002669388814048256\n",
      "train loss:0.003036098215328651\n",
      "train loss:0.003817219501060158\n",
      "train loss:0.014674649369719217\n",
      "train loss:0.00031586948618104446\n",
      "train loss:0.0003925159396079472\n",
      "train loss:0.00058662178708217\n",
      "train loss:0.0047599486271146865\n",
      "train loss:0.0013866684272207045\n",
      "train loss:0.0006636357943172646\n",
      "train loss:0.000608772290974995\n",
      "train loss:0.0018074110040705472\n",
      "train loss:0.0008853611263340186\n",
      "train loss:0.0023472531851320266\n",
      "train loss:0.0017213772385000767\n",
      "train loss:0.0012228512963195974\n",
      "train loss:0.0005676498937266039\n",
      "train loss:0.0005016048496439986\n",
      "train loss:0.0004315350543547736\n",
      "train loss:0.0004648218321207561\n",
      "train loss:0.0036241525725246738\n",
      "train loss:0.0050604813092687976\n",
      "train loss:0.0011666083855548814\n",
      "train loss:0.0018490957068136881\n",
      "train loss:0.0014261292189529462\n",
      "train loss:0.00030304671814378507\n",
      "=== epoch:18, train acc:0.996, test acc:0.988 ===\n",
      "train loss:5.5276537499412855e-05\n",
      "train loss:0.00031675152816924965\n",
      "train loss:0.008587869689333566\n",
      "train loss:0.007248230023128483\n",
      "train loss:0.002896781926712854\n",
      "train loss:0.002872981797363915\n",
      "train loss:0.005070234467957928\n",
      "train loss:0.00272794206593582\n",
      "train loss:0.004674068400729262\n",
      "train loss:0.0008823778913664928\n",
      "train loss:0.014073504714894063\n",
      "train loss:0.0003363150276195138\n",
      "train loss:0.00015546867332401432\n",
      "train loss:0.00011935345895815336\n",
      "train loss:0.0033906639725292207\n",
      "train loss:0.002703868641955414\n",
      "train loss:0.0019557842286805106\n",
      "train loss:0.0029266473383375846\n",
      "train loss:0.00038628214848815054\n",
      "train loss:0.004085025408821826\n",
      "train loss:0.004796927783024111\n",
      "train loss:0.0008460616056953715\n",
      "train loss:4.7856790635785e-05\n",
      "train loss:5.347732680860052e-05\n",
      "train loss:0.000485613432815839\n",
      "train loss:0.0008399498954078314\n",
      "train loss:0.0014020473424841999\n",
      "train loss:0.0014314587443982638\n",
      "train loss:0.00045838711060659505\n",
      "train loss:0.0021358370650850487\n",
      "train loss:0.001882757367210022\n",
      "train loss:0.0002486081396186901\n",
      "train loss:0.0027867169871709624\n",
      "train loss:0.0006164949477438814\n",
      "train loss:0.0037841010467223298\n",
      "train loss:0.0009869780485680423\n",
      "train loss:0.0026921632738512195\n",
      "train loss:0.0014064757205800322\n",
      "train loss:6.226535581511466e-05\n",
      "train loss:0.005512444070541861\n",
      "train loss:0.0001224862316582755\n",
      "train loss:0.003656252095300343\n",
      "train loss:0.0001514948167546748\n",
      "train loss:0.0006939128926702245\n",
      "train loss:0.0004910632079659764\n",
      "train loss:0.0008801531391461179\n",
      "train loss:0.004061356672249003\n",
      "train loss:0.0001729789942165068\n",
      "train loss:0.0002553633377617898\n",
      "train loss:0.0005526434188629271\n",
      "train loss:0.0007112826139762024\n",
      "train loss:0.003363836623602163\n",
      "train loss:0.0012956108010110537\n",
      "train loss:0.00018186547798983317\n",
      "train loss:0.0009757667749411019\n",
      "train loss:0.0002087360084808169\n",
      "train loss:0.0030409304536258234\n",
      "train loss:0.0033987511099532125\n",
      "train loss:0.0001739712136471552\n",
      "train loss:0.0002545067676278779\n",
      "train loss:0.00245560181024951\n",
      "train loss:0.003256722744832348\n",
      "train loss:8.705192699658701e-05\n",
      "train loss:0.0009282558705429661\n",
      "train loss:6.899442259725652e-05\n",
      "train loss:0.0011825926198483579\n",
      "train loss:0.0007726209896946127\n",
      "train loss:0.000123517759095993\n",
      "train loss:0.0003760185400148875\n",
      "train loss:0.002817426705564288\n",
      "train loss:0.0007064383500878913\n",
      "train loss:0.0014513220633316443\n",
      "train loss:0.014130608159775383\n",
      "train loss:0.00028023709031182455\n",
      "train loss:0.00018792541277963106\n",
      "train loss:0.000521791633422415\n",
      "train loss:0.0033772866061252405\n",
      "train loss:0.0001354484889171727\n",
      "train loss:0.000740336365169745\n",
      "train loss:0.00830096210442315\n",
      "train loss:0.0007841658980625936\n",
      "train loss:0.002721362267070874\n",
      "train loss:0.004024328904921593\n",
      "train loss:0.010909084378456741\n",
      "train loss:0.0005740392959983781\n",
      "train loss:0.0022629437779858926\n",
      "train loss:0.0001004387470280471\n",
      "train loss:0.004430787358503397\n",
      "train loss:0.0028709362141060343\n",
      "train loss:0.0018485701670789346\n",
      "train loss:0.0003072895478169872\n",
      "train loss:0.005219637037443592\n",
      "train loss:0.0013471067615555194\n",
      "train loss:0.0027424096925812284\n",
      "train loss:0.0018156480234134628\n",
      "train loss:0.0003926080329915139\n",
      "train loss:0.0062612508452199855\n",
      "train loss:0.0007826376380652994\n",
      "train loss:0.002094236889707722\n",
      "train loss:0.0012552038243984216\n",
      "train loss:0.00428469729509135\n",
      "train loss:0.0024169560081380125\n",
      "train loss:0.0014798606545494547\n",
      "train loss:0.0003055428237708524\n",
      "train loss:0.0007629714697534754\n",
      "train loss:0.0009009719586930934\n",
      "train loss:0.0028836075724048534\n",
      "train loss:0.0002836725116609114\n",
      "train loss:0.0010993869497347493\n",
      "train loss:0.0008210489452689105\n",
      "train loss:0.0008672477711852993\n",
      "train loss:0.0009563673651541237\n",
      "train loss:0.0008615935541578168\n",
      "train loss:0.01750969745376673\n",
      "train loss:0.0001542412104564997\n",
      "train loss:0.013248048601654898\n",
      "train loss:0.0015402278876610958\n",
      "train loss:0.00043146569048841164\n",
      "train loss:0.002009368894767739\n",
      "train loss:0.0016638138449666753\n",
      "train loss:5.052323905723386e-05\n",
      "train loss:0.006082908769791081\n",
      "train loss:0.0008248735232564426\n",
      "train loss:0.006907625317907038\n",
      "train loss:0.0037879394375079467\n",
      "train loss:0.0009112619900314169\n",
      "train loss:0.0030343561437432254\n",
      "train loss:0.0012181142840762915\n",
      "train loss:0.0032372131226626527\n",
      "train loss:0.006824019505320946\n",
      "train loss:0.010036946130456739\n",
      "train loss:0.0026613478375395044\n",
      "train loss:0.000757097635978714\n",
      "train loss:0.0030217983896913703\n",
      "train loss:0.0009434226948029723\n",
      "train loss:0.005578529401394464\n",
      "train loss:0.007214236206248059\n",
      "train loss:0.0027934434201790136\n",
      "train loss:0.0024657697659306427\n",
      "train loss:0.0005866818112568744\n",
      "train loss:0.0026957079411004036\n",
      "train loss:6.30975190178057e-05\n",
      "train loss:0.0025476336327189208\n",
      "train loss:0.003008966358164061\n",
      "train loss:0.0005904980847117961\n",
      "train loss:0.026360857152227992\n",
      "train loss:0.00043114381032786204\n",
      "train loss:0.0020552956798794595\n",
      "train loss:0.003948973891092326\n",
      "train loss:0.0001510236562127454\n",
      "train loss:0.0003628255128001461\n",
      "train loss:0.0013384255319954894\n",
      "train loss:5.618301166762694e-05\n",
      "train loss:0.00010288721707101616\n",
      "train loss:0.0010042198668410204\n",
      "train loss:0.001052038016115765\n",
      "train loss:0.0011087619798583381\n",
      "train loss:0.001412583300419479\n",
      "train loss:0.0025757665611458314\n",
      "train loss:0.0018654940266202144\n",
      "train loss:0.0018075430545897752\n",
      "train loss:0.00012500386632628872\n",
      "train loss:0.0045404635004409905\n",
      "train loss:0.0034468050556945113\n",
      "train loss:0.0018562768382854556\n",
      "train loss:0.0002323523902350935\n",
      "train loss:0.0003338468621270303\n",
      "train loss:0.03602371997051551\n",
      "train loss:0.0023534905642290972\n",
      "train loss:0.00399814743668657\n",
      "train loss:0.004924233052529953\n",
      "train loss:8.003095801246957e-05\n",
      "train loss:0.0012350440631574192\n",
      "train loss:0.0014586425754075762\n",
      "train loss:0.0005750634926322573\n",
      "train loss:0.0018605064024119688\n",
      "train loss:0.002546675944692325\n",
      "train loss:0.001016732638739639\n",
      "train loss:0.000570429151896571\n",
      "train loss:0.020807199318478912\n",
      "train loss:0.0002035807289858943\n",
      "train loss:0.0015183304609840591\n",
      "train loss:0.0003761528863009018\n",
      "train loss:0.0014387596910781964\n",
      "train loss:0.022077864627311507\n",
      "train loss:0.000189937190567672\n",
      "train loss:0.0009726648259025604\n",
      "train loss:0.005527010886945937\n",
      "train loss:0.0002044814235718236\n",
      "train loss:0.0011440936837306586\n",
      "train loss:0.001578316180763415\n",
      "train loss:0.0020990461510133375\n",
      "train loss:0.00038680815146569495\n",
      "train loss:0.0004562465329782827\n",
      "train loss:0.0016190146614535916\n",
      "train loss:9.906516902117287e-05\n",
      "train loss:0.0004268053834833427\n",
      "train loss:0.004837592458113273\n",
      "train loss:0.00011809754758162386\n",
      "train loss:0.0016068603197817903\n",
      "train loss:0.001929555869398654\n",
      "train loss:0.00041880144712740374\n",
      "train loss:0.002326761977016232\n",
      "train loss:0.00031267637144347804\n",
      "train loss:0.00037393833438908634\n",
      "train loss:0.00024230412201197023\n",
      "train loss:0.0015342251216119605\n",
      "train loss:0.00038588803737424967\n",
      "train loss:0.0002927439352874976\n",
      "train loss:0.0013847552181785413\n",
      "train loss:0.0015845158005962014\n",
      "train loss:0.0005878261641390561\n",
      "train loss:0.0023683983409669694\n",
      "train loss:7.561953980780271e-05\n",
      "train loss:0.000623121910643116\n",
      "train loss:0.00036964478422343107\n",
      "train loss:0.008250911045136726\n",
      "train loss:0.0005432585338662063\n",
      "train loss:0.00015584488913082366\n",
      "train loss:0.0006192534501144524\n",
      "train loss:0.0014738132445143981\n",
      "train loss:0.00209301333207375\n",
      "train loss:0.002713004187132537\n",
      "train loss:0.0011820545765363214\n",
      "train loss:0.002030429433624957\n",
      "train loss:0.001441516938331439\n",
      "train loss:0.02913840537708341\n",
      "train loss:0.0009468590154764457\n",
      "train loss:0.0007168764339790344\n",
      "train loss:0.002436417060144986\n",
      "train loss:0.00030813752419528103\n",
      "train loss:0.004926417863737547\n",
      "train loss:0.0022568181389289736\n",
      "train loss:0.0006392690975163891\n",
      "train loss:0.00015389052822573394\n",
      "train loss:0.003154938406582616\n",
      "train loss:0.006364771000820943\n",
      "train loss:0.0008701139347221883\n",
      "train loss:0.0008005388856822991\n",
      "train loss:0.017207236586724912\n",
      "train loss:0.007027615660357934\n",
      "train loss:0.0019805324005879774\n",
      "train loss:0.0007580733276404004\n",
      "train loss:0.000160776598023363\n",
      "train loss:0.0007545743319214674\n",
      "train loss:5.8683195799691904e-05\n",
      "train loss:0.0006215774124369962\n",
      "train loss:0.0005539416305139047\n",
      "train loss:0.0019042821756150442\n",
      "train loss:0.002100400854465397\n",
      "train loss:0.0004824230785076065\n",
      "train loss:0.0001235601705528527\n",
      "train loss:0.000932600067517972\n",
      "train loss:0.00012420606830355993\n",
      "train loss:0.004392080062888954\n",
      "train loss:0.001464222069247898\n",
      "train loss:0.04699972548484104\n",
      "train loss:0.0006352489433859076\n",
      "train loss:0.0021776587874085167\n",
      "train loss:0.0035138677560176213\n",
      "train loss:0.0004212424211412172\n",
      "train loss:0.00020099525388597576\n",
      "train loss:0.0010043907955068641\n",
      "train loss:0.00017670099316202315\n",
      "train loss:0.00038776126661668725\n",
      "train loss:0.003714513763558414\n",
      "train loss:0.000973718233019589\n",
      "train loss:0.0012123908434652172\n",
      "train loss:0.002632904450908124\n",
      "train loss:0.0020060108796778296\n",
      "train loss:0.002717083593520601\n",
      "train loss:0.0013740153878315225\n",
      "train loss:0.01634274477221741\n",
      "train loss:0.0012966398663602663\n",
      "train loss:0.010287186502724744\n",
      "train loss:0.0014872651270087629\n",
      "train loss:0.0003667072126156015\n",
      "train loss:0.002837082898093541\n",
      "train loss:0.004732734813437609\n",
      "train loss:0.00047594793426555\n",
      "train loss:0.0017945835256722223\n",
      "train loss:0.00046226607053766124\n",
      "train loss:0.00044040932494396687\n",
      "train loss:9.344496927415455e-05\n",
      "train loss:0.0001694097156653873\n",
      "train loss:0.0022628940416824796\n",
      "train loss:0.0018788706622394355\n",
      "train loss:0.0005976799581778036\n",
      "train loss:0.0012621057157045697\n",
      "train loss:0.0030578278266340164\n",
      "train loss:0.00018270867832360094\n",
      "train loss:0.00015093169082450552\n",
      "train loss:0.0019392353479674666\n",
      "train loss:0.0006000939687228222\n",
      "train loss:0.0003147372170898958\n",
      "train loss:0.0023018593965919657\n",
      "train loss:0.0026977239523681236\n",
      "train loss:0.00013382139494536567\n",
      "train loss:0.0071377186565871\n",
      "train loss:0.00028817365274233216\n",
      "train loss:0.0006902226145578346\n",
      "train loss:0.0012918663614440904\n",
      "train loss:0.0008886174472953133\n",
      "train loss:0.00030034965940879324\n",
      "train loss:0.000885340487795429\n",
      "train loss:0.000399822288654228\n",
      "train loss:0.0014323663871105682\n",
      "train loss:0.0010577727332501557\n",
      "train loss:0.0010607283128306862\n",
      "train loss:0.00012879751356811145\n",
      "train loss:0.003143059853952393\n",
      "train loss:0.0056497051563943\n",
      "train loss:4.703341257241392e-05\n",
      "train loss:0.00045323035990783514\n",
      "train loss:0.00029217538209798556\n",
      "train loss:4.030038187979053e-05\n",
      "train loss:3.393742993856141e-05\n",
      "train loss:0.00031609062717395767\n",
      "train loss:5.1454857474228285e-05\n",
      "train loss:2.5062606551180903e-05\n",
      "train loss:2.2789654314849093e-05\n",
      "train loss:0.0009607583877240889\n",
      "train loss:0.00041617983141086954\n",
      "train loss:0.0005757711726687224\n",
      "train loss:0.00022684221339167566\n",
      "train loss:0.003618573531678261\n",
      "train loss:3.671295174483601e-05\n",
      "train loss:0.0010861869587006781\n",
      "train loss:0.0012301921558008847\n",
      "train loss:0.0007956323963576571\n",
      "train loss:0.0002891789108172181\n",
      "train loss:0.00010772471107249722\n",
      "train loss:0.0010991930513249482\n",
      "train loss:0.0017904836501029266\n",
      "train loss:0.001941845582703314\n",
      "train loss:0.0020160405161551436\n",
      "train loss:0.002724565290756209\n",
      "train loss:9.238535550668232e-05\n",
      "train loss:0.00033577011622269905\n",
      "train loss:0.00018360578255416208\n",
      "train loss:0.0016446947723455657\n",
      "train loss:0.00011894080521981437\n",
      "train loss:0.000339735312535867\n",
      "train loss:0.0002254434429715739\n",
      "train loss:1.7783476860477882e-05\n",
      "train loss:0.0013733574246536972\n",
      "train loss:0.0016668012645058223\n",
      "train loss:0.00043742119547064283\n",
      "train loss:0.0017318943291716835\n",
      "train loss:0.0031091501316153815\n",
      "train loss:0.0014595688414101424\n",
      "train loss:0.00023146805369696853\n",
      "train loss:0.00019733821918563942\n",
      "train loss:0.00033586862771731873\n",
      "train loss:0.00020019351302490228\n",
      "train loss:0.0003480853865243758\n",
      "train loss:0.0002216334667409399\n",
      "train loss:0.00021761019628520963\n",
      "train loss:0.002719282590901458\n",
      "train loss:0.00011802095290074029\n",
      "train loss:5.211125140039619e-05\n",
      "train loss:0.0007621185431762605\n",
      "train loss:0.00036885458452146205\n",
      "train loss:0.0007818696384337846\n",
      "train loss:0.0022409304502396415\n",
      "train loss:0.003774473761092568\n",
      "train loss:0.00014952059740348014\n",
      "train loss:0.00025964974703531895\n",
      "train loss:0.0009753831210921123\n",
      "train loss:0.0015468001272267962\n",
      "train loss:0.000735103411876476\n",
      "train loss:0.0018620835862520585\n",
      "train loss:0.00016414932673570036\n",
      "train loss:0.0019994691521249375\n",
      "train loss:8.561437087858663e-05\n",
      "train loss:0.00033304557531240066\n",
      "train loss:0.000637310404965918\n",
      "train loss:0.0004778876894128523\n",
      "train loss:0.0016499373900401904\n",
      "train loss:0.00017493244661622383\n",
      "train loss:0.0006611129154510884\n",
      "train loss:0.0001555297869840246\n",
      "train loss:0.0007419591051565366\n",
      "train loss:0.0014519561609597597\n",
      "train loss:0.001834645268494875\n",
      "train loss:0.0008772703799786066\n",
      "train loss:0.00014503026620652735\n",
      "train loss:0.003082757877164397\n",
      "train loss:0.001841111273078746\n",
      "train loss:0.0003998336476104501\n",
      "train loss:0.0012550895671375056\n",
      "train loss:0.007559147119110197\n",
      "train loss:0.00477924083390522\n",
      "train loss:0.004475005083742042\n",
      "train loss:0.0009308821851950147\n",
      "train loss:0.0005590048089287571\n",
      "train loss:0.004899718238410968\n",
      "train loss:0.003420886701114398\n",
      "train loss:0.003373459128003897\n",
      "train loss:0.0004173484003812781\n",
      "train loss:0.0010057305624202875\n",
      "train loss:0.0038524273381184038\n",
      "train loss:0.0009145410770970397\n",
      "train loss:0.0005540491129041858\n",
      "train loss:0.0006945860653980065\n",
      "train loss:5.822551761718621e-06\n",
      "train loss:0.0030223634871866223\n",
      "train loss:0.00028943122344345833\n",
      "train loss:0.0036342460253123393\n",
      "train loss:0.0001789896863150288\n",
      "train loss:0.04958922839683504\n",
      "train loss:0.0006906576130962433\n",
      "train loss:0.0005394298061573244\n",
      "train loss:0.013263288747744689\n",
      "train loss:0.06089678162985301\n",
      "train loss:0.0016246499487403893\n",
      "train loss:0.002922441317478444\n",
      "train loss:0.00028014521594361345\n",
      "train loss:0.0012490230853645775\n",
      "train loss:0.000545787904253008\n",
      "train loss:0.0012198671088089886\n",
      "train loss:0.003001083217219456\n",
      "train loss:0.004001125991969155\n",
      "train loss:0.000916831983890024\n",
      "train loss:0.0026196874773066693\n",
      "train loss:0.00040532588132058433\n",
      "train loss:0.0005582600966102971\n",
      "train loss:0.002759888789048576\n",
      "train loss:0.00030165808808331576\n",
      "train loss:0.008910784099648995\n",
      "train loss:0.00025578120087833606\n",
      "train loss:0.0002681333657883202\n",
      "train loss:0.0026595485660439342\n",
      "train loss:0.0006056176873967475\n",
      "train loss:0.0002837011675425102\n",
      "train loss:0.001340005273599422\n",
      "train loss:0.0003590452828147991\n",
      "train loss:0.0005167638532871589\n",
      "train loss:0.00914112856189921\n",
      "train loss:0.005439161836183962\n",
      "train loss:0.00337756960437965\n",
      "train loss:0.0020514519296963977\n",
      "train loss:0.000654380678628581\n",
      "train loss:0.0005884210376051964\n",
      "train loss:0.003541690638721866\n",
      "train loss:0.0010101617207723915\n",
      "train loss:0.0019631610277812046\n",
      "train loss:0.0002056696875661714\n",
      "train loss:0.0014716705271731073\n",
      "train loss:0.0003574677255317457\n",
      "train loss:0.00044776732883337065\n",
      "train loss:0.0018567249502891806\n",
      "train loss:0.010736413728122158\n",
      "train loss:0.0003999798882449843\n",
      "train loss:0.001901826635056018\n",
      "train loss:0.002217484193678382\n",
      "train loss:0.0007691563003649947\n",
      "train loss:6.633840912709122e-05\n",
      "train loss:8.260587651903692e-05\n",
      "train loss:0.004194926840495739\n",
      "train loss:0.006395068595537828\n",
      "train loss:0.004822428073418688\n",
      "train loss:0.0031934238961825847\n",
      "train loss:0.0036637183031516052\n",
      "train loss:0.0029635226379308892\n",
      "train loss:0.0011658484559022792\n",
      "train loss:0.002242314183715536\n",
      "train loss:0.003232527236755436\n",
      "train loss:5.082489028874299e-05\n",
      "train loss:0.0019103861410424076\n",
      "train loss:0.0029169400024936336\n",
      "train loss:0.00020258423947429598\n",
      "train loss:0.03010160196443304\n",
      "train loss:0.0016270719329983727\n",
      "train loss:0.002265311319136803\n",
      "train loss:0.002652326500546153\n",
      "train loss:0.030500363721338276\n",
      "train loss:0.0008584838357743139\n",
      "train loss:0.0006807640780984183\n",
      "train loss:0.0004502952598022575\n",
      "train loss:0.0008071733301784428\n",
      "train loss:0.0010693448207214763\n",
      "train loss:0.002645076056851926\n",
      "train loss:0.001062557049100298\n",
      "train loss:0.0010455464710730838\n",
      "train loss:0.0019284089747909617\n",
      "train loss:0.001548432395179202\n",
      "train loss:0.0013665293754189342\n",
      "train loss:0.0004823551984361195\n",
      "train loss:0.0011512480024145992\n",
      "train loss:0.0009420463643600589\n",
      "train loss:0.00041078261824052664\n",
      "train loss:0.0034361802187577828\n",
      "train loss:0.0005079964827930433\n",
      "train loss:0.00017839718633566\n",
      "train loss:0.0006762312009113118\n",
      "train loss:0.00620485243261906\n",
      "train loss:0.0006890011553617324\n",
      "train loss:0.002841576778667764\n",
      "train loss:0.0010469664486144593\n",
      "train loss:5.936044293447607e-05\n",
      "train loss:0.00010225926366232723\n",
      "train loss:0.0011059828424951983\n",
      "train loss:0.0014141425541185993\n",
      "train loss:0.0006346226163678446\n",
      "train loss:0.005647176973090811\n",
      "train loss:0.004861137338804176\n",
      "train loss:0.0004642724999292337\n",
      "train loss:0.0005825739460848856\n",
      "train loss:0.0001780177283905451\n",
      "train loss:0.0011310863292390654\n",
      "train loss:0.0005593245612294831\n",
      "train loss:0.0011741669397762138\n",
      "train loss:0.0017877986539312524\n",
      "train loss:0.00031819361361928205\n",
      "train loss:0.0021023145983790465\n",
      "train loss:0.0032072302308962324\n",
      "train loss:0.00011732389861440315\n",
      "train loss:0.001377269374882572\n",
      "train loss:0.0005601957294622907\n",
      "train loss:0.0024470598459536037\n",
      "train loss:0.00036465524242696714\n",
      "train loss:0.001691057591172329\n",
      "train loss:0.003517647099266817\n",
      "train loss:0.0005255993352698104\n",
      "train loss:0.0028736165282919014\n",
      "train loss:0.0006714467199971221\n",
      "train loss:0.008171978832275568\n",
      "train loss:0.0002778884989547781\n",
      "train loss:0.00021629436874773462\n",
      "train loss:0.004641103637434905\n",
      "train loss:0.0002119659844136728\n",
      "train loss:8.654280706332822e-05\n",
      "train loss:0.002299659018214417\n",
      "train loss:0.0009851594058523042\n",
      "train loss:0.00033273475596320816\n",
      "train loss:0.000604329785502947\n",
      "train loss:0.0015305632654988826\n",
      "train loss:3.2695961824955765e-05\n",
      "train loss:0.00010785856896267799\n",
      "train loss:0.0017784443100581817\n",
      "train loss:0.0007302637483447\n",
      "train loss:0.0015716182378395364\n",
      "train loss:0.0003892317851507614\n",
      "train loss:0.0007037795026146441\n",
      "train loss:0.00033790461915128155\n",
      "train loss:0.001387018681366576\n",
      "train loss:0.0019000005619068288\n",
      "train loss:0.0016259526791100685\n",
      "train loss:0.0019609218922370325\n",
      "train loss:0.002467268407075188\n",
      "train loss:0.002623152692455599\n",
      "train loss:0.00023281386308411645\n",
      "train loss:0.00012310606101680754\n",
      "train loss:0.00011443975212043523\n",
      "train loss:0.0006889478673379443\n",
      "train loss:0.0005187288094631311\n",
      "train loss:0.0007808420699268229\n",
      "train loss:9.205571847301276e-05\n",
      "train loss:0.0003458786253793987\n",
      "train loss:0.0019947312624101253\n",
      "train loss:4.686097720419825e-05\n",
      "train loss:0.0019272445879687282\n",
      "train loss:0.0007472176897586992\n",
      "train loss:9.28388191292011e-05\n",
      "train loss:0.00012020171984324265\n",
      "train loss:0.0038713229525078503\n",
      "train loss:0.00019209499973983944\n",
      "train loss:8.134490393847516e-05\n",
      "train loss:0.0005751707991521811\n",
      "train loss:0.0016818101550505477\n",
      "train loss:0.001640361906906434\n",
      "train loss:0.000960012536918607\n",
      "train loss:0.0005147791746619632\n",
      "train loss:0.00013097678810404577\n",
      "train loss:0.005175266622420362\n",
      "train loss:0.0017311827233150558\n",
      "train loss:0.0008032670471139981\n",
      "train loss:0.0007462852513788937\n",
      "train loss:0.00027101540018694\n",
      "train loss:0.0003294028056653021\n",
      "train loss:0.00033666110654906886\n",
      "train loss:0.0006943377732353247\n",
      "train loss:0.0002024788423566855\n",
      "train loss:0.0010230798989473554\n",
      "train loss:0.0001986881087446644\n",
      "train loss:0.0002958565121169211\n",
      "train loss:7.695834284341301e-06\n",
      "train loss:0.0002905579847747065\n",
      "train loss:0.0008834552252180833\n",
      "train loss:0.001342145519684902\n",
      "train loss:7.123025528429566e-05\n",
      "train loss:0.00017952017314245785\n",
      "train loss:0.0003402372196036712\n",
      "train loss:0.0005150184017259585\n",
      "train loss:0.0036821374707521055\n",
      "train loss:0.00011071940761726543\n",
      "train loss:0.00020220268308937528\n",
      "train loss:2.8924002157445212e-05\n",
      "train loss:0.0001480874655948948\n",
      "=== epoch:19, train acc:0.999, test acc:0.988 ===\n",
      "train loss:0.0007588466738264747\n",
      "train loss:0.00016098349902105683\n",
      "train loss:0.0022052097116049604\n",
      "train loss:0.0005986642254454164\n",
      "train loss:0.003852951199801314\n",
      "train loss:0.0005199754862257873\n",
      "train loss:0.00046087701480813307\n",
      "train loss:0.00043688876634179213\n",
      "train loss:0.0020273988047482525\n",
      "train loss:0.0031326493777354557\n",
      "train loss:0.000169607108718722\n",
      "train loss:0.00010855101484409756\n",
      "train loss:0.0009683990510635649\n",
      "train loss:0.0008097741430796279\n",
      "train loss:0.002077138859243036\n",
      "train loss:0.00017754270520957928\n",
      "train loss:0.0010230130128083955\n",
      "train loss:0.0004730293829017932\n",
      "train loss:0.004120063595988025\n",
      "train loss:0.00035327927684069177\n",
      "train loss:0.0001475777774379753\n",
      "train loss:1.8350387442496663e-05\n",
      "train loss:0.0012359548671903077\n",
      "train loss:0.0013008473048441178\n",
      "train loss:0.00022018605365059008\n",
      "train loss:5.186847262509356e-05\n",
      "train loss:0.00013003992743097642\n",
      "train loss:0.00032234493950038885\n",
      "train loss:0.0007489353922572347\n",
      "train loss:0.00022595977724329045\n",
      "train loss:0.00018232410708016105\n",
      "train loss:0.0015633609801531884\n",
      "train loss:0.0002527759021386315\n",
      "train loss:0.0003120701634366995\n",
      "train loss:0.0016098851168897896\n",
      "train loss:0.00010549345135820225\n",
      "train loss:0.000223150376929333\n",
      "train loss:0.0009526681776087763\n",
      "train loss:0.00011247818435558001\n",
      "train loss:0.000905845049412636\n",
      "train loss:0.00013333882869903858\n",
      "train loss:0.00031953577678791353\n",
      "train loss:0.007744817821069147\n",
      "train loss:0.001063593420842646\n",
      "train loss:0.0027026088638846253\n",
      "train loss:0.000666799081923523\n",
      "train loss:0.0004461421702484342\n",
      "train loss:0.0006422798061616449\n",
      "train loss:8.592410291732145e-05\n",
      "train loss:0.00032607511100545434\n",
      "train loss:0.00014969665835807067\n",
      "train loss:3.3830108022297656e-05\n",
      "train loss:0.0007438529071262047\n",
      "train loss:0.0006288427241404166\n",
      "train loss:1.176049798467886e-05\n",
      "train loss:0.00020434196345988278\n",
      "train loss:0.0004540740784632592\n",
      "train loss:6.458636505101715e-05\n",
      "train loss:0.0029625279547827754\n",
      "train loss:0.00021489645507810997\n",
      "train loss:0.0011467070033517137\n",
      "train loss:0.0003633760817611767\n",
      "train loss:0.004957628611303338\n",
      "train loss:0.00019663634367701678\n",
      "train loss:0.002643277957967022\n",
      "train loss:0.00011823877216406946\n",
      "train loss:0.0013972098480763318\n",
      "train loss:0.00011706060854640895\n",
      "train loss:0.00042799885509592144\n",
      "train loss:0.01310231109402356\n",
      "train loss:0.00022745699167006018\n",
      "train loss:7.395901808260471e-05\n",
      "train loss:0.00011286719733442623\n",
      "train loss:0.0015786488309315401\n",
      "train loss:0.0003676675849028413\n",
      "train loss:0.0004818510279025348\n",
      "train loss:0.001771528187132048\n",
      "train loss:0.0020865532664145403\n",
      "train loss:0.010276330278282913\n",
      "train loss:0.00036182922479644777\n",
      "train loss:0.004148946422347245\n",
      "train loss:0.015649322087432273\n",
      "train loss:0.0008757891558820386\n",
      "train loss:0.00017085625703976276\n",
      "train loss:0.0001273575470973228\n",
      "train loss:0.0043078210974673925\n",
      "train loss:0.00020004612603165064\n",
      "train loss:0.007739773185692416\n",
      "train loss:0.0008000360517520852\n",
      "train loss:0.0015745472749272105\n",
      "train loss:0.00029995430527311056\n",
      "train loss:0.0005079065725337723\n",
      "train loss:0.001832527850347717\n",
      "train loss:7.442028821086019e-05\n",
      "train loss:0.0018852230907085582\n",
      "train loss:0.0006964671430071003\n",
      "train loss:9.867830626214854e-05\n",
      "train loss:0.00023051139359646966\n",
      "train loss:0.00419536560504308\n",
      "train loss:0.0005147188544277835\n",
      "train loss:0.0012879297018219323\n",
      "train loss:0.003612419266696773\n",
      "train loss:0.0018090502012756198\n",
      "train loss:0.000270152733042948\n",
      "train loss:0.00023219050049436775\n",
      "train loss:0.00048792535782362436\n",
      "train loss:0.003036138408142044\n",
      "train loss:4.4531841856162104e-05\n",
      "train loss:5.030589146994968e-05\n",
      "train loss:0.0006919250039307862\n",
      "train loss:0.0006631659736228268\n",
      "train loss:0.0009391470856861856\n",
      "train loss:0.001149362927379605\n",
      "train loss:4.825308832356767e-05\n",
      "train loss:7.479142377930262e-05\n",
      "train loss:0.0005300982842156782\n",
      "train loss:0.0002386517121196129\n",
      "train loss:0.0005043174360398861\n",
      "train loss:0.0020424326078986505\n",
      "train loss:0.0008053312270981115\n",
      "train loss:7.611068139159044e-05\n",
      "train loss:0.0016067843255451136\n",
      "train loss:0.0006595891811420544\n",
      "train loss:0.0011273353373655868\n",
      "train loss:1.810000626334293e-05\n",
      "train loss:0.001156435684548962\n",
      "train loss:0.0013470483676763711\n",
      "train loss:0.002715733871364353\n",
      "train loss:0.0010067273557836766\n",
      "train loss:0.00235752843491496\n",
      "train loss:0.0014240566153031276\n",
      "train loss:0.0030851963084486803\n",
      "train loss:0.001040716441971959\n",
      "train loss:0.0018918127893626279\n",
      "train loss:0.0006593269427358328\n",
      "train loss:0.0008290464858606066\n",
      "train loss:6.739852904327332e-05\n",
      "train loss:0.0005094248873619939\n",
      "train loss:0.0036408490934534752\n",
      "train loss:0.0008692101068386995\n",
      "train loss:0.030069377188479494\n",
      "train loss:0.0006516234777769721\n",
      "train loss:0.003417018437646283\n",
      "train loss:0.003924894578568211\n",
      "train loss:0.003509724443960273\n",
      "train loss:0.0023640409038159934\n",
      "train loss:0.0007295491226207841\n",
      "train loss:5.229427854243693e-05\n",
      "train loss:0.00019296159228371452\n",
      "train loss:0.000231767246091046\n",
      "train loss:0.0008005935008643652\n",
      "train loss:0.001469712669759955\n",
      "train loss:0.00042738736181143085\n",
      "train loss:0.00015489195242169757\n",
      "train loss:0.002003439307158739\n",
      "train loss:0.0010159261814866427\n",
      "train loss:0.0005320318972944063\n",
      "train loss:0.004192868497324649\n",
      "train loss:0.000484781119757088\n",
      "train loss:0.0005945690495603748\n",
      "train loss:0.00012850828564424586\n",
      "train loss:0.0007814403115967999\n",
      "train loss:0.001264078421537472\n",
      "train loss:0.001372424329630101\n",
      "train loss:0.0005422438712319967\n",
      "train loss:0.002064277561421895\n",
      "train loss:0.00033812991392585736\n",
      "train loss:0.0029748166134805835\n",
      "train loss:0.00011802901084413599\n",
      "train loss:0.001350932978975089\n",
      "train loss:5.840320658213851e-05\n",
      "train loss:0.022520901513009863\n",
      "train loss:0.0001603780154867583\n",
      "train loss:0.0007815763066248149\n",
      "train loss:0.0002783800294962101\n",
      "train loss:0.0008865346548116912\n",
      "train loss:0.0011726981220523236\n",
      "train loss:0.0016435219035161818\n",
      "train loss:0.001398962885862276\n",
      "train loss:0.00596556427705482\n",
      "train loss:0.0012636650356182427\n",
      "train loss:0.000815237632767795\n",
      "train loss:0.0007402500454397207\n",
      "train loss:0.006238138549904028\n",
      "train loss:0.0027417163729477885\n",
      "train loss:0.004895547026313587\n",
      "train loss:0.003070266289996071\n",
      "train loss:0.0003880621597643472\n",
      "train loss:0.00040370584365258147\n",
      "train loss:0.0031228317022248915\n",
      "train loss:0.004816383203557042\n",
      "train loss:0.003332620803918509\n",
      "train loss:0.0005335302282355418\n",
      "train loss:0.002076175457373525\n",
      "train loss:9.471017383355139e-05\n",
      "train loss:0.005139320211534412\n",
      "train loss:0.0012479555620156775\n",
      "train loss:0.005513585172485275\n",
      "train loss:0.0016674174689489923\n",
      "train loss:0.0008354657274077691\n",
      "train loss:0.0003570576474329734\n",
      "train loss:0.001828309256341441\n",
      "train loss:8.261949474559546e-05\n",
      "train loss:0.0020678534444220614\n",
      "train loss:0.000604782631163696\n",
      "train loss:0.0032979898155282798\n",
      "train loss:0.0010344763774714763\n",
      "train loss:0.0032588327540867133\n",
      "train loss:0.00037792133016604384\n",
      "train loss:0.010355230616191478\n",
      "train loss:0.0002464081454455928\n",
      "train loss:0.0003215887001557897\n",
      "train loss:0.0008006987899064973\n",
      "train loss:0.0021712421718365293\n",
      "train loss:0.0005750618500904755\n",
      "train loss:0.0033679933939881695\n",
      "train loss:0.001598806600855488\n",
      "train loss:0.0028840515231570883\n",
      "train loss:0.0003142395010952498\n",
      "train loss:0.0005635771418665569\n",
      "train loss:0.0008486493322058539\n",
      "train loss:0.0024968585788119587\n",
      "train loss:0.005953428416681639\n",
      "train loss:0.00027872285848972545\n",
      "train loss:0.0028606859362850924\n",
      "train loss:0.00039777114385539775\n",
      "train loss:8.860446971367785e-05\n",
      "train loss:0.0018922906683129874\n",
      "train loss:0.00259600710377394\n",
      "train loss:0.0018094154421581061\n",
      "train loss:0.0018275131873858863\n",
      "train loss:0.0009085573518995667\n",
      "train loss:0.00014309269279205795\n",
      "train loss:0.0002793188241134749\n",
      "train loss:0.001792802973257198\n",
      "train loss:0.00018199001780487746\n",
      "train loss:3.175127112003992e-05\n",
      "train loss:0.0006155995024717135\n",
      "train loss:0.0017726723131362434\n",
      "train loss:2.4637399318827246e-05\n",
      "train loss:0.00020603467001890468\n",
      "train loss:0.0020096821790062005\n",
      "train loss:4.4391847067669136e-05\n",
      "train loss:0.0003030118583372985\n",
      "train loss:0.002201684984309019\n",
      "train loss:0.0037090432154019766\n",
      "train loss:0.0007022864678070366\n",
      "train loss:0.0004678116166187563\n",
      "train loss:0.00038959050776107243\n",
      "train loss:0.0004696441391624669\n",
      "train loss:0.0014964140055589712\n",
      "train loss:4.790929999445857e-05\n",
      "train loss:0.00011284467743449808\n",
      "train loss:0.0009662393995299905\n",
      "train loss:0.0005312191904207015\n",
      "train loss:0.0011648978295944812\n",
      "train loss:0.004362974309140189\n",
      "train loss:0.00017552855520436817\n",
      "train loss:7.409005104545836e-05\n",
      "train loss:5.218815549658635e-05\n",
      "train loss:0.0025738220594103624\n",
      "train loss:0.0006252267950411874\n",
      "train loss:9.556853009623228e-05\n",
      "train loss:0.001468855460833761\n",
      "train loss:0.0016929036047210568\n",
      "train loss:0.0005138305607936337\n",
      "train loss:0.004147823219862331\n",
      "train loss:0.0014513164024712183\n",
      "train loss:0.002326003535217721\n",
      "train loss:0.00885726176452281\n",
      "train loss:0.0014463985035397691\n",
      "train loss:0.00044193666174978754\n",
      "train loss:0.00023662775021212197\n",
      "train loss:6.08527959482789e-05\n",
      "train loss:0.002751674160190095\n",
      "train loss:0.00011124557439151558\n",
      "train loss:0.003457910047114196\n",
      "train loss:0.0019243855810928562\n",
      "train loss:0.0001321286474006185\n",
      "train loss:0.002030494769107307\n",
      "train loss:0.00039459873236165983\n",
      "train loss:0.012054835814216064\n",
      "train loss:0.0011632143567226\n",
      "train loss:0.00014951806555179518\n",
      "train loss:3.4795960436808176e-05\n",
      "train loss:0.00010900079269779076\n",
      "train loss:3.4341092568823086e-05\n",
      "train loss:0.0007723802063747647\n",
      "train loss:0.0036608531475357405\n",
      "train loss:0.0015323746873091237\n",
      "train loss:0.0016870653473845738\n",
      "train loss:0.000493771642367915\n",
      "train loss:0.00031158923361458176\n",
      "train loss:0.0019074604404701106\n",
      "train loss:0.00014002500050912516\n",
      "train loss:0.00014881611299265155\n",
      "train loss:0.00013064667387477943\n",
      "train loss:0.0016651134636773573\n",
      "train loss:0.0010690603017390462\n",
      "train loss:0.000904654196321955\n",
      "train loss:0.002129358070026609\n",
      "train loss:0.006274975167900824\n",
      "train loss:0.0011566661282779603\n",
      "train loss:7.600645925861901e-05\n",
      "train loss:0.0014932575328126274\n",
      "train loss:0.0009829844145537142\n",
      "train loss:0.0012893872893228076\n",
      "train loss:0.0001773227417512705\n",
      "train loss:0.0012676337797232371\n",
      "train loss:0.00023888414864156254\n",
      "train loss:4.7444383200068806e-05\n",
      "train loss:0.00028964874770368693\n",
      "train loss:0.0006789613872120364\n",
      "train loss:0.00019653983776110834\n",
      "train loss:0.004617558703478879\n",
      "train loss:0.003126837469665097\n",
      "train loss:0.0002619593971745843\n",
      "train loss:0.0008743986046896781\n",
      "train loss:0.00032865195285530254\n",
      "train loss:0.00014348598036831382\n",
      "train loss:6.675295620398054e-05\n",
      "train loss:0.002078810627961178\n",
      "train loss:0.0015862565092975862\n",
      "train loss:8.612849656242127e-05\n",
      "train loss:0.0007759604828463691\n",
      "train loss:0.01922339063493709\n",
      "train loss:4.998208956258856e-05\n",
      "train loss:0.0009202534156107324\n",
      "train loss:0.007387663580215107\n",
      "train loss:0.00016996655602592728\n",
      "train loss:5.261337447895497e-05\n",
      "train loss:0.00010059339936503231\n",
      "train loss:0.003774117011961428\n",
      "train loss:0.0014149868227396401\n",
      "train loss:0.00018669310850406073\n",
      "train loss:0.0005335969127885451\n",
      "train loss:0.00027106050328984057\n",
      "train loss:0.0006998861185161927\n",
      "train loss:0.003098998499442255\n",
      "train loss:0.0023756358624968097\n",
      "train loss:0.0013212100886394484\n",
      "train loss:0.0012009905597299537\n",
      "train loss:0.0009045296008149016\n",
      "train loss:0.0011115234121478073\n",
      "train loss:0.003282032008553057\n",
      "train loss:0.0009699768710706712\n",
      "train loss:0.0011772902363042835\n",
      "train loss:0.00047717789263792046\n",
      "train loss:0.0007068650208111039\n",
      "train loss:0.0005311117990114275\n",
      "train loss:0.0004707467462254448\n",
      "train loss:0.005116490248611374\n",
      "train loss:0.0037746127984809408\n",
      "train loss:0.0011545743616632404\n",
      "train loss:0.0009380708109692596\n",
      "train loss:0.0014988184006786446\n",
      "train loss:0.00022437275017739267\n",
      "train loss:0.14197550056575414\n",
      "train loss:0.0005761207123059402\n",
      "train loss:7.374684215106833e-05\n",
      "train loss:0.00014199873308568434\n",
      "train loss:0.0009091647622097839\n",
      "train loss:0.001722262712253533\n",
      "train loss:0.0005050227695858247\n",
      "train loss:0.0022684648530381137\n",
      "train loss:0.00019699725840897577\n",
      "train loss:0.0012962770480669428\n",
      "train loss:0.00016363754765363027\n",
      "train loss:0.005445901265762375\n",
      "train loss:0.0006105041512028041\n",
      "train loss:0.0003422051822851667\n",
      "train loss:0.0007755122719838179\n",
      "train loss:0.0007538603105008082\n",
      "train loss:0.0022952694093336867\n",
      "train loss:0.0014453150491113885\n",
      "train loss:0.0031824745822402346\n",
      "train loss:0.0021017826790287034\n",
      "train loss:1.5386288055378078e-05\n",
      "train loss:0.0013639631456133423\n",
      "train loss:0.0001096036436910296\n",
      "train loss:0.010816320443495954\n",
      "train loss:0.005209907391290337\n",
      "train loss:0.00680497306496009\n",
      "train loss:0.0007835695205524274\n",
      "train loss:0.003376684295583539\n",
      "train loss:0.0002053336893445884\n",
      "train loss:0.0003657722513050238\n",
      "train loss:0.003045192936489043\n",
      "train loss:0.009299787983158982\n",
      "train loss:0.000344754442659786\n",
      "train loss:0.0006528826585615115\n",
      "train loss:0.00671594763107531\n",
      "train loss:0.0011698361928666092\n",
      "train loss:0.0011908025563656124\n",
      "train loss:0.000491022501586599\n",
      "train loss:0.0008291754577123693\n",
      "train loss:0.0014789508005946283\n",
      "train loss:0.0004537702124456944\n",
      "train loss:0.0009026766858314972\n",
      "train loss:0.0011444739595308346\n",
      "train loss:0.003597462314594257\n",
      "train loss:2.032735837325169e-05\n",
      "train loss:0.002847501987957732\n",
      "train loss:0.0002565223329252462\n",
      "train loss:0.000204545550421689\n",
      "train loss:0.0012455284398751145\n",
      "train loss:0.0018174875909882809\n",
      "train loss:0.004278888400316819\n",
      "train loss:0.00015775176372159337\n",
      "train loss:0.00020493714657925178\n",
      "train loss:0.002822115659387566\n",
      "train loss:0.0002460148700084222\n",
      "train loss:4.539535004545895e-05\n",
      "train loss:0.0003373750520958268\n",
      "train loss:0.0004908006470305759\n",
      "train loss:0.0003262472423772623\n",
      "train loss:0.0005044782034463877\n",
      "train loss:0.0003154750290187682\n",
      "train loss:0.0002802112473309246\n",
      "train loss:0.0006958862859588151\n",
      "train loss:0.0024447405461449174\n",
      "train loss:0.00020879070108089086\n",
      "train loss:0.0014063676172776575\n",
      "train loss:0.0015543507003151359\n",
      "train loss:0.0013220416007158988\n",
      "train loss:0.0006117627736692152\n",
      "train loss:0.0020592887515682775\n",
      "train loss:0.0002802836947659703\n",
      "train loss:0.0025888628116714357\n",
      "train loss:0.0002652416270403712\n",
      "train loss:0.0007458164888620249\n",
      "train loss:0.0008380111277485064\n",
      "train loss:0.00011123287163714422\n",
      "train loss:0.000258048826333695\n",
      "train loss:0.00015347583227818802\n",
      "train loss:0.0012428114022527636\n",
      "train loss:0.0012154790302000007\n",
      "train loss:0.0008781283722850916\n",
      "train loss:0.0003476467805622032\n",
      "train loss:0.001069812115869615\n",
      "train loss:0.0003911552724332984\n",
      "train loss:0.0007715029951108437\n",
      "train loss:0.002150901310154883\n",
      "train loss:0.005355299994251432\n",
      "train loss:0.00023271250169730893\n",
      "train loss:0.0008780362241397752\n",
      "train loss:0.0013572026995535332\n",
      "train loss:9.879838078153675e-05\n",
      "train loss:2.171037556483067e-05\n",
      "train loss:0.00039425518018034394\n",
      "train loss:0.0018925084468521458\n",
      "train loss:0.004182088873595626\n",
      "train loss:0.00010140410476962683\n",
      "train loss:6.211106541263332e-05\n",
      "train loss:0.00045019896663132117\n",
      "train loss:0.0006496974339120736\n",
      "train loss:0.0029182886527146894\n",
      "train loss:0.0007034206996506215\n",
      "train loss:2.466430299670301e-05\n",
      "train loss:0.0012239273437183841\n",
      "train loss:0.0008798803096623623\n",
      "train loss:2.5810395008199417e-05\n",
      "train loss:0.00018829791791316115\n",
      "train loss:0.012822552883719725\n",
      "train loss:0.001382164214568128\n",
      "train loss:0.0004505742479024091\n",
      "train loss:0.000827794084011263\n",
      "train loss:6.428642888125614e-05\n",
      "train loss:0.0056371453837325645\n",
      "train loss:0.0018919609497709486\n",
      "train loss:0.0006288052436964068\n",
      "train loss:0.0020568697533255046\n",
      "train loss:0.001303143861472725\n",
      "train loss:0.0005717517292524628\n",
      "train loss:0.003980996659213717\n",
      "train loss:0.001715583341189536\n",
      "train loss:0.00023087923138644478\n",
      "train loss:0.0003404001505882636\n",
      "train loss:0.001265448380443501\n",
      "train loss:0.00028492161074005477\n",
      "train loss:0.000280178836101809\n",
      "train loss:0.00037755200314191427\n",
      "train loss:0.0009224932029115057\n",
      "train loss:0.0006478288361174736\n",
      "train loss:0.0003223298825780881\n",
      "train loss:0.00032264940426740026\n",
      "train loss:0.0020480744862523413\n",
      "train loss:0.0008313334110349709\n",
      "train loss:0.001037280399601062\n",
      "train loss:0.0004539886867890385\n",
      "train loss:0.00013057412899778107\n",
      "train loss:0.000544890060262104\n",
      "train loss:0.0026415889999106736\n",
      "train loss:0.006446941172777123\n",
      "train loss:0.003146945618792137\n",
      "train loss:0.0017657291736374366\n",
      "train loss:0.00036643543508428145\n",
      "train loss:0.00036971892455610984\n",
      "train loss:0.0030245266916116924\n",
      "train loss:0.004882512289946617\n",
      "train loss:0.0001692732783943027\n",
      "train loss:0.00023260066307105094\n",
      "train loss:0.000315917091453169\n",
      "train loss:0.001560799211607463\n",
      "train loss:0.003858007566448668\n",
      "train loss:0.00021759981109041224\n",
      "train loss:0.00045865234561079013\n",
      "train loss:0.002145792041576183\n",
      "train loss:0.0005619440652572771\n",
      "train loss:0.0034203777677638413\n",
      "train loss:0.0020534893635675427\n",
      "train loss:0.0004059425096756552\n",
      "train loss:0.0005510134553137955\n",
      "train loss:0.004864461384488111\n",
      "train loss:6.0386689810112305e-05\n",
      "train loss:0.00011156195925799046\n",
      "train loss:0.0046969938505614945\n",
      "train loss:3.783314391575097e-05\n",
      "train loss:0.00019937486899400316\n",
      "train loss:0.000526790187752454\n",
      "train loss:0.00011165521133606008\n",
      "train loss:0.00021360459333594203\n",
      "train loss:0.0008420235189953644\n",
      "train loss:0.0006189136838933066\n",
      "train loss:0.0008837541531883614\n",
      "train loss:0.0005142942952434704\n",
      "train loss:0.0005465041806518184\n",
      "train loss:0.0010336499425578917\n",
      "train loss:2.308961190172274e-05\n",
      "train loss:0.0003979800724673743\n",
      "train loss:0.0002891851407620759\n",
      "train loss:2.3497817000111233e-05\n",
      "train loss:0.00017040641379087652\n",
      "train loss:0.0018873245912869863\n",
      "train loss:0.00042026059096282993\n",
      "train loss:0.0050544637957100225\n",
      "train loss:0.002866090176252416\n",
      "train loss:0.00510134746557545\n",
      "train loss:0.004480470699681203\n",
      "train loss:0.006176044734645591\n",
      "train loss:0.0008809777997741597\n",
      "train loss:0.00016316566639610534\n",
      "train loss:5.075388762447357e-05\n",
      "train loss:0.001890440706129218\n",
      "train loss:0.003863002660644233\n",
      "train loss:0.0005487318138579466\n",
      "train loss:0.0013690698802155043\n",
      "train loss:0.0034627734818791335\n",
      "train loss:0.00024382083551511118\n",
      "train loss:0.00043209416793270767\n",
      "train loss:0.0005209996076599165\n",
      "train loss:4.649944979660731e-05\n",
      "train loss:0.0002006243816364466\n",
      "train loss:0.00023259968587029708\n",
      "train loss:0.00156255614989777\n",
      "train loss:0.0006586161268152407\n",
      "train loss:0.0007474300431488315\n",
      "train loss:0.001951734067736578\n",
      "train loss:0.00023099497974926053\n",
      "train loss:6.523340912458713e-05\n",
      "train loss:0.0013599674647807225\n",
      "train loss:0.0009232969308428492\n",
      "train loss:0.001008608534063322\n",
      "train loss:0.0020651245511323422\n",
      "train loss:0.0018052432859205663\n",
      "train loss:0.001805110168971427\n",
      "train loss:0.0012029972588488084\n",
      "train loss:0.0007660967427468545\n",
      "train loss:0.0023394306268241833\n",
      "train loss:5.793578032445841e-05\n",
      "train loss:0.0005490395731594502\n",
      "train loss:0.0012435216059356843\n",
      "train loss:0.0002201562087313868\n",
      "train loss:0.0008686347063420974\n",
      "train loss:0.00058322687244822\n",
      "train loss:0.0006656220931940679\n",
      "train loss:0.019936471337204473\n",
      "train loss:0.0002852995379401891\n",
      "train loss:0.0012324254972830098\n",
      "train loss:0.001176087646951814\n",
      "train loss:0.0022397768101836478\n",
      "train loss:0.00020913286846692015\n",
      "train loss:0.0001828589099066746\n",
      "train loss:0.0014295633995543699\n",
      "train loss:0.00013946454962056182\n",
      "train loss:0.00015499020845561112\n",
      "train loss:8.458099337922886e-05\n",
      "train loss:0.004369359012725517\n",
      "train loss:0.0003918868399521707\n",
      "train loss:0.0022679956319983457\n",
      "train loss:0.0012326486310644867\n",
      "train loss:0.003217464139215896\n",
      "train loss:8.482383638782883e-05\n",
      "train loss:0.00016201634277695587\n",
      "train loss:0.00011916714492804743\n",
      "train loss:0.0005289369858147681\n",
      "train loss:9.302112136829165e-05\n",
      "train loss:0.0008031367073656187\n",
      "train loss:0.0003001759734088955\n",
      "train loss:0.00036203979766598294\n",
      "=== epoch:20, train acc:0.997, test acc:0.99 ===\n",
      "train loss:0.0001043555293390077\n",
      "train loss:0.0003358870253610687\n",
      "train loss:0.0003961245894438538\n",
      "train loss:0.0003269891902565773\n",
      "train loss:0.0014032337244195272\n",
      "train loss:6.867499978721477e-05\n",
      "train loss:0.00026014262588225557\n",
      "train loss:3.9604987259476965e-05\n",
      "train loss:0.002485044768081106\n",
      "train loss:0.001923436375015436\n",
      "train loss:0.00295322390352833\n",
      "train loss:0.015092409548204212\n",
      "train loss:0.00015015384108468368\n",
      "train loss:0.00030962348668782147\n",
      "train loss:3.726786005456032e-05\n",
      "train loss:0.0001825489605454129\n",
      "train loss:0.0008855482263083208\n",
      "train loss:0.0005677373797562859\n",
      "train loss:0.0001994708885043661\n",
      "train loss:0.011022494371671196\n",
      "train loss:0.000867345594031491\n",
      "train loss:2.4787428387192217e-05\n",
      "train loss:0.0008599053999762615\n",
      "train loss:0.0008721899089783499\n",
      "train loss:0.00024051780029209563\n",
      "train loss:0.0037694746039871135\n",
      "train loss:0.0015646896511928529\n",
      "train loss:0.0017689207805043252\n",
      "train loss:0.001705135500916898\n",
      "train loss:0.0005054999001460664\n",
      "train loss:0.007764656605450587\n",
      "train loss:0.0002902571810213667\n",
      "train loss:0.000309637802452761\n",
      "train loss:0.0003503623501062412\n",
      "train loss:0.00031072710012399444\n",
      "train loss:0.00028478983752862954\n",
      "train loss:0.0007928378392523318\n",
      "train loss:0.0014963487858073287\n",
      "train loss:0.001697900223488259\n",
      "train loss:0.00023171761999069725\n",
      "train loss:0.00030622877984549343\n",
      "train loss:0.00019828613755869088\n",
      "train loss:0.0005988874378337497\n",
      "train loss:0.00031112045930683303\n",
      "train loss:0.0008554738258128383\n",
      "train loss:0.0009221557278583891\n",
      "train loss:0.001112143853652514\n",
      "train loss:0.002652896648269888\n",
      "train loss:0.0009673489366484258\n",
      "train loss:0.0005340912745065166\n",
      "train loss:0.0002776257473748573\n",
      "train loss:7.623750096933578e-05\n",
      "train loss:0.0002345347984246693\n",
      "train loss:0.0008001349797236838\n",
      "train loss:0.00026118932134635317\n",
      "train loss:0.0023293805292548516\n",
      "train loss:0.0009167383804115383\n",
      "train loss:0.0005088056504800751\n",
      "train loss:0.00031640789745984233\n",
      "train loss:0.0010811035141836576\n",
      "train loss:0.0001085390652589745\n",
      "train loss:0.0007346381622888354\n",
      "train loss:0.0001545245706969843\n",
      "train loss:0.00021885365782166013\n",
      "train loss:0.00011273094171263581\n",
      "train loss:8.50920177443456e-05\n",
      "train loss:0.0013301676671990136\n",
      "train loss:0.00032775245843297393\n",
      "train loss:0.0008620428663065914\n",
      "train loss:0.0008186958734624929\n",
      "train loss:0.0011037112774700468\n",
      "train loss:0.0004164472388598408\n",
      "train loss:7.144486098503934e-05\n",
      "train loss:3.9710534784382926e-05\n",
      "train loss:0.00020137416700238736\n",
      "train loss:0.002472997815338296\n",
      "train loss:0.00036421183727476506\n",
      "train loss:0.0007969758851261658\n",
      "train loss:0.00018375649233336942\n",
      "train loss:0.002641621504544056\n",
      "train loss:0.00026684178294448667\n",
      "train loss:0.0016357142661227717\n",
      "train loss:0.0002574469503761326\n",
      "train loss:0.0005406610157436628\n",
      "train loss:9.057059272627717e-05\n",
      "train loss:0.0019520126955718314\n",
      "train loss:0.000289210258807354\n",
      "train loss:0.0008154152974752392\n",
      "train loss:0.0012692955272534767\n",
      "train loss:0.00023025474750433832\n",
      "train loss:0.0021739708243742476\n",
      "train loss:4.368745929995407e-05\n",
      "train loss:0.0002211426885418301\n",
      "train loss:0.0018198295646065707\n",
      "train loss:0.00022766796688362818\n",
      "train loss:0.0001624388400485148\n",
      "train loss:0.0016257115748356866\n",
      "train loss:0.004360772684248881\n",
      "train loss:0.0006458686065420728\n",
      "train loss:0.0002547460241893835\n",
      "train loss:0.0025436877017846076\n",
      "train loss:0.00039846743233846115\n",
      "train loss:0.0014492215245826593\n",
      "train loss:0.0001140412660507052\n",
      "train loss:0.0008238738707526022\n",
      "train loss:0.001588678545029292\n",
      "train loss:0.00042946579009156706\n",
      "train loss:0.00032077488584648646\n",
      "train loss:6.053928028172356e-05\n",
      "train loss:0.0008239883353413926\n",
      "train loss:0.0019361908303489788\n",
      "train loss:0.0006104587012593872\n",
      "train loss:0.00019953396569723588\n",
      "train loss:0.0024170486297323216\n",
      "train loss:0.00021054801229394667\n",
      "train loss:0.0005635085623196471\n",
      "train loss:0.0013809927740953045\n",
      "train loss:0.00020431421440029622\n",
      "train loss:0.0010242003900781886\n",
      "train loss:0.0013208219500807387\n",
      "train loss:4.9654534481944525e-05\n",
      "train loss:0.0005341744042230682\n",
      "train loss:7.854525885920015e-05\n",
      "train loss:0.00015174193896052595\n",
      "train loss:0.00038714157636188397\n",
      "train loss:0.002663258858222211\n",
      "train loss:0.0001793668580840766\n",
      "train loss:0.0019599014663662416\n",
      "train loss:3.844403835172917e-05\n",
      "train loss:0.003257962029955187\n",
      "train loss:5.863379298994702e-05\n",
      "train loss:0.001883097830607077\n",
      "train loss:0.0024030713661706386\n",
      "train loss:0.0005737831638274029\n",
      "train loss:0.0017879430291158809\n",
      "train loss:0.0008495038524572625\n",
      "train loss:0.0003578606996806354\n",
      "train loss:0.0007044336850023791\n",
      "train loss:0.00011496137140509598\n",
      "train loss:0.000400323761512595\n",
      "train loss:1.81947606302138e-05\n",
      "train loss:0.00016180184190790024\n",
      "train loss:6.934397993146986e-05\n",
      "train loss:0.00011788626062372771\n",
      "train loss:0.00022663851709751496\n",
      "train loss:0.0024309244912681586\n",
      "train loss:2.5819950846981956e-05\n",
      "train loss:4.181510571823342e-05\n",
      "train loss:0.0007588716900582394\n",
      "train loss:0.0011075680524298618\n",
      "train loss:0.00035006578839926605\n",
      "train loss:0.00012233682007868865\n",
      "train loss:0.0023077157772866505\n",
      "train loss:0.000418545526063919\n",
      "train loss:9.318949680890241e-05\n",
      "train loss:0.009113262511654287\n",
      "train loss:0.012155775976563414\n",
      "train loss:0.0009171168491508934\n",
      "train loss:0.000836717752631366\n",
      "train loss:0.0021454138439691993\n",
      "train loss:0.004172603745656461\n",
      "train loss:0.0029797432963748873\n",
      "train loss:0.0013093244241765792\n",
      "train loss:0.003874487684533941\n",
      "train loss:0.0009519418486003585\n",
      "train loss:0.00801731652147468\n",
      "train loss:0.0007638058628199132\n",
      "train loss:0.0010231133273297024\n",
      "train loss:0.00268650219989536\n",
      "train loss:0.000610907358162972\n",
      "train loss:0.00046695762433579427\n",
      "train loss:0.0025464916049684665\n",
      "train loss:0.0045764583131263905\n",
      "train loss:2.6485635282254073e-05\n",
      "train loss:0.006045877718168461\n",
      "train loss:0.0004797801845782018\n",
      "train loss:0.0005007178665272415\n",
      "train loss:0.0001590961468480291\n",
      "train loss:6.019443781076936e-05\n",
      "train loss:0.0011229263447353074\n",
      "train loss:0.00016471882809340258\n",
      "train loss:0.0016226436256965412\n",
      "train loss:0.0014522368592576479\n",
      "train loss:0.0004621749356837991\n",
      "train loss:0.00034940796718921634\n",
      "train loss:0.0009641352842748653\n",
      "train loss:0.0016778954010619217\n",
      "train loss:0.0032022025000661637\n",
      "train loss:0.0014083981320611903\n",
      "train loss:0.0012780081462864887\n",
      "train loss:0.00017821475841489854\n",
      "train loss:0.0005593184616425838\n",
      "train loss:0.004693289104175573\n",
      "train loss:0.00039475501624799215\n",
      "train loss:0.0025648030058972263\n",
      "train loss:0.004563326267083662\n",
      "train loss:0.00045383616142593295\n",
      "train loss:0.0021513337259741663\n",
      "train loss:0.0006999348814979531\n",
      "train loss:0.0032944740587606543\n",
      "train loss:0.0009179192198525657\n",
      "train loss:0.0016702163005554993\n",
      "train loss:0.000509475988064104\n",
      "train loss:0.0012153804099596132\n",
      "train loss:0.00013199203877602196\n",
      "train loss:0.0006832690208575258\n",
      "train loss:0.006165010430882228\n",
      "train loss:0.003020445596647004\n",
      "train loss:0.030566072999748402\n",
      "train loss:0.00025176498243971104\n",
      "train loss:0.001079915915235566\n",
      "train loss:0.0007673467934534051\n",
      "train loss:0.0017577369651689306\n",
      "train loss:0.00041944892240529006\n",
      "train loss:0.0019161138466678477\n",
      "train loss:0.0035637732153074725\n",
      "train loss:0.0003360416313885993\n",
      "train loss:2.4454644480601315e-05\n",
      "train loss:0.002128125516039384\n",
      "train loss:0.0007134800250923363\n",
      "train loss:0.006370136845654118\n",
      "train loss:0.0008410080152997395\n",
      "train loss:0.0027139691528914023\n",
      "train loss:0.0022197708513221307\n",
      "train loss:0.003524988214158103\n",
      "train loss:0.00038661305610080185\n",
      "train loss:7.02598757942576e-05\n",
      "train loss:0.00013153738047887807\n",
      "train loss:0.0020285024892087253\n",
      "train loss:0.00032134653706628464\n",
      "train loss:0.006241261506500834\n",
      "train loss:0.00015174246493437733\n",
      "train loss:0.00036696629621012894\n",
      "train loss:0.00143361455323728\n",
      "train loss:0.001169080170532901\n",
      "train loss:0.0012099603184270895\n",
      "train loss:0.0002098182414174493\n",
      "train loss:0.00011427107008072901\n",
      "train loss:0.0017889906114886777\n",
      "train loss:0.0004300665942974334\n",
      "train loss:6.362731374479484e-05\n",
      "train loss:0.0034488819554032517\n",
      "train loss:0.00026718554072058297\n",
      "train loss:0.0011940827784925308\n",
      "train loss:0.0002977726743378117\n",
      "train loss:0.0013541661291574835\n",
      "train loss:0.0001322526504051089\n",
      "train loss:2.9119420959959298e-05\n",
      "train loss:0.0008941849060118314\n",
      "train loss:0.007459795480063386\n",
      "train loss:0.0012379804396236613\n",
      "train loss:0.0007954688833214598\n",
      "train loss:0.0003894135299001728\n",
      "train loss:0.00038102601480529205\n",
      "train loss:0.0008282831501467602\n",
      "train loss:0.008914177202793158\n",
      "train loss:0.00011653747314494916\n",
      "train loss:1.8738613060318015e-05\n",
      "train loss:0.0040652048843563045\n",
      "train loss:0.0021249540544058523\n",
      "train loss:0.0005471704432721675\n",
      "train loss:0.00025342769938412404\n",
      "train loss:0.0021168494269716833\n",
      "train loss:0.00016763300863499657\n",
      "train loss:3.329758047978526e-05\n",
      "train loss:0.001747209802959819\n",
      "train loss:0.0006546739154534133\n",
      "train loss:0.00010232457714768658\n",
      "train loss:0.00012445719672969898\n",
      "train loss:0.0019185492082207823\n",
      "train loss:0.0005430797320973939\n",
      "train loss:0.0016293175513076138\n",
      "train loss:0.0005808116044089398\n",
      "train loss:0.0005459128833325965\n",
      "train loss:0.0007139338713206967\n",
      "train loss:0.00015842282778908199\n",
      "train loss:0.0005188829716114113\n",
      "train loss:0.001490779275174622\n",
      "train loss:0.0002812479402770338\n",
      "train loss:0.00168767167225495\n",
      "train loss:0.0019180868475240753\n",
      "train loss:0.0008836815191969494\n",
      "train loss:0.0018218516451063073\n",
      "train loss:0.003006291475880303\n",
      "train loss:0.0005077618501954816\n",
      "train loss:0.002278153211018015\n",
      "train loss:0.0008249481208937121\n",
      "train loss:0.0008842862450070445\n",
      "train loss:0.0003804492517083005\n",
      "train loss:0.00034372258236706644\n",
      "train loss:0.00016519441302269896\n",
      "train loss:0.0001483329717872123\n",
      "train loss:0.0001135064785627265\n",
      "train loss:0.0014651131568072407\n",
      "train loss:0.006863964857677375\n",
      "train loss:0.00022035866050694724\n",
      "train loss:0.0012804582975444346\n",
      "train loss:0.0014498963004791678\n",
      "train loss:2.792066629734032e-05\n",
      "train loss:0.00043725145550254014\n",
      "train loss:0.00030429990189162536\n",
      "train loss:0.00475665994220817\n",
      "train loss:0.0015590099416420916\n",
      "train loss:0.0005103904100620774\n",
      "train loss:1.0776291586193313e-05\n",
      "train loss:0.0018968778698718262\n",
      "train loss:0.0017060171157130008\n",
      "train loss:0.0007093748724531731\n",
      "train loss:0.00017657285282718436\n",
      "train loss:0.0011154831449390937\n",
      "train loss:0.00011207367156048399\n",
      "train loss:0.002163207176224138\n",
      "train loss:0.00048591137970418856\n",
      "train loss:0.000474771922578897\n",
      "train loss:0.0005107886748955965\n",
      "train loss:0.00018343406323795508\n",
      "train loss:0.00022243000443569288\n",
      "train loss:0.0017124442819107528\n",
      "train loss:0.005722796360691621\n",
      "train loss:0.012351359183799393\n",
      "train loss:0.0010456056229409794\n",
      "train loss:0.00030041071593170393\n",
      "train loss:0.00010884093467160903\n",
      "train loss:0.00198720975891503\n",
      "train loss:0.00022000672001661864\n",
      "train loss:0.0005441999468846981\n",
      "train loss:0.0003303860388657393\n",
      "train loss:0.0006036581002027435\n",
      "train loss:0.0022938034472850363\n",
      "train loss:0.0003262817390796708\n",
      "train loss:8.193771520037975e-05\n",
      "train loss:0.0010177361180530589\n",
      "train loss:2.911323382552463e-05\n",
      "train loss:0.007534664907089117\n",
      "train loss:0.00027960882740025295\n",
      "train loss:0.00045928235837580845\n",
      "train loss:3.408318256960652e-05\n",
      "train loss:0.0015629771619276606\n",
      "train loss:0.00026317062551143547\n",
      "train loss:0.0006067254095679627\n",
      "train loss:0.000479417790745027\n",
      "train loss:0.000385776073743057\n",
      "train loss:0.001224513038946553\n",
      "train loss:0.0006004744973902907\n",
      "train loss:0.0016762734344924993\n",
      "train loss:0.0008231053647993396\n",
      "train loss:0.00041232789402106994\n",
      "train loss:0.004708093542784355\n",
      "train loss:0.0011931274307284375\n",
      "train loss:0.0015841290545141112\n",
      "train loss:0.0006394425292725217\n",
      "train loss:0.0004154364923602101\n",
      "train loss:0.00010077368323429875\n",
      "train loss:0.00022318470923887628\n",
      "train loss:0.0004584720139310689\n",
      "train loss:0.0013766212164500055\n",
      "train loss:0.0008453443251807607\n",
      "train loss:0.0003992921999558241\n",
      "train loss:0.001361188146393569\n",
      "train loss:0.00011471331235861594\n",
      "train loss:0.002004812861944938\n",
      "train loss:0.0006976851019623541\n",
      "train loss:0.002040903003825701\n",
      "train loss:8.676296287396274e-05\n",
      "train loss:5.252948410393377e-05\n",
      "train loss:0.0005410828162781454\n",
      "train loss:7.948246638990858e-05\n",
      "train loss:0.0002856389895160205\n",
      "train loss:0.0003451459027005919\n",
      "train loss:0.0001294106915897849\n",
      "train loss:0.000489091635043171\n",
      "train loss:0.000987143928067871\n",
      "train loss:0.0012227310502250929\n",
      "train loss:0.0009090491020815858\n",
      "train loss:0.0010775863036384485\n",
      "train loss:0.0007535673092138966\n",
      "train loss:0.0012721086007576625\n",
      "train loss:0.002806549599750508\n",
      "train loss:0.006234099239125116\n",
      "train loss:0.001617372801157909\n",
      "train loss:0.0007920648123770403\n",
      "train loss:0.0005649725674035574\n",
      "train loss:0.0008451902760999602\n",
      "train loss:0.003481325272413488\n",
      "train loss:0.0013306116475216517\n",
      "train loss:0.0037565751065896736\n",
      "train loss:0.0008878496899310181\n",
      "train loss:0.0006327395776438667\n",
      "train loss:0.034420842277067695\n",
      "train loss:0.002981057603551382\n",
      "train loss:0.00034323882730307077\n",
      "train loss:0.0009194549393685746\n",
      "train loss:0.0014533679982614795\n",
      "train loss:0.0021205193786477594\n",
      "train loss:0.0013616380034519476\n",
      "train loss:9.059578034460229e-05\n",
      "train loss:0.00011797027025635295\n",
      "train loss:6.783943261722694e-05\n",
      "train loss:7.901172258032733e-05\n",
      "train loss:0.0024919089718533198\n",
      "train loss:0.00038475967409799875\n",
      "train loss:0.0011070110441426795\n",
      "train loss:1.714290764038364e-05\n",
      "train loss:0.0006344448380260013\n",
      "train loss:0.0005477152999898924\n",
      "train loss:0.001204679516503051\n",
      "train loss:0.0004208419754128055\n",
      "train loss:0.00026106213006306145\n",
      "train loss:0.001448063004476275\n",
      "train loss:0.000780326979089647\n",
      "train loss:0.0017271699931330246\n",
      "train loss:0.0022415135421554894\n",
      "train loss:0.00010065355987790238\n",
      "train loss:0.001434008031944992\n",
      "train loss:0.00013120855664871156\n",
      "train loss:0.0014885634815850301\n",
      "train loss:0.0025905630714249815\n",
      "train loss:0.0003940067749913677\n",
      "train loss:0.0022064724596265305\n",
      "train loss:0.0005939027622594603\n",
      "train loss:4.806667938396409e-05\n",
      "train loss:0.0005286204689432112\n",
      "train loss:0.0003041167572817056\n",
      "train loss:0.0005092781202792317\n",
      "train loss:0.00017826352770548192\n",
      "train loss:0.00041906487692237795\n",
      "train loss:0.00040198085570612865\n",
      "train loss:0.0008115568099037132\n",
      "train loss:9.152175620656165e-05\n",
      "train loss:0.0009765535689688647\n",
      "train loss:9.176392771796332e-05\n",
      "train loss:1.3596823186822262e-05\n",
      "train loss:1.9190351969833356e-05\n",
      "train loss:5.2862850568222696e-05\n",
      "train loss:0.002209946751159536\n",
      "train loss:0.0011758729880293542\n",
      "train loss:0.00020608115432056235\n",
      "train loss:0.003240108650768017\n",
      "train loss:0.001324517099306976\n",
      "train loss:0.00023755611178832142\n",
      "train loss:0.0004439302400009265\n",
      "train loss:0.00020257492235839711\n",
      "train loss:0.0003015289567478216\n",
      "train loss:0.00013095504621581284\n",
      "train loss:3.803253495525874e-05\n",
      "train loss:0.0010011059937824758\n",
      "train loss:0.0009094661774855363\n",
      "train loss:0.0007299699981231536\n",
      "train loss:0.0002388480971984432\n",
      "train loss:0.0038600349048578063\n",
      "train loss:7.828801698523437e-05\n",
      "train loss:0.0004334991653964009\n",
      "train loss:0.00010440374804713806\n",
      "train loss:0.0014459390150732732\n",
      "train loss:9.193636540287776e-05\n",
      "train loss:0.00025168454290498877\n",
      "train loss:4.102971234104431e-05\n",
      "train loss:0.00010027046482018964\n",
      "train loss:0.00040886572919067194\n",
      "train loss:0.001328848788332772\n",
      "train loss:2.850881884580864e-05\n",
      "train loss:0.0016141011008382281\n",
      "train loss:0.0010866763181813864\n",
      "train loss:2.3995806838292036e-05\n",
      "train loss:5.7530299851457974e-05\n",
      "train loss:0.00019509424390620457\n",
      "train loss:0.00018352104738606563\n",
      "train loss:0.00018026202275149228\n",
      "train loss:0.0002526202055221543\n",
      "train loss:0.0006167552123546022\n",
      "train loss:0.00020451145119581324\n",
      "train loss:0.0007972903854061551\n",
      "train loss:0.0010728899625612493\n",
      "train loss:0.00035570862424980115\n",
      "train loss:3.429759085418863e-05\n",
      "train loss:0.011907424520285299\n",
      "train loss:7.865024385773453e-05\n",
      "train loss:0.00016227525494340593\n",
      "train loss:0.0001676281746923615\n",
      "train loss:0.00011484907051526631\n",
      "train loss:0.00479181073667558\n",
      "train loss:0.00025392484694326215\n",
      "train loss:0.0021060987357124257\n",
      "train loss:0.000785359800137812\n",
      "train loss:0.0004987081191787797\n",
      "train loss:0.0005411712025730396\n",
      "train loss:0.0007842669363644149\n",
      "train loss:0.00025719703444672463\n",
      "train loss:0.0006670934512802044\n",
      "train loss:9.968687719723318e-05\n",
      "train loss:0.00019025731857327707\n",
      "train loss:0.0004707932932013458\n",
      "train loss:0.000633430641834632\n",
      "train loss:0.0003638117506144539\n",
      "train loss:0.0013523187229720088\n",
      "train loss:0.0011143386949103967\n",
      "train loss:0.0007290089731181403\n",
      "train loss:0.0008215745943663177\n",
      "train loss:0.00119756167896712\n",
      "train loss:0.0001498383541276106\n",
      "train loss:0.00023838514854876495\n",
      "train loss:0.00013723390577266537\n",
      "train loss:0.006973707594969986\n",
      "train loss:0.0010614417372820247\n",
      "train loss:7.057877428228236e-06\n",
      "train loss:0.00017411879616858862\n",
      "train loss:1.4004216461788459e-05\n",
      "train loss:0.0003010782047609631\n",
      "train loss:0.001221594883231449\n",
      "train loss:6.276919968665177e-05\n",
      "train loss:0.00041246641870383924\n",
      "train loss:1.813113296837355e-05\n",
      "train loss:0.0019603757465314307\n",
      "train loss:0.002587286925892141\n",
      "train loss:0.00042913853117440657\n",
      "train loss:0.0013611349718462605\n",
      "train loss:0.0001541226359825449\n",
      "train loss:0.00141279719146099\n",
      "train loss:0.0005115873767754955\n",
      "train loss:6.996562853867084e-05\n",
      "train loss:0.0050679629733765205\n",
      "train loss:0.0007667383115412542\n",
      "train loss:0.004075494268098818\n",
      "train loss:0.0013532791810099314\n",
      "train loss:0.000740508203939525\n",
      "train loss:0.000935219774309028\n",
      "train loss:0.0001405173817977575\n",
      "train loss:0.0006261405132591259\n",
      "train loss:0.006851925448345773\n",
      "train loss:0.0005527423078420679\n",
      "train loss:0.026566108511659938\n",
      "train loss:1.7164848960835852e-05\n",
      "train loss:2.062515773212598e-05\n",
      "train loss:0.003462471634428338\n",
      "train loss:0.0005873826259371852\n",
      "train loss:0.00046685560551241843\n",
      "train loss:9.505556672148401e-05\n",
      "train loss:9.822395153333926e-05\n",
      "train loss:0.005529447489713591\n",
      "train loss:0.0044978269041718805\n",
      "train loss:0.0002613733842246423\n",
      "train loss:0.004306997955649802\n",
      "train loss:0.002292327907994808\n",
      "train loss:0.0006919223432147876\n",
      "train loss:0.009253449529030424\n",
      "train loss:0.0007712674576799767\n",
      "train loss:0.0014544102413117507\n",
      "train loss:0.0009311504390201596\n",
      "train loss:0.004830862457757821\n",
      "train loss:0.0007348774066428843\n",
      "train loss:0.002845566629096641\n",
      "train loss:0.0015694325411350362\n",
      "train loss:0.00030817031909108035\n",
      "train loss:0.00037619812035839107\n",
      "train loss:2.0963828913355794e-05\n",
      "train loss:0.0009984233978508463\n",
      "train loss:0.0010547551217601418\n",
      "train loss:0.00010717188651396743\n",
      "train loss:0.00014439872942344602\n",
      "train loss:0.0012945267326618037\n",
      "train loss:0.003502821470308345\n",
      "train loss:0.0024238338581906303\n",
      "train loss:0.003106980109703888\n",
      "train loss:0.00017868153409995375\n",
      "train loss:0.0020345019934018774\n",
      "train loss:0.0010616221873714629\n",
      "train loss:0.0005187521531512516\n",
      "train loss:0.006295190646527421\n",
      "train loss:0.03404159042001833\n",
      "train loss:0.0016474392436166014\n",
      "train loss:0.007973316504807086\n",
      "train loss:0.0008680200964797284\n",
      "train loss:0.0006905560330339161\n",
      "train loss:0.0006825821331555057\n",
      "train loss:0.0005845265920883421\n",
      "train loss:0.0025463503318417994\n",
      "train loss:0.0001480442201188704\n",
      "train loss:0.004164087553901865\n",
      "train loss:0.005807709260249685\n",
      "train loss:0.0017908068310355778\n",
      "train loss:0.0016637570893582212\n",
      "train loss:0.0013208763224457445\n",
      "train loss:0.001102743263966251\n",
      "train loss:0.001212856596511794\n",
      "train loss:0.005098709015528691\n",
      "train loss:0.0007062256950719492\n",
      "train loss:0.0016753304802943675\n",
      "train loss:0.006152719742200454\n",
      "train loss:0.0008627869653466239\n",
      "train loss:0.0005844344661738982\n",
      "train loss:0.0007511881864477557\n",
      "train loss:0.0007535470967150532\n",
      "train loss:0.00023467769418513776\n",
      "train loss:0.00012601149423940118\n",
      "train loss:4.394662152492823e-05\n",
      "train loss:0.002390212260602335\n",
      "train loss:0.007882304754568699\n",
      "train loss:0.00044893330327919553\n",
      "train loss:0.00265275746897401\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9894\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0de9b2e6-ac3c-442c-b7f6-c4175755092b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'simple_convnet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msimple_convnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleConvNet\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_show\u001b[39m(filters, nx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'simple_convnet'"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from simple_convnet import SimpleConvNet\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 무작위(랜덤) 초기화 후의 가중치\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b24b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "합성곱 후 shape: 높이 6, 너비 8\n",
      "풀링 후 shape: 높이 1, 너비 1\n",
      "최종 컨볼루션 후 shape: (1, 3, 1, 1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baae5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
